{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b686d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_score(val):\n",
    "    if val > 4.0:\n",
    "        return 4.0\n",
    "    elif val < 1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "\n",
    "def add_missing_entries(source_path, target_path):\n",
    "    s_df = read_csv(source_path, sep=',', usecols=['pair_id'])\n",
    "    t_df = read_csv(target_path, sep=',', usecols=['pair_id', 'Overall'])\n",
    "    print(s_df['pair_id'].unique().shape)\n",
    "    print(t_df['pair_id'].unique().shape)\n",
    "    # print(t_df.shape)\n",
    "    # n_df =\n",
    "    # print(n_df.shape)\n",
    "    final_rows = []\n",
    "    for row in s_df.itertuples(index=False):\n",
    "        p_id = row[0]\n",
    "        t_row = t_df.loc[t_df['pair_id'] == p_id]\n",
    "        score = t_row.iloc[0, 1] if t_row.shape[0] >= 1 else random.choice([2, 3])\n",
    "        final_rows.append([p_id, score])\n",
    "\n",
    "    df = DataFrame(final_rows, columns=['pair_id', 'Overall'])\n",
    "    df['Overall'] = df['Overall'].apply(clip_score)\n",
    "    df.to_csv(target_path, mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fad782aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4590, 14) (4590,) (242, 14) (242,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas import read_csv, concat, DataFrame\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from src.config import CLEANED_PATH, DataType, UNCLEANED_PATH, RAW_FILE, INFERENCE_FILE\n",
    "\n",
    "\n",
    "train_path = CLEANED_PATH.format(data_type=DataType.train.name) + INFERENCE_FILE\n",
    "test_path = CLEANED_PATH.format(data_type=DataType.test.name) + INFERENCE_FILE\n",
    "\n",
    "train_df = read_csv(train_path, sep=',', usecols=['sentences_mean', 'sentences_min', 'sentences_max',\n",
    "                                                  'sentences_med', 'title', 'n1_title_n2_text',\n",
    "                                                  'n2_title_n1_text', 'n1_title_n1_text',\n",
    "                                                  'n2_title_n2_text', 'start_para', 'end_para',\n",
    "                                                  'ner', 'tf_idf', 'wmd_dist', 'overall'])\n",
    "\n",
    "\n",
    "train_df = train_df.drop_duplicates()\n",
    "test_df = read_csv(test_path, sep=',', usecols=['sentences_mean', 'sentences_min', 'sentences_max',\n",
    "                                                'sentences_med', 'title', 'n1_title_n2_text',\n",
    "                                                'n2_title_n1_text', 'n1_title_n1_text',\n",
    "                                                'n2_title_n2_text', 'start_para', 'end_para',\n",
    "                                                'ner', 'tf_idf', 'wmd_dist'])\n",
    "\n",
    "y = train_df.pop('overall')\n",
    "y = y.values\n",
    "x = train_df.values\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.05, random_state=5)\n",
    "print(train_x.shape, np.array(train_y).shape, val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90cb7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "class Pearson(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"pearson\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return pearsonr(y_pred, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a44b817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 11.84973| val_0_mse: 3.66417 |  0:00:00s\n",
      "epoch 1  | loss: 1.79276 | val_0_mse: 1.47862 |  0:00:00s\n",
      "epoch 2  | loss: 1.03512 | val_0_mse: 1.39096 |  0:00:00s\n",
      "epoch 3  | loss: 0.73674 | val_0_mse: 1.05266 |  0:00:00s\n",
      "epoch 4  | loss: 0.61881 | val_0_mse: 1.03978 |  0:00:00s\n",
      "epoch 5  | loss: 0.56444 | val_0_mse: 0.91519 |  0:00:01s\n",
      "epoch 6  | loss: 0.55235 | val_0_mse: 0.83656 |  0:00:01s\n",
      "epoch 7  | loss: 0.53148 | val_0_mse: 0.89056 |  0:00:01s\n",
      "epoch 8  | loss: 0.51278 | val_0_mse: 0.84334 |  0:00:01s\n",
      "epoch 9  | loss: 0.50782 | val_0_mse: 0.82895 |  0:00:02s\n",
      "epoch 10 | loss: 0.50769 | val_0_mse: 0.86019 |  0:00:02s\n",
      "epoch 11 | loss: 0.50316 | val_0_mse: 0.8221  |  0:00:02s\n",
      "epoch 12 | loss: 0.50278 | val_0_mse: 0.80893 |  0:00:02s\n",
      "epoch 13 | loss: 0.50055 | val_0_mse: 0.89366 |  0:00:02s\n",
      "epoch 14 | loss: 0.50715 | val_0_mse: 0.76424 |  0:00:02s\n",
      "epoch 15 | loss: 0.49152 | val_0_mse: 0.78388 |  0:00:03s\n",
      "epoch 16 | loss: 0.48084 | val_0_mse: 0.79238 |  0:00:03s\n",
      "epoch 17 | loss: 0.46964 | val_0_mse: 0.80963 |  0:00:03s\n",
      "epoch 18 | loss: 0.48328 | val_0_mse: 0.76474 |  0:00:03s\n",
      "epoch 19 | loss: 0.46636 | val_0_mse: 0.7491  |  0:00:03s\n",
      "epoch 20 | loss: 0.48669 | val_0_mse: 0.75336 |  0:00:04s\n",
      "epoch 21 | loss: 0.46797 | val_0_mse: 0.71405 |  0:00:04s\n",
      "epoch 22 | loss: 0.4654  | val_0_mse: 0.71764 |  0:00:04s\n",
      "epoch 23 | loss: 0.46931 | val_0_mse: 0.7072  |  0:00:04s\n",
      "epoch 24 | loss: 0.47351 | val_0_mse: 0.71717 |  0:00:05s\n",
      "epoch 25 | loss: 0.47528 | val_0_mse: 0.70269 |  0:00:05s\n",
      "epoch 26 | loss: 0.47586 | val_0_mse: 0.675   |  0:00:05s\n",
      "epoch 27 | loss: 0.47551 | val_0_mse: 0.66589 |  0:00:05s\n",
      "epoch 28 | loss: 0.47164 | val_0_mse: 0.6747  |  0:00:05s\n",
      "epoch 29 | loss: 0.47111 | val_0_mse: 0.64464 |  0:00:06s\n",
      "epoch 30 | loss: 0.45971 | val_0_mse: 0.63901 |  0:00:06s\n",
      "epoch 31 | loss: 0.46629 | val_0_mse: 0.64902 |  0:00:06s\n",
      "epoch 32 | loss: 0.46117 | val_0_mse: 0.63146 |  0:00:06s\n",
      "epoch 33 | loss: 0.46474 | val_0_mse: 0.62397 |  0:00:06s\n",
      "epoch 34 | loss: 0.46228 | val_0_mse: 0.61151 |  0:00:07s\n",
      "epoch 35 | loss: 0.45652 | val_0_mse: 0.58448 |  0:00:07s\n",
      "epoch 36 | loss: 0.46407 | val_0_mse: 0.62085 |  0:00:07s\n",
      "epoch 37 | loss: 0.46649 | val_0_mse: 0.60186 |  0:00:07s\n",
      "epoch 38 | loss: 0.4513  | val_0_mse: 0.58238 |  0:00:07s\n",
      "epoch 39 | loss: 0.45472 | val_0_mse: 0.58596 |  0:00:08s\n",
      "epoch 40 | loss: 0.44802 | val_0_mse: 0.60575 |  0:00:08s\n",
      "epoch 41 | loss: 0.44956 | val_0_mse: 0.5852  |  0:00:08s\n",
      "epoch 42 | loss: 0.45255 | val_0_mse: 0.56261 |  0:00:08s\n",
      "epoch 43 | loss: 0.4597  | val_0_mse: 0.57164 |  0:00:08s\n",
      "epoch 44 | loss: 0.45417 | val_0_mse: 0.57406 |  0:00:09s\n",
      "epoch 45 | loss: 0.44789 | val_0_mse: 0.58872 |  0:00:09s\n",
      "epoch 46 | loss: 0.45419 | val_0_mse: 0.56841 |  0:00:09s\n",
      "epoch 47 | loss: 0.4468  | val_0_mse: 0.53551 |  0:00:09s\n",
      "epoch 48 | loss: 0.45306 | val_0_mse: 0.56889 |  0:00:09s\n",
      "epoch 49 | loss: 0.47883 | val_0_mse: 0.57641 |  0:00:09s\n",
      "epoch 50 | loss: 0.46652 | val_0_mse: 0.54928 |  0:00:10s\n",
      "epoch 51 | loss: 0.45992 | val_0_mse: 0.55046 |  0:00:10s\n",
      "epoch 52 | loss: 0.46249 | val_0_mse: 0.53806 |  0:00:10s\n",
      "epoch 53 | loss: 0.45282 | val_0_mse: 0.54257 |  0:00:10s\n",
      "epoch 54 | loss: 0.457   | val_0_mse: 0.53566 |  0:00:10s\n",
      "epoch 55 | loss: 0.44366 | val_0_mse: 0.51341 |  0:00:11s\n",
      "epoch 56 | loss: 0.43604 | val_0_mse: 0.538   |  0:00:11s\n",
      "epoch 57 | loss: 0.43526 | val_0_mse: 0.52574 |  0:00:11s\n",
      "epoch 58 | loss: 0.43724 | val_0_mse: 0.53229 |  0:00:11s\n",
      "epoch 59 | loss: 0.434   | val_0_mse: 0.50009 |  0:00:11s\n",
      "epoch 60 | loss: 0.43697 | val_0_mse: 0.53952 |  0:00:12s\n",
      "epoch 61 | loss: 0.44232 | val_0_mse: 0.52105 |  0:00:12s\n",
      "epoch 62 | loss: 0.44566 | val_0_mse: 0.50978 |  0:00:12s\n",
      "epoch 63 | loss: 0.43586 | val_0_mse: 0.50899 |  0:00:12s\n",
      "epoch 64 | loss: 0.44523 | val_0_mse: 0.52277 |  0:00:12s\n",
      "epoch 65 | loss: 0.44401 | val_0_mse: 0.48493 |  0:00:13s\n",
      "epoch 66 | loss: 0.42942 | val_0_mse: 0.49734 |  0:00:13s\n",
      "epoch 67 | loss: 0.43857 | val_0_mse: 0.49052 |  0:00:13s\n",
      "epoch 68 | loss: 0.42233 | val_0_mse: 0.49202 |  0:00:13s\n",
      "epoch 69 | loss: 0.43982 | val_0_mse: 0.47375 |  0:00:13s\n",
      "epoch 70 | loss: 0.43355 | val_0_mse: 0.48308 |  0:00:14s\n",
      "epoch 71 | loss: 0.43492 | val_0_mse: 0.48591 |  0:00:14s\n",
      "epoch 72 | loss: 0.43669 | val_0_mse: 0.48619 |  0:00:14s\n",
      "epoch 73 | loss: 0.43628 | val_0_mse: 0.49756 |  0:00:14s\n",
      "epoch 74 | loss: 0.43561 | val_0_mse: 0.49722 |  0:00:15s\n",
      "epoch 75 | loss: 0.43978 | val_0_mse: 0.50591 |  0:00:15s\n",
      "epoch 76 | loss: 0.4383  | val_0_mse: 0.50575 |  0:00:15s\n",
      "epoch 77 | loss: 0.43302 | val_0_mse: 0.4948  |  0:00:15s\n",
      "epoch 78 | loss: 0.4281  | val_0_mse: 0.48549 |  0:00:15s\n",
      "epoch 79 | loss: 0.43245 | val_0_mse: 0.49843 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 0.47375\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    clf = TabNetRegressor(seed=5, n_d=16, n_independent=1, n_shared=2, n_steps=5, momentum=0.19, mask_type='entmax')  #TabNetRegressor()\n",
    "    clf.fit(train_x, np.array(train_y).reshape(-1, 1), eval_set=[(val_x, np.array(val_y).reshape(-1, 1))])\n",
    "    \n",
    "    return clf\n",
    "\n",
    "model = train()\n",
    "# print(model.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "882071cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7935352695459977, 4.0292371297862686e-158)\n"
     ]
    }
   ],
   "source": [
    "pred_val = model.predict(val_x)\n",
    "\n",
    "\n",
    "pred_val = np.squeeze(np.asarray(pred_val))\n",
    "\n",
    "val_y = np.squeeze(np.asarray(val_y))\n",
    "print(pearsonr(pred_val, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6f12090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 4t2h3fjz\n",
      "Sweep URL: https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "sweep_config = {\n",
    "  \"name\" : \"tabnet-b-100\",\n",
    "    \"metric\": {\"name\": \"pearson\", \"goal\": \"maximize\"},\n",
    "  \"method\" : \"bayes\",\n",
    "  \"parameters\" : {\n",
    "    \"seed\": {\"values\" :[5]},\n",
    "    \"n_d\" : {\"values\" :[8, 12, 16, 20, 24]},\n",
    "    \"n_steps\": {\n",
    "        \"min\": 3,\n",
    "        \"max\": 8\n",
    "    },\n",
    "    \"n_independent\": {\n",
    "        \"min\": 1,\n",
    "        \"max\": 5\n",
    "    },\n",
    "    \"n_shared\": {\n",
    "        \"min\": 1,\n",
    "        \"max\": 5\n",
    "    },\n",
    "    \"momentum\": {\n",
    "        \"min\": 0.01,\n",
    "        \"max\": 0.4\n",
    "    },\n",
    "    \"mask_type\": {\"values\" :[\"sparsemax\", \"entmax\"]}\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"SemEval-Task-8\", entity=\"notsomonk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        model = make_model(config)\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "            loss = model.fit()  # your model training code here\n",
    "            wandb.log({\"loss\": loss, \"epoch\": epoch})\n",
    "\n",
    "count = 5 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6dc409f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g9qnpr9p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1795786550449812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/g9qnpr9p\" target=\"_blank\">radiant-sweep-1</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 8.08177 | val_0_mse: 5.58359 |  0:00:00s\n",
      "epoch 1  | loss: 2.29005 | val_0_mse: 1.73575 |  0:00:00s\n",
      "epoch 2  | loss: 1.63158 | val_0_mse: 1.98248 |  0:00:00s\n",
      "epoch 3  | loss: 1.195   | val_0_mse: 1.39432 |  0:00:01s\n",
      "epoch 4  | loss: 1.11975 | val_0_mse: 1.21482 |  0:00:01s\n",
      "epoch 5  | loss: 1.07678 | val_0_mse: 1.30251 |  0:00:01s\n",
      "epoch 6  | loss: 0.81231 | val_0_mse: 1.46327 |  0:00:02s\n",
      "epoch 7  | loss: 0.82965 | val_0_mse: 0.92023 |  0:00:02s\n",
      "epoch 8  | loss: 0.77882 | val_0_mse: 0.93488 |  0:00:02s\n",
      "epoch 9  | loss: 0.76152 | val_0_mse: 0.91054 |  0:00:03s\n",
      "epoch 10 | loss: 0.75762 | val_0_mse: 0.9332  |  0:00:03s\n",
      "epoch 11 | loss: 0.89413 | val_0_mse: 0.93136 |  0:00:04s\n",
      "epoch 12 | loss: 1.06822 | val_0_mse: 0.99202 |  0:00:04s\n",
      "epoch 13 | loss: 0.75124 | val_0_mse: 0.87063 |  0:00:04s\n",
      "epoch 14 | loss: 0.79435 | val_0_mse: 0.98102 |  0:00:05s\n",
      "epoch 15 | loss: 0.75398 | val_0_mse: 0.85802 |  0:00:05s\n",
      "epoch 16 | loss: 0.71527 | val_0_mse: 0.95634 |  0:00:05s\n",
      "epoch 17 | loss: 0.64362 | val_0_mse: 0.86802 |  0:00:06s\n",
      "epoch 18 | loss: 0.66177 | val_0_mse: 0.80043 |  0:00:06s\n",
      "epoch 19 | loss: 0.63202 | val_0_mse: 1.05944 |  0:00:06s\n",
      "epoch 20 | loss: 0.69292 | val_0_mse: 0.84237 |  0:00:07s\n",
      "epoch 21 | loss: 0.65263 | val_0_mse: 0.85512 |  0:00:07s\n",
      "epoch 22 | loss: 0.58473 | val_0_mse: 0.82213 |  0:00:07s\n",
      "epoch 23 | loss: 0.60516 | val_0_mse: 0.83844 |  0:00:08s\n",
      "epoch 24 | loss: 0.68462 | val_0_mse: 0.89442 |  0:00:08s\n",
      "epoch 25 | loss: 0.61797 | val_0_mse: 0.73404 |  0:00:08s\n",
      "epoch 26 | loss: 0.61458 | val_0_mse: 0.73815 |  0:00:09s\n",
      "epoch 27 | loss: 0.60769 | val_0_mse: 0.781   |  0:00:09s\n",
      "epoch 28 | loss: 0.60253 | val_0_mse: 0.71826 |  0:00:09s\n",
      "epoch 29 | loss: 0.57087 | val_0_mse: 0.82252 |  0:00:10s\n",
      "epoch 30 | loss: 0.57478 | val_0_mse: 0.68416 |  0:00:10s\n",
      "epoch 31 | loss: 0.59197 | val_0_mse: 0.843   |  0:00:10s\n",
      "epoch 32 | loss: 0.6074  | val_0_mse: 0.64479 |  0:00:11s\n",
      "epoch 33 | loss: 0.55388 | val_0_mse: 0.71622 |  0:00:11s\n",
      "epoch 34 | loss: 0.55308 | val_0_mse: 0.71409 |  0:00:11s\n",
      "epoch 35 | loss: 0.5467  | val_0_mse: 0.7822  |  0:00:12s\n",
      "epoch 36 | loss: 0.55105 | val_0_mse: 0.66679 |  0:00:12s\n",
      "epoch 37 | loss: 0.53777 | val_0_mse: 0.75588 |  0:00:12s\n",
      "epoch 38 | loss: 0.55543 | val_0_mse: 0.66587 |  0:00:13s\n",
      "epoch 39 | loss: 0.53791 | val_0_mse: 0.65037 |  0:00:13s\n",
      "epoch 40 | loss: 0.53938 | val_0_mse: 0.63565 |  0:00:13s\n",
      "epoch 41 | loss: 0.53643 | val_0_mse: 0.61476 |  0:00:14s\n",
      "epoch 42 | loss: 0.54481 | val_0_mse: 0.60895 |  0:00:14s\n",
      "epoch 43 | loss: 0.52743 | val_0_mse: 0.62676 |  0:00:14s\n",
      "epoch 44 | loss: 0.51403 | val_0_mse: 0.68296 |  0:00:15s\n",
      "epoch 45 | loss: 0.5183  | val_0_mse: 0.63576 |  0:00:15s\n",
      "epoch 46 | loss: 0.51726 | val_0_mse: 0.6057  |  0:00:15s\n",
      "epoch 47 | loss: 0.50894 | val_0_mse: 0.64224 |  0:00:16s\n",
      "epoch 48 | loss: 0.52334 | val_0_mse: 0.63363 |  0:00:16s\n",
      "epoch 49 | loss: 0.5181  | val_0_mse: 0.59499 |  0:00:17s\n",
      "epoch 50 | loss: 0.52588 | val_0_mse: 0.62579 |  0:00:17s\n",
      "epoch 51 | loss: 0.53613 | val_0_mse: 0.59285 |  0:00:17s\n",
      "epoch 52 | loss: 0.57077 | val_0_mse: 0.56636 |  0:00:18s\n",
      "epoch 53 | loss: 0.52758 | val_0_mse: 0.57788 |  0:00:18s\n",
      "epoch 54 | loss: 0.51603 | val_0_mse: 0.55555 |  0:00:18s\n",
      "epoch 55 | loss: 0.5212  | val_0_mse: 0.65816 |  0:00:19s\n",
      "epoch 56 | loss: 0.54348 | val_0_mse: 0.58077 |  0:00:19s\n",
      "epoch 57 | loss: 0.53229 | val_0_mse: 0.5641  |  0:00:19s\n",
      "epoch 58 | loss: 0.52197 | val_0_mse: 0.54373 |  0:00:20s\n",
      "epoch 59 | loss: 0.51362 | val_0_mse: 0.54877 |  0:00:20s\n",
      "epoch 60 | loss: 0.51283 | val_0_mse: 0.54201 |  0:00:20s\n",
      "epoch 61 | loss: 0.53138 | val_0_mse: 0.64168 |  0:00:21s\n",
      "epoch 62 | loss: 0.57943 | val_0_mse: 0.59828 |  0:00:21s\n",
      "epoch 63 | loss: 0.5522  | val_0_mse: 0.62453 |  0:00:21s\n",
      "epoch 64 | loss: 0.54625 | val_0_mse: 0.5708  |  0:00:22s\n",
      "epoch 65 | loss: 0.56918 | val_0_mse: 0.61399 |  0:00:22s\n",
      "epoch 66 | loss: 0.65576 | val_0_mse: 0.57378 |  0:00:22s\n",
      "epoch 67 | loss: 0.65658 | val_0_mse: 0.73298 |  0:00:23s\n",
      "epoch 68 | loss: 0.66555 | val_0_mse: 0.65605 |  0:00:23s\n",
      "epoch 69 | loss: 0.72308 | val_0_mse: 0.68581 |  0:00:23s\n",
      "epoch 70 | loss: 0.58045 | val_0_mse: 0.59382 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 0.54201\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3324... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77148</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">radiant-sweep-1</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/g9qnpr9p\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/g9qnpr9p</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044053-g9qnpr9p/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bkjdokji with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.08175560611527018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/bkjdokji\" target=\"_blank\">dandy-sweep-2</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 10.36213| val_0_mse: 3.88142 |  0:00:00s\n",
      "epoch 1  | loss: 2.50942 | val_0_mse: 1.85333 |  0:00:00s\n",
      "epoch 2  | loss: 1.57743 | val_0_mse: 1.34098 |  0:00:01s\n",
      "epoch 3  | loss: 1.13351 | val_0_mse: 1.04792 |  0:00:01s\n",
      "epoch 4  | loss: 0.93672 | val_0_mse: 1.00733 |  0:00:01s\n",
      "epoch 5  | loss: 0.8812  | val_0_mse: 1.03779 |  0:00:02s\n",
      "epoch 6  | loss: 0.82557 | val_0_mse: 1.05669 |  0:00:02s\n",
      "epoch 7  | loss: 0.74736 | val_0_mse: 0.9246  |  0:00:02s\n",
      "epoch 8  | loss: 0.79937 | val_0_mse: 1.16297 |  0:00:03s\n",
      "epoch 9  | loss: 0.76232 | val_0_mse: 0.92028 |  0:00:03s\n",
      "epoch 10 | loss: 0.7474  | val_0_mse: 0.97491 |  0:00:03s\n",
      "epoch 11 | loss: 0.65979 | val_0_mse: 0.96433 |  0:00:04s\n",
      "epoch 12 | loss: 0.66773 | val_0_mse: 0.89734 |  0:00:04s\n",
      "epoch 13 | loss: 0.65177 | val_0_mse: 1.00376 |  0:00:05s\n",
      "epoch 14 | loss: 0.63155 | val_0_mse: 0.81489 |  0:00:05s\n",
      "epoch 15 | loss: 0.6109  | val_0_mse: 0.76942 |  0:00:05s\n",
      "epoch 16 | loss: 0.63709 | val_0_mse: 0.75191 |  0:00:06s\n",
      "epoch 17 | loss: 0.6232  | val_0_mse: 0.81178 |  0:00:06s\n",
      "epoch 18 | loss: 0.61158 | val_0_mse: 0.93804 |  0:00:06s\n",
      "epoch 19 | loss: 0.64977 | val_0_mse: 0.91652 |  0:00:07s\n",
      "epoch 20 | loss: 0.62543 | val_0_mse: 0.98657 |  0:00:07s\n",
      "epoch 21 | loss: 0.66091 | val_0_mse: 0.69208 |  0:00:08s\n",
      "epoch 22 | loss: 0.68984 | val_0_mse: 0.90516 |  0:00:08s\n",
      "epoch 23 | loss: 0.65924 | val_0_mse: 0.78408 |  0:00:08s\n",
      "epoch 24 | loss: 0.68155 | val_0_mse: 0.91427 |  0:00:09s\n",
      "epoch 25 | loss: 0.68825 | val_0_mse: 0.70855 |  0:00:09s\n",
      "epoch 26 | loss: 0.83179 | val_0_mse: 0.67945 |  0:00:09s\n",
      "epoch 27 | loss: 0.60927 | val_0_mse: 0.73582 |  0:00:10s\n",
      "epoch 28 | loss: 0.59744 | val_0_mse: 0.72803 |  0:00:10s\n",
      "epoch 29 | loss: 0.57187 | val_0_mse: 0.67138 |  0:00:11s\n",
      "epoch 30 | loss: 0.57385 | val_0_mse: 0.71842 |  0:00:11s\n",
      "epoch 31 | loss: 0.56038 | val_0_mse: 0.6825  |  0:00:11s\n",
      "epoch 32 | loss: 0.53923 | val_0_mse: 0.68799 |  0:00:12s\n",
      "epoch 33 | loss: 0.55866 | val_0_mse: 0.66044 |  0:00:12s\n",
      "epoch 34 | loss: 0.55191 | val_0_mse: 0.66386 |  0:00:12s\n",
      "epoch 35 | loss: 0.55215 | val_0_mse: 0.67027 |  0:00:13s\n",
      "epoch 36 | loss: 0.56045 | val_0_mse: 0.71057 |  0:00:13s\n",
      "epoch 37 | loss: 0.56046 | val_0_mse: 0.645   |  0:00:14s\n",
      "epoch 38 | loss: 0.5642  | val_0_mse: 0.6825  |  0:00:14s\n",
      "epoch 39 | loss: 0.54883 | val_0_mse: 0.6143  |  0:00:14s\n",
      "epoch 40 | loss: 0.55091 | val_0_mse: 0.58874 |  0:00:15s\n",
      "epoch 41 | loss: 0.53623 | val_0_mse: 0.61048 |  0:00:15s\n",
      "epoch 42 | loss: 0.53721 | val_0_mse: 0.60544 |  0:00:15s\n",
      "epoch 43 | loss: 0.52633 | val_0_mse: 0.65051 |  0:00:16s\n",
      "epoch 44 | loss: 0.56349 | val_0_mse: 0.73131 |  0:00:16s\n",
      "epoch 45 | loss: 0.59764 | val_0_mse: 0.60905 |  0:00:16s\n",
      "epoch 46 | loss: 0.58714 | val_0_mse: 0.69533 |  0:00:17s\n",
      "epoch 47 | loss: 0.55433 | val_0_mse: 0.62885 |  0:00:17s\n",
      "epoch 48 | loss: 0.53727 | val_0_mse: 0.59428 |  0:00:18s\n",
      "epoch 49 | loss: 0.53023 | val_0_mse: 0.6208  |  0:00:18s\n",
      "epoch 50 | loss: 0.53226 | val_0_mse: 0.67946 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_mse = 0.58874\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3393... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76371</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dandy-sweep-2</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/bkjdokji\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/bkjdokji</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044124-bkjdokji/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aei5dkoz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1946445954235542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/aei5dkoz\" target=\"_blank\">copper-sweep-3</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.92979 | val_0_mse: 2.21854 |  0:00:00s\n",
      "epoch 1  | loss: 1.96298 | val_0_mse: 1.39582 |  0:00:00s\n",
      "epoch 2  | loss: 1.18482 | val_0_mse: 1.24455 |  0:00:00s\n",
      "epoch 3  | loss: 1.04837 | val_0_mse: 1.30427 |  0:00:01s\n",
      "epoch 4  | loss: 0.94767 | val_0_mse: 0.90237 |  0:00:01s\n",
      "epoch 5  | loss: 0.94568 | val_0_mse: 1.28839 |  0:00:01s\n",
      "epoch 6  | loss: 0.81649 | val_0_mse: 0.92922 |  0:00:02s\n",
      "epoch 7  | loss: 0.7094  | val_0_mse: 1.03592 |  0:00:02s\n",
      "epoch 8  | loss: 0.64301 | val_0_mse: 0.84883 |  0:00:02s\n",
      "epoch 9  | loss: 0.61246 | val_0_mse: 0.95805 |  0:00:02s\n",
      "epoch 10 | loss: 0.60062 | val_0_mse: 0.98402 |  0:00:03s\n",
      "epoch 11 | loss: 0.59328 | val_0_mse: 0.95011 |  0:00:03s\n",
      "epoch 12 | loss: 0.5738  | val_0_mse: 1.0162  |  0:00:03s\n",
      "epoch 13 | loss: 0.54742 | val_0_mse: 0.97607 |  0:00:04s\n",
      "epoch 14 | loss: 0.53204 | val_0_mse: 0.89343 |  0:00:04s\n",
      "epoch 15 | loss: 0.53782 | val_0_mse: 0.7832  |  0:00:04s\n",
      "epoch 16 | loss: 0.56576 | val_0_mse: 0.77193 |  0:00:04s\n",
      "epoch 17 | loss: 0.55465 | val_0_mse: 0.79493 |  0:00:05s\n",
      "epoch 18 | loss: 0.53486 | val_0_mse: 0.90378 |  0:00:05s\n",
      "epoch 19 | loss: 0.54029 | val_0_mse: 0.83452 |  0:00:05s\n",
      "epoch 20 | loss: 0.53781 | val_0_mse: 0.83388 |  0:00:06s\n",
      "epoch 21 | loss: 0.54828 | val_0_mse: 0.78701 |  0:00:06s\n",
      "epoch 22 | loss: 0.52142 | val_0_mse: 0.80717 |  0:00:06s\n",
      "epoch 23 | loss: 0.52884 | val_0_mse: 0.74618 |  0:00:07s\n",
      "epoch 24 | loss: 0.61554 | val_0_mse: 0.86552 |  0:00:07s\n",
      "epoch 25 | loss: 0.66057 | val_0_mse: 0.81216 |  0:00:07s\n",
      "epoch 26 | loss: 0.52718 | val_0_mse: 0.78967 |  0:00:07s\n",
      "epoch 27 | loss: 0.56081 | val_0_mse: 0.67074 |  0:00:08s\n",
      "epoch 28 | loss: 0.54577 | val_0_mse: 0.78762 |  0:00:08s\n",
      "epoch 29 | loss: 0.53549 | val_0_mse: 0.67482 |  0:00:08s\n",
      "epoch 30 | loss: 0.52437 | val_0_mse: 0.75069 |  0:00:09s\n",
      "epoch 31 | loss: 0.51435 | val_0_mse: 0.71044 |  0:00:09s\n",
      "epoch 32 | loss: 0.5162  | val_0_mse: 0.64467 |  0:00:09s\n",
      "epoch 33 | loss: 0.50694 | val_0_mse: 0.71572 |  0:00:10s\n",
      "epoch 34 | loss: 0.50776 | val_0_mse: 0.63121 |  0:00:10s\n",
      "epoch 35 | loss: 0.51297 | val_0_mse: 0.74111 |  0:00:10s\n",
      "epoch 36 | loss: 0.50925 | val_0_mse: 0.67448 |  0:00:10s\n",
      "epoch 37 | loss: 0.51222 | val_0_mse: 0.7629  |  0:00:11s\n",
      "epoch 38 | loss: 0.53235 | val_0_mse: 0.61409 |  0:00:11s\n",
      "epoch 39 | loss: 0.53133 | val_0_mse: 0.70279 |  0:00:11s\n",
      "epoch 40 | loss: 0.60892 | val_0_mse: 0.64344 |  0:00:12s\n",
      "epoch 41 | loss: 0.56077 | val_0_mse: 0.61521 |  0:00:12s\n",
      "epoch 42 | loss: 0.51973 | val_0_mse: 0.65366 |  0:00:12s\n",
      "epoch 43 | loss: 0.49228 | val_0_mse: 0.58026 |  0:00:12s\n",
      "epoch 44 | loss: 0.49092 | val_0_mse: 0.61705 |  0:00:13s\n",
      "epoch 45 | loss: 0.50957 | val_0_mse: 0.66128 |  0:00:13s\n",
      "epoch 46 | loss: 0.50653 | val_0_mse: 0.63767 |  0:00:13s\n",
      "epoch 47 | loss: 0.49182 | val_0_mse: 0.5975  |  0:00:14s\n",
      "epoch 48 | loss: 0.49294 | val_0_mse: 0.60045 |  0:00:14s\n",
      "epoch 49 | loss: 0.51075 | val_0_mse: 0.60431 |  0:00:14s\n",
      "epoch 50 | loss: 0.50456 | val_0_mse: 0.6497  |  0:00:15s\n",
      "epoch 51 | loss: 0.50381 | val_0_mse: 0.6046  |  0:00:15s\n",
      "epoch 52 | loss: 0.49707 | val_0_mse: 0.57813 |  0:00:15s\n",
      "epoch 53 | loss: 0.49769 | val_0_mse: 0.59266 |  0:00:15s\n",
      "epoch 54 | loss: 0.49154 | val_0_mse: 0.57015 |  0:00:16s\n",
      "epoch 55 | loss: 0.49686 | val_0_mse: 0.61744 |  0:00:16s\n",
      "epoch 56 | loss: 0.49879 | val_0_mse: 0.57832 |  0:00:16s\n",
      "epoch 57 | loss: 0.49587 | val_0_mse: 0.58418 |  0:00:17s\n",
      "epoch 58 | loss: 0.49516 | val_0_mse: 0.58932 |  0:00:17s\n",
      "epoch 59 | loss: 0.49689 | val_0_mse: 0.56566 |  0:00:17s\n",
      "epoch 60 | loss: 0.48918 | val_0_mse: 0.56133 |  0:00:17s\n",
      "epoch 61 | loss: 0.51337 | val_0_mse: 0.53437 |  0:00:18s\n",
      "epoch 62 | loss: 0.50504 | val_0_mse: 0.5669  |  0:00:18s\n",
      "epoch 63 | loss: 0.52122 | val_0_mse: 0.5739  |  0:00:18s\n",
      "epoch 64 | loss: 0.51065 | val_0_mse: 0.56643 |  0:00:19s\n",
      "epoch 65 | loss: 0.50443 | val_0_mse: 0.57613 |  0:00:19s\n",
      "epoch 66 | loss: 0.50218 | val_0_mse: 0.60938 |  0:00:19s\n",
      "epoch 67 | loss: 0.50366 | val_0_mse: 0.59203 |  0:00:20s\n",
      "epoch 68 | loss: 0.51928 | val_0_mse: 0.53269 |  0:00:20s\n",
      "epoch 69 | loss: 0.48489 | val_0_mse: 0.56392 |  0:00:20s\n",
      "epoch 70 | loss: 0.48135 | val_0_mse: 0.53955 |  0:00:20s\n",
      "epoch 71 | loss: 0.47978 | val_0_mse: 0.57985 |  0:00:21s\n",
      "epoch 72 | loss: 0.48984 | val_0_mse: 0.55896 |  0:00:21s\n",
      "epoch 73 | loss: 0.49382 | val_0_mse: 0.5498  |  0:00:21s\n",
      "epoch 74 | loss: 0.50305 | val_0_mse: 0.53411 |  0:00:22s\n",
      "epoch 75 | loss: 0.48682 | val_0_mse: 0.52499 |  0:00:22s\n",
      "epoch 76 | loss: 0.47952 | val_0_mse: 0.51938 |  0:00:22s\n",
      "epoch 77 | loss: 0.48724 | val_0_mse: 0.51909 |  0:00:23s\n",
      "epoch 78 | loss: 0.47522 | val_0_mse: 0.51827 |  0:00:23s\n",
      "epoch 79 | loss: 0.48286 | val_0_mse: 0.52382 |  0:00:23s\n",
      "epoch 80 | loss: 0.47533 | val_0_mse: 0.53151 |  0:00:24s\n",
      "epoch 81 | loss: 0.48117 | val_0_mse: 0.54016 |  0:00:24s\n",
      "epoch 82 | loss: 0.49947 | val_0_mse: 0.50916 |  0:00:24s\n",
      "epoch 83 | loss: 0.49241 | val_0_mse: 0.5261  |  0:00:24s\n",
      "epoch 84 | loss: 0.49508 | val_0_mse: 0.52892 |  0:00:25s\n",
      "epoch 85 | loss: 0.48532 | val_0_mse: 0.51563 |  0:00:25s\n",
      "epoch 86 | loss: 0.48213 | val_0_mse: 0.51509 |  0:00:25s\n",
      "epoch 87 | loss: 0.48417 | val_0_mse: 0.51841 |  0:00:26s\n",
      "epoch 88 | loss: 0.47825 | val_0_mse: 0.50753 |  0:00:26s\n",
      "epoch 89 | loss: 0.48657 | val_0_mse: 0.5001  |  0:00:26s\n",
      "epoch 90 | loss: 0.48296 | val_0_mse: 0.5081  |  0:00:26s\n",
      "epoch 91 | loss: 0.48226 | val_0_mse: 0.51835 |  0:00:27s\n",
      "epoch 92 | loss: 0.49263 | val_0_mse: 0.504   |  0:00:27s\n",
      "epoch 93 | loss: 0.47646 | val_0_mse: 0.49405 |  0:00:27s\n",
      "epoch 94 | loss: 0.48323 | val_0_mse: 0.50858 |  0:00:28s\n",
      "epoch 95 | loss: 0.49387 | val_0_mse: 0.51051 |  0:00:28s\n",
      "epoch 96 | loss: 0.48514 | val_0_mse: 0.50896 |  0:00:28s\n",
      "epoch 97 | loss: 0.48646 | val_0_mse: 0.52125 |  0:00:29s\n",
      "epoch 98 | loss: 0.4804  | val_0_mse: 0.53601 |  0:00:29s\n",
      "epoch 99 | loss: 0.50492 | val_0_mse: 0.55843 |  0:00:29s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_mse = 0.49405\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3485... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.79152</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">copper-sweep-3</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/aei5dkoz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/aei5dkoz</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044149-aei5dkoz/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sff2n1e1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.3404754019429927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/sff2n1e1\" target=\"_blank\">fluent-sweep-4</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 11.58948| val_0_mse: 1.90667 |  0:00:00s\n",
      "epoch 1  | loss: 3.41639 | val_0_mse: 1.13186 |  0:00:01s\n",
      "epoch 2  | loss: 1.62486 | val_0_mse: 1.04969 |  0:00:01s\n",
      "epoch 3  | loss: 1.39921 | val_0_mse: 0.98528 |  0:00:02s\n",
      "epoch 4  | loss: 1.18423 | val_0_mse: 0.84419 |  0:00:02s\n",
      "epoch 5  | loss: 1.02927 | val_0_mse: 0.87385 |  0:00:03s\n",
      "epoch 6  | loss: 1.04625 | val_0_mse: 1.10369 |  0:00:03s\n",
      "epoch 7  | loss: 0.97876 | val_0_mse: 1.35517 |  0:00:04s\n",
      "epoch 8  | loss: 0.93724 | val_0_mse: 0.96414 |  0:00:04s\n",
      "epoch 9  | loss: 0.83531 | val_0_mse: 0.95856 |  0:00:05s\n",
      "epoch 10 | loss: 0.76857 | val_0_mse: 1.14537 |  0:00:05s\n",
      "epoch 11 | loss: 0.82559 | val_0_mse: 0.94509 |  0:00:06s\n",
      "epoch 12 | loss: 0.75586 | val_0_mse: 0.85113 |  0:00:06s\n",
      "epoch 13 | loss: 0.9789  | val_0_mse: 0.88135 |  0:00:07s\n",
      "epoch 14 | loss: 0.93608 | val_0_mse: 1.01862 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 0.84419\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3536... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.68218</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fluent-sweep-4</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/sff2n1e1\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/sff2n1e1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044224-sff2n1e1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y8234np2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1389252019629229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/y8234np2\" target=\"_blank\">volcanic-sweep-5</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.37356 | val_0_mse: 2.23339 |  0:00:00s\n",
      "epoch 1  | loss: 1.67788 | val_0_mse: 1.11818 |  0:00:00s\n",
      "epoch 2  | loss: 1.11557 | val_0_mse: 1.3088  |  0:00:00s\n",
      "epoch 3  | loss: 0.93647 | val_0_mse: 1.00028 |  0:00:01s\n",
      "epoch 4  | loss: 0.77575 | val_0_mse: 1.0205  |  0:00:01s\n",
      "epoch 5  | loss: 0.68955 | val_0_mse: 0.98133 |  0:00:01s\n",
      "epoch 6  | loss: 0.71343 | val_0_mse: 1.03847 |  0:00:02s\n",
      "epoch 7  | loss: 0.67254 | val_0_mse: 0.96969 |  0:00:02s\n",
      "epoch 8  | loss: 0.62349 | val_0_mse: 0.86566 |  0:00:02s\n",
      "epoch 9  | loss: 0.63976 | val_0_mse: 0.74712 |  0:00:03s\n",
      "epoch 10 | loss: 0.6193  | val_0_mse: 0.77518 |  0:00:03s\n",
      "epoch 11 | loss: 0.65495 | val_0_mse: 0.83157 |  0:00:04s\n",
      "epoch 12 | loss: 0.61494 | val_0_mse: 1.02495 |  0:00:04s\n",
      "epoch 13 | loss: 0.67493 | val_0_mse: 0.77602 |  0:00:04s\n",
      "epoch 14 | loss: 0.61478 | val_0_mse: 0.89367 |  0:00:05s\n",
      "epoch 15 | loss: 0.58064 | val_0_mse: 0.71742 |  0:00:05s\n",
      "epoch 16 | loss: 0.55417 | val_0_mse: 0.77466 |  0:00:05s\n",
      "epoch 17 | loss: 0.56538 | val_0_mse: 0.72541 |  0:00:06s\n",
      "epoch 18 | loss: 0.56653 | val_0_mse: 0.68331 |  0:00:06s\n",
      "epoch 19 | loss: 0.6354  | val_0_mse: 0.78663 |  0:00:06s\n",
      "epoch 20 | loss: 0.58185 | val_0_mse: 0.74743 |  0:00:07s\n",
      "epoch 21 | loss: 0.55047 | val_0_mse: 0.7381  |  0:00:07s\n",
      "epoch 22 | loss: 0.57753 | val_0_mse: 0.84602 |  0:00:07s\n",
      "epoch 23 | loss: 0.57053 | val_0_mse: 0.70651 |  0:00:08s\n",
      "epoch 24 | loss: 0.55669 | val_0_mse: 0.86808 |  0:00:08s\n",
      "epoch 25 | loss: 0.60725 | val_0_mse: 0.73058 |  0:00:08s\n",
      "epoch 26 | loss: 0.59971 | val_0_mse: 0.79753 |  0:00:09s\n",
      "epoch 27 | loss: 0.57055 | val_0_mse: 0.67088 |  0:00:09s\n",
      "epoch 28 | loss: 0.66714 | val_0_mse: 0.73742 |  0:00:09s\n",
      "epoch 29 | loss: 0.58313 | val_0_mse: 0.62773 |  0:00:10s\n",
      "epoch 30 | loss: 0.59047 | val_0_mse: 0.72197 |  0:00:10s\n",
      "epoch 31 | loss: 0.54795 | val_0_mse: 0.66112 |  0:00:10s\n",
      "epoch 32 | loss: 0.55319 | val_0_mse: 0.73995 |  0:00:11s\n",
      "epoch 33 | loss: 0.55547 | val_0_mse: 0.68097 |  0:00:11s\n",
      "epoch 34 | loss: 0.58679 | val_0_mse: 0.72494 |  0:00:11s\n",
      "epoch 35 | loss: 0.56088 | val_0_mse: 0.66031 |  0:00:12s\n",
      "epoch 36 | loss: 0.5283  | val_0_mse: 0.67091 |  0:00:12s\n",
      "epoch 37 | loss: 0.54341 | val_0_mse: 0.60737 |  0:00:12s\n",
      "epoch 38 | loss: 0.57792 | val_0_mse: 0.67531 |  0:00:13s\n",
      "epoch 39 | loss: 0.62875 | val_0_mse: 0.67019 |  0:00:13s\n",
      "epoch 40 | loss: 0.55093 | val_0_mse: 0.6469  |  0:00:13s\n",
      "epoch 41 | loss: 0.53781 | val_0_mse: 0.59096 |  0:00:14s\n",
      "epoch 42 | loss: 0.5943  | val_0_mse: 0.65323 |  0:00:14s\n",
      "epoch 43 | loss: 0.56437 | val_0_mse: 0.58976 |  0:00:14s\n",
      "epoch 44 | loss: 0.53436 | val_0_mse: 0.61872 |  0:00:15s\n",
      "epoch 45 | loss: 0.52978 | val_0_mse: 0.60828 |  0:00:15s\n",
      "epoch 46 | loss: 0.66547 | val_0_mse: 0.57138 |  0:00:15s\n",
      "epoch 47 | loss: 0.55434 | val_0_mse: 0.57064 |  0:00:16s\n",
      "epoch 48 | loss: 0.55051 | val_0_mse: 0.61183 |  0:00:16s\n",
      "epoch 49 | loss: 0.51138 | val_0_mse: 0.61987 |  0:00:16s\n",
      "epoch 50 | loss: 0.51737 | val_0_mse: 0.63154 |  0:00:17s\n",
      "epoch 51 | loss: 0.51024 | val_0_mse: 0.58352 |  0:00:17s\n",
      "epoch 52 | loss: 0.50495 | val_0_mse: 0.57438 |  0:00:17s\n",
      "epoch 53 | loss: 0.50034 | val_0_mse: 0.58248 |  0:00:18s\n",
      "epoch 54 | loss: 0.49712 | val_0_mse: 0.60216 |  0:00:18s\n",
      "epoch 55 | loss: 0.51357 | val_0_mse: 0.58045 |  0:00:18s\n",
      "epoch 56 | loss: 0.55015 | val_0_mse: 0.59462 |  0:00:19s\n",
      "epoch 57 | loss: 0.51004 | val_0_mse: 0.5823  |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mse = 0.57064\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3592... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76296</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">volcanic-sweep-5</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/y8234np2\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/y8234np2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044238-y8234np2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n2ewpr7v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1606015118714217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/n2ewpr7v\" target=\"_blank\">vague-sweep-6</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.99317 | val_0_mse: 2.87798 |  0:00:00s\n",
      "epoch 1  | loss: 2.1353  | val_0_mse: 1.34218 |  0:00:00s\n",
      "epoch 2  | loss: 1.46138 | val_0_mse: 1.04432 |  0:00:00s\n",
      "epoch 3  | loss: 1.05014 | val_0_mse: 0.91823 |  0:00:01s\n",
      "epoch 4  | loss: 0.96018 | val_0_mse: 1.0356  |  0:00:01s\n",
      "epoch 5  | loss: 0.89984 | val_0_mse: 0.87689 |  0:00:02s\n",
      "epoch 6  | loss: 0.82201 | val_0_mse: 1.24434 |  0:00:02s\n",
      "epoch 7  | loss: 0.80149 | val_0_mse: 1.0007  |  0:00:02s\n",
      "epoch 8  | loss: 0.69564 | val_0_mse: 0.83881 |  0:00:02s\n",
      "epoch 9  | loss: 0.70711 | val_0_mse: 0.92306 |  0:00:03s\n",
      "epoch 10 | loss: 0.63728 | val_0_mse: 0.77875 |  0:00:03s\n",
      "epoch 11 | loss: 0.66198 | val_0_mse: 0.73649 |  0:00:03s\n",
      "epoch 12 | loss: 0.7335  | val_0_mse: 0.90469 |  0:00:04s\n",
      "epoch 13 | loss: 0.68995 | val_0_mse: 0.8592  |  0:00:04s\n",
      "epoch 14 | loss: 0.70375 | val_0_mse: 0.90246 |  0:00:04s\n",
      "epoch 15 | loss: 0.66369 | val_0_mse: 0.76617 |  0:00:05s\n",
      "epoch 16 | loss: 0.59427 | val_0_mse: 0.8477  |  0:00:05s\n",
      "epoch 17 | loss: 0.57272 | val_0_mse: 0.80663 |  0:00:05s\n",
      "epoch 18 | loss: 0.56676 | val_0_mse: 0.75928 |  0:00:06s\n",
      "epoch 19 | loss: 0.56781 | val_0_mse: 0.79581 |  0:00:06s\n",
      "epoch 20 | loss: 0.57243 | val_0_mse: 0.71004 |  0:00:06s\n",
      "epoch 21 | loss: 0.56904 | val_0_mse: 0.79287 |  0:00:07s\n",
      "epoch 22 | loss: 0.60222 | val_0_mse: 0.67236 |  0:00:07s\n",
      "epoch 23 | loss: 0.56605 | val_0_mse: 0.63099 |  0:00:07s\n",
      "epoch 24 | loss: 0.55341 | val_0_mse: 0.77649 |  0:00:08s\n",
      "epoch 25 | loss: 0.54579 | val_0_mse: 0.69601 |  0:00:08s\n",
      "epoch 26 | loss: 0.55272 | val_0_mse: 0.71248 |  0:00:08s\n",
      "epoch 27 | loss: 0.54642 | val_0_mse: 0.71856 |  0:00:09s\n",
      "epoch 28 | loss: 0.52487 | val_0_mse: 0.68323 |  0:00:09s\n",
      "epoch 29 | loss: 0.53021 | val_0_mse: 0.67155 |  0:00:09s\n",
      "epoch 30 | loss: 0.52458 | val_0_mse: 0.69505 |  0:00:10s\n",
      "epoch 31 | loss: 0.51945 | val_0_mse: 0.66828 |  0:00:10s\n",
      "epoch 32 | loss: 0.52181 | val_0_mse: 0.64275 |  0:00:10s\n",
      "epoch 33 | loss: 0.5091  | val_0_mse: 0.65109 |  0:00:11s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.63099\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3668... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76988</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vague-sweep-6</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/n2ewpr7v\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/n2ewpr7v</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044303-n2ewpr7v/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 23j79lda with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2107396744253121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/23j79lda\" target=\"_blank\">skilled-sweep-7</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.28292 | val_0_mse: 3.34204 |  0:00:00s\n",
      "epoch 1  | loss: 1.80317 | val_0_mse: 1.314   |  0:00:00s\n",
      "epoch 2  | loss: 1.12006 | val_0_mse: 1.02561 |  0:00:00s\n",
      "epoch 3  | loss: 0.91938 | val_0_mse: 0.89813 |  0:00:01s\n",
      "epoch 4  | loss: 0.81107 | val_0_mse: 0.94323 |  0:00:01s\n",
      "epoch 5  | loss: 0.80907 | val_0_mse: 0.95954 |  0:00:01s\n",
      "epoch 6  | loss: 0.74444 | val_0_mse: 1.00079 |  0:00:02s\n",
      "epoch 7  | loss: 0.68034 | val_0_mse: 0.85663 |  0:00:02s\n",
      "epoch 8  | loss: 0.63781 | val_0_mse: 1.25633 |  0:00:02s\n",
      "epoch 9  | loss: 0.64149 | val_0_mse: 1.16677 |  0:00:03s\n",
      "epoch 10 | loss: 0.62799 | val_0_mse: 0.75188 |  0:00:03s\n",
      "epoch 11 | loss: 0.6184  | val_0_mse: 0.85929 |  0:00:03s\n",
      "epoch 12 | loss: 0.68118 | val_0_mse: 1.10494 |  0:00:04s\n",
      "epoch 13 | loss: 0.64359 | val_0_mse: 0.84585 |  0:00:04s\n",
      "epoch 14 | loss: 0.58547 | val_0_mse: 0.92064 |  0:00:04s\n",
      "epoch 15 | loss: 0.56427 | val_0_mse: 0.76481 |  0:00:05s\n",
      "epoch 16 | loss: 0.57292 | val_0_mse: 0.78704 |  0:00:05s\n",
      "epoch 17 | loss: 0.56338 | val_0_mse: 0.77159 |  0:00:05s\n",
      "epoch 18 | loss: 0.56764 | val_0_mse: 0.78425 |  0:00:05s\n",
      "epoch 19 | loss: 0.57229 | val_0_mse: 0.74204 |  0:00:06s\n",
      "epoch 20 | loss: 0.56164 | val_0_mse: 0.78792 |  0:00:06s\n",
      "epoch 21 | loss: 0.54985 | val_0_mse: 0.75096 |  0:00:06s\n",
      "epoch 22 | loss: 0.54956 | val_0_mse: 0.79618 |  0:00:07s\n",
      "epoch 23 | loss: 0.54126 | val_0_mse: 0.80875 |  0:00:07s\n",
      "epoch 24 | loss: 0.55273 | val_0_mse: 0.68571 |  0:00:07s\n",
      "epoch 25 | loss: 0.56844 | val_0_mse: 0.80061 |  0:00:08s\n",
      "epoch 26 | loss: 0.55442 | val_0_mse: 0.69722 |  0:00:08s\n",
      "epoch 27 | loss: 0.56236 | val_0_mse: 0.74372 |  0:00:08s\n",
      "epoch 28 | loss: 0.58218 | val_0_mse: 0.67251 |  0:00:09s\n",
      "epoch 29 | loss: 0.54608 | val_0_mse: 0.72149 |  0:00:09s\n",
      "epoch 30 | loss: 0.52102 | val_0_mse: 0.73245 |  0:00:09s\n",
      "epoch 31 | loss: 0.52004 | val_0_mse: 0.70461 |  0:00:10s\n",
      "epoch 32 | loss: 0.52722 | val_0_mse: 0.67344 |  0:00:10s\n",
      "epoch 33 | loss: 0.54094 | val_0_mse: 0.66656 |  0:00:10s\n",
      "epoch 34 | loss: 0.55119 | val_0_mse: 0.6958  |  0:00:11s\n",
      "epoch 35 | loss: 0.53056 | val_0_mse: 0.64258 |  0:00:11s\n",
      "epoch 36 | loss: 0.53426 | val_0_mse: 0.66376 |  0:00:11s\n",
      "epoch 37 | loss: 0.53964 | val_0_mse: 0.62456 |  0:00:12s\n",
      "epoch 38 | loss: 0.55485 | val_0_mse: 0.6038  |  0:00:12s\n",
      "epoch 39 | loss: 0.51707 | val_0_mse: 0.57648 |  0:00:12s\n",
      "epoch 40 | loss: 0.51347 | val_0_mse: 0.59096 |  0:00:13s\n",
      "epoch 41 | loss: 0.50958 | val_0_mse: 0.61126 |  0:00:13s\n",
      "epoch 42 | loss: 0.50274 | val_0_mse: 0.64269 |  0:00:13s\n",
      "epoch 43 | loss: 0.51622 | val_0_mse: 0.62879 |  0:00:14s\n",
      "epoch 44 | loss: 0.51811 | val_0_mse: 0.71949 |  0:00:14s\n",
      "epoch 45 | loss: 0.66463 | val_0_mse: 0.64895 |  0:00:14s\n",
      "epoch 46 | loss: 0.53214 | val_0_mse: 0.60179 |  0:00:14s\n",
      "epoch 47 | loss: 0.50419 | val_0_mse: 0.60587 |  0:00:15s\n",
      "epoch 48 | loss: 0.5101  | val_0_mse: 0.61868 |  0:00:15s\n",
      "epoch 49 | loss: 0.51244 | val_0_mse: 0.65928 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 0.57648\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3761... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77864</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">skilled-sweep-7</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/23j79lda\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/23j79lda</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044320-23j79lda/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: basyas34 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.19588894537768375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/basyas34\" target=\"_blank\">driven-sweep-8</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.097   | val_0_mse: 3.12216 |  0:00:00s\n",
      "epoch 1  | loss: 2.594   | val_0_mse: 2.13854 |  0:00:00s\n",
      "epoch 2  | loss: 1.72786 | val_0_mse: 2.16063 |  0:00:00s\n",
      "epoch 3  | loss: 1.2737  | val_0_mse: 1.30364 |  0:00:01s\n",
      "epoch 4  | loss: 0.99611 | val_0_mse: 1.43766 |  0:00:01s\n",
      "epoch 5  | loss: 0.81166 | val_0_mse: 0.90757 |  0:00:01s\n",
      "epoch 6  | loss: 0.73527 | val_0_mse: 1.10348 |  0:00:02s\n",
      "epoch 7  | loss: 0.67582 | val_0_mse: 0.93879 |  0:00:02s\n",
      "epoch 8  | loss: 0.69659 | val_0_mse: 0.82148 |  0:00:02s\n",
      "epoch 9  | loss: 0.64955 | val_0_mse: 0.84597 |  0:00:03s\n",
      "epoch 10 | loss: 0.58953 | val_0_mse: 0.91463 |  0:00:03s\n",
      "epoch 11 | loss: 0.59029 | val_0_mse: 0.95258 |  0:00:03s\n",
      "epoch 12 | loss: 0.5891  | val_0_mse: 0.82005 |  0:00:04s\n",
      "epoch 13 | loss: 0.652   | val_0_mse: 1.02935 |  0:00:04s\n",
      "epoch 14 | loss: 0.68604 | val_0_mse: 0.70475 |  0:00:04s\n",
      "epoch 15 | loss: 0.67993 | val_0_mse: 0.8455  |  0:00:04s\n",
      "epoch 16 | loss: 0.5769  | val_0_mse: 0.7718  |  0:00:05s\n",
      "epoch 17 | loss: 0.60898 | val_0_mse: 0.90455 |  0:00:05s\n",
      "epoch 18 | loss: 0.60583 | val_0_mse: 0.75502 |  0:00:05s\n",
      "epoch 19 | loss: 0.68027 | val_0_mse: 0.85148 |  0:00:06s\n",
      "epoch 20 | loss: 0.69618 | val_0_mse: 0.97518 |  0:00:06s\n",
      "epoch 21 | loss: 0.58546 | val_0_mse: 0.77071 |  0:00:06s\n",
      "epoch 22 | loss: 0.58627 | val_0_mse: 0.85342 |  0:00:07s\n",
      "epoch 23 | loss: 0.57498 | val_0_mse: 0.76488 |  0:00:07s\n",
      "epoch 24 | loss: 0.60987 | val_0_mse: 0.83388 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_mse = 0.70475\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3851... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.75857</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">driven-sweep-8</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/basyas34\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/basyas34</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044343-basyas34/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xsn3q4nk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1798960687535672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/xsn3q4nk\" target=\"_blank\">crimson-sweep-9</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 8.85136 | val_0_mse: 2.97658 |  0:00:00s\n",
      "epoch 1  | loss: 2.40579 | val_0_mse: 2.34661 |  0:00:00s\n",
      "epoch 2  | loss: 1.51595 | val_0_mse: 1.24496 |  0:00:00s\n",
      "epoch 3  | loss: 1.40859 | val_0_mse: 1.22314 |  0:00:00s\n",
      "epoch 4  | loss: 1.04514 | val_0_mse: 0.9754  |  0:00:01s\n",
      "epoch 5  | loss: 0.85431 | val_0_mse: 1.00666 |  0:00:01s\n",
      "epoch 6  | loss: 0.73443 | val_0_mse: 0.94329 |  0:00:01s\n",
      "epoch 7  | loss: 0.7021  | val_0_mse: 0.9178  |  0:00:01s\n",
      "epoch 8  | loss: 0.6604  | val_0_mse: 0.81845 |  0:00:01s\n",
      "epoch 9  | loss: 0.84966 | val_0_mse: 1.09719 |  0:00:02s\n",
      "epoch 10 | loss: 0.81463 | val_0_mse: 0.96081 |  0:00:02s\n",
      "epoch 11 | loss: 0.88363 | val_0_mse: 1.00044 |  0:00:02s\n",
      "epoch 12 | loss: 0.84116 | val_0_mse: 0.96365 |  0:00:02s\n",
      "epoch 13 | loss: 0.72433 | val_0_mse: 0.89824 |  0:00:02s\n",
      "epoch 14 | loss: 0.67973 | val_0_mse: 0.80507 |  0:00:03s\n",
      "epoch 15 | loss: 0.59724 | val_0_mse: 0.90308 |  0:00:03s\n",
      "epoch 16 | loss: 0.59637 | val_0_mse: 0.76482 |  0:00:03s\n",
      "epoch 17 | loss: 0.56665 | val_0_mse: 0.85422 |  0:00:03s\n",
      "epoch 18 | loss: 0.53971 | val_0_mse: 0.8318  |  0:00:03s\n",
      "epoch 19 | loss: 0.55232 | val_0_mse: 0.77469 |  0:00:04s\n",
      "epoch 20 | loss: 0.54478 | val_0_mse: 0.85578 |  0:00:04s\n",
      "epoch 21 | loss: 0.54077 | val_0_mse: 0.71279 |  0:00:04s\n",
      "epoch 22 | loss: 0.55311 | val_0_mse: 0.72638 |  0:00:04s\n",
      "epoch 23 | loss: 0.53505 | val_0_mse: 0.79622 |  0:00:04s\n",
      "epoch 24 | loss: 0.54312 | val_0_mse: 0.7786  |  0:00:05s\n",
      "epoch 25 | loss: 0.53201 | val_0_mse: 0.70855 |  0:00:05s\n",
      "epoch 26 | loss: 0.51578 | val_0_mse: 0.71274 |  0:00:05s\n",
      "epoch 27 | loss: 0.51143 | val_0_mse: 0.73373 |  0:00:05s\n",
      "epoch 28 | loss: 0.51312 | val_0_mse: 0.73539 |  0:00:05s\n",
      "epoch 29 | loss: 0.5113  | val_0_mse: 0.65034 |  0:00:06s\n",
      "epoch 30 | loss: 0.50726 | val_0_mse: 0.63744 |  0:00:06s\n",
      "epoch 31 | loss: 0.50751 | val_0_mse: 0.7481  |  0:00:06s\n",
      "epoch 32 | loss: 0.56667 | val_0_mse: 0.63659 |  0:00:06s\n",
      "epoch 33 | loss: 0.73356 | val_0_mse: 0.67647 |  0:00:07s\n",
      "epoch 34 | loss: 0.54186 | val_0_mse: 0.78426 |  0:00:07s\n",
      "epoch 35 | loss: 0.53345 | val_0_mse: 0.6097  |  0:00:07s\n",
      "epoch 36 | loss: 0.50844 | val_0_mse: 0.63402 |  0:00:07s\n",
      "epoch 37 | loss: 0.50445 | val_0_mse: 0.67653 |  0:00:07s\n",
      "epoch 38 | loss: 0.50689 | val_0_mse: 0.61604 |  0:00:08s\n",
      "epoch 39 | loss: 0.4954  | val_0_mse: 0.6027  |  0:00:08s\n",
      "epoch 40 | loss: 0.49894 | val_0_mse: 0.59157 |  0:00:08s\n",
      "epoch 41 | loss: 0.50513 | val_0_mse: 0.65484 |  0:00:08s\n",
      "epoch 42 | loss: 0.51468 | val_0_mse: 0.61259 |  0:00:08s\n",
      "epoch 43 | loss: 0.49821 | val_0_mse: 0.58357 |  0:00:09s\n",
      "epoch 44 | loss: 0.49422 | val_0_mse: 0.63817 |  0:00:09s\n",
      "epoch 45 | loss: 0.49837 | val_0_mse: 0.63711 |  0:00:09s\n",
      "epoch 46 | loss: 0.48909 | val_0_mse: 0.59099 |  0:00:09s\n",
      "epoch 47 | loss: 0.49206 | val_0_mse: 0.5858  |  0:00:09s\n",
      "epoch 48 | loss: 0.49094 | val_0_mse: 0.58598 |  0:00:10s\n",
      "epoch 49 | loss: 0.49446 | val_0_mse: 0.60418 |  0:00:10s\n",
      "epoch 50 | loss: 0.50457 | val_0_mse: 0.58822 |  0:00:10s\n",
      "epoch 51 | loss: 0.48783 | val_0_mse: 0.59195 |  0:00:10s\n",
      "epoch 52 | loss: 0.51156 | val_0_mse: 0.56882 |  0:00:10s\n",
      "epoch 53 | loss: 0.49245 | val_0_mse: 0.59101 |  0:00:11s\n",
      "epoch 54 | loss: 0.48561 | val_0_mse: 0.56021 |  0:00:11s\n",
      "epoch 55 | loss: 0.49191 | val_0_mse: 0.59512 |  0:00:11s\n",
      "epoch 56 | loss: 0.4853  | val_0_mse: 0.55576 |  0:00:11s\n",
      "epoch 57 | loss: 0.48213 | val_0_mse: 0.57934 |  0:00:11s\n",
      "epoch 58 | loss: 0.48335 | val_0_mse: 0.54657 |  0:00:12s\n",
      "epoch 59 | loss: 0.49299 | val_0_mse: 0.54602 |  0:00:12s\n",
      "epoch 60 | loss: 0.4745  | val_0_mse: 0.55524 |  0:00:12s\n",
      "epoch 61 | loss: 0.48839 | val_0_mse: 0.57693 |  0:00:12s\n",
      "epoch 62 | loss: 0.53653 | val_0_mse: 0.55177 |  0:00:13s\n",
      "epoch 63 | loss: 0.47484 | val_0_mse: 0.54914 |  0:00:13s\n",
      "epoch 64 | loss: 0.47231 | val_0_mse: 0.56534 |  0:00:13s\n",
      "epoch 65 | loss: 0.50749 | val_0_mse: 0.5869  |  0:00:13s\n",
      "epoch 66 | loss: 0.50349 | val_0_mse: 0.54251 |  0:00:13s\n",
      "epoch 67 | loss: 0.50388 | val_0_mse: 0.53641 |  0:00:14s\n",
      "epoch 68 | loss: 0.48863 | val_0_mse: 0.52504 |  0:00:14s\n",
      "epoch 69 | loss: 0.48376 | val_0_mse: 0.57179 |  0:00:14s\n",
      "epoch 70 | loss: 0.50052 | val_0_mse: 0.5487  |  0:00:14s\n",
      "epoch 71 | loss: 0.51063 | val_0_mse: 0.56146 |  0:00:14s\n",
      "epoch 72 | loss: 0.55187 | val_0_mse: 0.53498 |  0:00:15s\n",
      "epoch 73 | loss: 0.49427 | val_0_mse: 0.5605  |  0:00:15s\n",
      "epoch 74 | loss: 0.51763 | val_0_mse: 0.55385 |  0:00:15s\n",
      "epoch 75 | loss: 0.60057 | val_0_mse: 0.53305 |  0:00:15s\n",
      "epoch 76 | loss: 0.52285 | val_0_mse: 0.58509 |  0:00:15s\n",
      "epoch 77 | loss: 0.51224 | val_0_mse: 0.55165 |  0:00:16s\n",
      "epoch 78 | loss: 0.51509 | val_0_mse: 0.58448 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.52504\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3911... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78087</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">crimson-sweep-9</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/xsn3q4nk\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/xsn3q4nk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044356-xsn3q4nk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fcvnfxkp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1815195900164855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/fcvnfxkp\" target=\"_blank\">radiant-sweep-10</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.85786 | val_0_mse: 2.95413 |  0:00:00s\n",
      "epoch 1  | loss: 1.54215 | val_0_mse: 1.51175 |  0:00:00s\n",
      "epoch 2  | loss: 1.08013 | val_0_mse: 1.08933 |  0:00:00s\n",
      "epoch 3  | loss: 0.73981 | val_0_mse: 1.1431  |  0:00:00s\n",
      "epoch 4  | loss: 0.68048 | val_0_mse: 1.05428 |  0:00:01s\n",
      "epoch 5  | loss: 0.63171 | val_0_mse: 0.88924 |  0:00:01s\n",
      "epoch 6  | loss: 0.6168  | val_0_mse: 1.01237 |  0:00:01s\n",
      "epoch 7  | loss: 0.58415 | val_0_mse: 0.99244 |  0:00:01s\n",
      "epoch 8  | loss: 0.57732 | val_0_mse: 0.94537 |  0:00:01s\n",
      "epoch 9  | loss: 0.585   | val_0_mse: 0.94899 |  0:00:02s\n",
      "epoch 10 | loss: 0.55649 | val_0_mse: 0.89149 |  0:00:02s\n",
      "epoch 11 | loss: 0.54663 | val_0_mse: 0.8886  |  0:00:02s\n",
      "epoch 12 | loss: 0.54643 | val_0_mse: 0.82815 |  0:00:02s\n",
      "epoch 13 | loss: 0.51672 | val_0_mse: 0.80177 |  0:00:02s\n",
      "epoch 14 | loss: 0.50989 | val_0_mse: 0.71646 |  0:00:03s\n",
      "epoch 15 | loss: 0.51571 | val_0_mse: 0.75872 |  0:00:03s\n",
      "epoch 16 | loss: 0.51687 | val_0_mse: 0.86479 |  0:00:03s\n",
      "epoch 17 | loss: 0.52544 | val_0_mse: 0.72051 |  0:00:03s\n",
      "epoch 18 | loss: 0.52406 | val_0_mse: 0.81041 |  0:00:03s\n",
      "epoch 19 | loss: 0.51903 | val_0_mse: 0.67959 |  0:00:04s\n",
      "epoch 20 | loss: 0.55033 | val_0_mse: 0.79293 |  0:00:04s\n",
      "epoch 21 | loss: 0.56619 | val_0_mse: 0.69748 |  0:00:04s\n",
      "epoch 22 | loss: 0.58939 | val_0_mse: 0.83377 |  0:00:04s\n",
      "epoch 23 | loss: 0.56519 | val_0_mse: 0.6969  |  0:00:04s\n",
      "epoch 24 | loss: 0.58013 | val_0_mse: 0.72317 |  0:00:05s\n",
      "epoch 25 | loss: 0.52721 | val_0_mse: 0.68609 |  0:00:05s\n",
      "epoch 26 | loss: 0.52958 | val_0_mse: 0.78181 |  0:00:05s\n",
      "epoch 27 | loss: 0.53304 | val_0_mse: 0.64935 |  0:00:05s\n",
      "epoch 28 | loss: 0.55277 | val_0_mse: 0.72437 |  0:00:06s\n",
      "epoch 29 | loss: 0.55737 | val_0_mse: 0.59556 |  0:00:06s\n",
      "epoch 30 | loss: 0.53595 | val_0_mse: 0.72544 |  0:00:06s\n",
      "epoch 31 | loss: 0.54041 | val_0_mse: 0.67339 |  0:00:06s\n",
      "epoch 32 | loss: 0.51265 | val_0_mse: 0.70641 |  0:00:06s\n",
      "epoch 33 | loss: 0.51778 | val_0_mse: 0.62494 |  0:00:07s\n",
      "epoch 34 | loss: 0.55366 | val_0_mse: 0.71524 |  0:00:07s\n",
      "epoch 35 | loss: 0.55627 | val_0_mse: 0.68492 |  0:00:07s\n",
      "epoch 36 | loss: 0.52048 | val_0_mse: 0.65243 |  0:00:07s\n",
      "epoch 37 | loss: 0.52079 | val_0_mse: 0.62699 |  0:00:07s\n",
      "epoch 38 | loss: 0.5243  | val_0_mse: 0.70846 |  0:00:08s\n",
      "epoch 39 | loss: 0.52395 | val_0_mse: 0.61561 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_mse = 0.59556\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3958... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76763</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">radiant-sweep-10</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/fcvnfxkp\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/fcvnfxkp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044418-fcvnfxkp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1oaaus95 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.12553698733769603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1oaaus95\" target=\"_blank\">glamorous-sweep-11</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 32.68093| val_0_mse: 3.65489 |  0:00:00s\n",
      "epoch 1  | loss: 4.28212 | val_0_mse: 1.92931 |  0:00:00s\n",
      "epoch 2  | loss: 3.27995 | val_0_mse: 1.35481 |  0:00:00s\n",
      "epoch 3  | loss: 1.94286 | val_0_mse: 1.15264 |  0:00:01s\n",
      "epoch 4  | loss: 1.22382 | val_0_mse: 1.0745  |  0:00:01s\n",
      "epoch 5  | loss: 1.16666 | val_0_mse: 1.04181 |  0:00:01s\n",
      "epoch 6  | loss: 1.12481 | val_0_mse: 1.00187 |  0:00:01s\n",
      "epoch 7  | loss: 1.01298 | val_0_mse: 1.01727 |  0:00:02s\n",
      "epoch 8  | loss: 0.80744 | val_0_mse: 1.04035 |  0:00:02s\n",
      "epoch 9  | loss: 0.73211 | val_0_mse: 1.03585 |  0:00:02s\n",
      "epoch 10 | loss: 0.70012 | val_0_mse: 1.02832 |  0:00:03s\n",
      "epoch 11 | loss: 0.7041  | val_0_mse: 0.9931  |  0:00:03s\n",
      "epoch 12 | loss: 0.63853 | val_0_mse: 0.99317 |  0:00:03s\n",
      "epoch 13 | loss: 0.68056 | val_0_mse: 1.04185 |  0:00:03s\n",
      "epoch 14 | loss: 0.62059 | val_0_mse: 1.07289 |  0:00:04s\n",
      "epoch 15 | loss: 0.59888 | val_0_mse: 1.02024 |  0:00:04s\n",
      "epoch 16 | loss: 0.63817 | val_0_mse: 0.86383 |  0:00:04s\n",
      "epoch 17 | loss: 0.56686 | val_0_mse: 0.99279 |  0:00:05s\n",
      "epoch 18 | loss: 0.58334 | val_0_mse: 0.79595 |  0:00:05s\n",
      "epoch 19 | loss: 0.57925 | val_0_mse: 0.85592 |  0:00:05s\n",
      "epoch 20 | loss: 0.57001 | val_0_mse: 0.88551 |  0:00:05s\n",
      "epoch 21 | loss: 0.55482 | val_0_mse: 0.84638 |  0:00:06s\n",
      "epoch 22 | loss: 0.55291 | val_0_mse: 0.93553 |  0:00:06s\n",
      "epoch 23 | loss: 0.57471 | val_0_mse: 0.83182 |  0:00:06s\n",
      "epoch 24 | loss: 0.54861 | val_0_mse: 0.77588 |  0:00:06s\n",
      "epoch 25 | loss: 0.534   | val_0_mse: 0.79572 |  0:00:07s\n",
      "epoch 26 | loss: 0.54275 | val_0_mse: 0.80832 |  0:00:07s\n",
      "epoch 27 | loss: 0.52988 | val_0_mse: 0.79315 |  0:00:07s\n",
      "epoch 28 | loss: 0.5325  | val_0_mse: 0.90217 |  0:00:08s\n",
      "epoch 29 | loss: 0.53946 | val_0_mse: 0.85389 |  0:00:08s\n",
      "epoch 30 | loss: 0.52793 | val_0_mse: 0.76908 |  0:00:08s\n",
      "epoch 31 | loss: 0.54513 | val_0_mse: 0.75089 |  0:00:08s\n",
      "epoch 32 | loss: 0.52312 | val_0_mse: 0.91468 |  0:00:09s\n",
      "epoch 33 | loss: 0.59553 | val_0_mse: 0.74668 |  0:00:09s\n",
      "epoch 34 | loss: 0.6147  | val_0_mse: 0.8756  |  0:00:09s\n",
      "epoch 35 | loss: 0.69779 | val_0_mse: 0.70768 |  0:00:10s\n",
      "epoch 36 | loss: 0.56788 | val_0_mse: 0.83325 |  0:00:10s\n",
      "epoch 37 | loss: 0.57891 | val_0_mse: 0.70826 |  0:00:10s\n",
      "epoch 38 | loss: 0.55855 | val_0_mse: 0.75466 |  0:00:10s\n",
      "epoch 39 | loss: 0.60163 | val_0_mse: 0.65616 |  0:00:11s\n",
      "epoch 40 | loss: 0.50484 | val_0_mse: 0.71632 |  0:00:11s\n",
      "epoch 41 | loss: 0.51458 | val_0_mse: 0.64845 |  0:00:11s\n",
      "epoch 42 | loss: 0.51233 | val_0_mse: 0.68581 |  0:00:11s\n",
      "epoch 43 | loss: 0.50417 | val_0_mse: 0.67396 |  0:00:12s\n",
      "epoch 44 | loss: 0.49826 | val_0_mse: 0.63056 |  0:00:12s\n",
      "epoch 45 | loss: 0.50735 | val_0_mse: 0.62099 |  0:00:12s\n",
      "epoch 46 | loss: 0.48882 | val_0_mse: 0.65281 |  0:00:13s\n",
      "epoch 47 | loss: 0.50654 | val_0_mse: 0.62905 |  0:00:13s\n",
      "epoch 48 | loss: 0.5049  | val_0_mse: 0.65882 |  0:00:13s\n",
      "epoch 49 | loss: 0.51517 | val_0_mse: 0.62052 |  0:00:13s\n",
      "epoch 50 | loss: 0.50062 | val_0_mse: 0.61234 |  0:00:14s\n",
      "epoch 51 | loss: 0.5156  | val_0_mse: 0.64362 |  0:00:14s\n",
      "epoch 52 | loss: 0.50374 | val_0_mse: 0.60295 |  0:00:14s\n",
      "epoch 53 | loss: 0.50456 | val_0_mse: 0.60774 |  0:00:14s\n",
      "epoch 54 | loss: 0.5062  | val_0_mse: 0.61915 |  0:00:15s\n",
      "epoch 55 | loss: 0.50656 | val_0_mse: 0.64444 |  0:00:15s\n",
      "epoch 56 | loss: 0.51869 | val_0_mse: 0.58314 |  0:00:15s\n",
      "epoch 57 | loss: 0.51281 | val_0_mse: 0.59106 |  0:00:16s\n",
      "epoch 58 | loss: 0.51087 | val_0_mse: 0.59663 |  0:00:16s\n",
      "epoch 59 | loss: 0.49933 | val_0_mse: 0.60195 |  0:00:16s\n",
      "epoch 60 | loss: 0.49969 | val_0_mse: 0.58709 |  0:00:16s\n",
      "epoch 61 | loss: 0.53156 | val_0_mse: 0.62118 |  0:00:17s\n",
      "epoch 62 | loss: 0.54006 | val_0_mse: 0.59086 |  0:00:17s\n",
      "epoch 63 | loss: 0.54628 | val_0_mse: 0.70093 |  0:00:17s\n",
      "epoch 64 | loss: 0.54237 | val_0_mse: 0.58633 |  0:00:17s\n",
      "epoch 65 | loss: 0.51444 | val_0_mse: 0.68184 |  0:00:18s\n",
      "epoch 66 | loss: 0.62961 | val_0_mse: 0.56985 |  0:00:18s\n",
      "epoch 67 | loss: 0.58608 | val_0_mse: 0.58122 |  0:00:18s\n",
      "epoch 68 | loss: 0.55049 | val_0_mse: 0.5669  |  0:00:19s\n",
      "epoch 69 | loss: 0.56438 | val_0_mse: 0.58533 |  0:00:19s\n",
      "epoch 70 | loss: 0.55707 | val_0_mse: 0.56845 |  0:00:19s\n",
      "epoch 71 | loss: 0.51386 | val_0_mse: 0.62969 |  0:00:19s\n",
      "epoch 72 | loss: 0.53299 | val_0_mse: 0.57875 |  0:00:20s\n",
      "epoch 73 | loss: 0.51088 | val_0_mse: 0.58097 |  0:00:20s\n",
      "epoch 74 | loss: 0.50246 | val_0_mse: 0.55872 |  0:00:20s\n",
      "epoch 75 | loss: 0.49035 | val_0_mse: 0.56615 |  0:00:21s\n",
      "epoch 76 | loss: 0.52166 | val_0_mse: 0.62987 |  0:00:21s\n",
      "epoch 77 | loss: 0.66359 | val_0_mse: 0.66371 |  0:00:21s\n",
      "epoch 78 | loss: 0.53047 | val_0_mse: 0.63421 |  0:00:21s\n",
      "epoch 79 | loss: 0.60026 | val_0_mse: 0.58822 |  0:00:22s\n",
      "epoch 80 | loss: 0.51523 | val_0_mse: 0.57302 |  0:00:22s\n",
      "epoch 81 | loss: 0.50948 | val_0_mse: 0.64408 |  0:00:22s\n",
      "epoch 82 | loss: 0.54703 | val_0_mse: 0.5988  |  0:00:22s\n",
      "epoch 83 | loss: 0.5129  | val_0_mse: 0.61352 |  0:00:23s\n",
      "epoch 84 | loss: 0.53846 | val_0_mse: 0.56032 |  0:00:23s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.55872\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4010... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76689</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glamorous-sweep-11</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1oaaus95\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/1oaaus95</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044432-1oaaus95/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6i3ibxet with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.21918597199769063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/6i3ibxet\" target=\"_blank\">autumn-sweep-12</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 21.15829| val_0_mse: 10.00679|  0:00:00s\n",
      "epoch 1  | loss: 6.39968 | val_0_mse: 5.84019 |  0:00:00s\n",
      "epoch 2  | loss: 1.93537 | val_0_mse: 2.27708 |  0:00:00s\n",
      "epoch 3  | loss: 1.09209 | val_0_mse: 1.51055 |  0:00:01s\n",
      "epoch 4  | loss: 0.7651  | val_0_mse: 0.98006 |  0:00:01s\n",
      "epoch 5  | loss: 0.73356 | val_0_mse: 1.03704 |  0:00:01s\n",
      "epoch 6  | loss: 0.63478 | val_0_mse: 1.03177 |  0:00:02s\n",
      "epoch 7  | loss: 0.63175 | val_0_mse: 0.80025 |  0:00:02s\n",
      "epoch 8  | loss: 0.62592 | val_0_mse: 0.95023 |  0:00:02s\n",
      "epoch 9  | loss: 0.59565 | val_0_mse: 0.82808 |  0:00:03s\n",
      "epoch 10 | loss: 0.59206 | val_0_mse: 1.14787 |  0:00:03s\n",
      "epoch 11 | loss: 0.62754 | val_0_mse: 0.7575  |  0:00:03s\n",
      "epoch 12 | loss: 0.60954 | val_0_mse: 0.99761 |  0:00:04s\n",
      "epoch 13 | loss: 0.62227 | val_0_mse: 0.76987 |  0:00:04s\n",
      "epoch 14 | loss: 0.57582 | val_0_mse: 0.92119 |  0:00:04s\n",
      "epoch 15 | loss: 0.54423 | val_0_mse: 0.83418 |  0:00:05s\n",
      "epoch 16 | loss: 0.5466  | val_0_mse: 0.84616 |  0:00:05s\n",
      "epoch 17 | loss: 0.53881 | val_0_mse: 0.79753 |  0:00:05s\n",
      "epoch 18 | loss: 0.51879 | val_0_mse: 0.74309 |  0:00:06s\n",
      "epoch 19 | loss: 0.5157  | val_0_mse: 0.86958 |  0:00:06s\n",
      "epoch 20 | loss: 0.55814 | val_0_mse: 0.72625 |  0:00:06s\n",
      "epoch 21 | loss: 0.52311 | val_0_mse: 0.72113 |  0:00:06s\n",
      "epoch 22 | loss: 0.54476 | val_0_mse: 0.93382 |  0:00:07s\n",
      "epoch 23 | loss: 0.58034 | val_0_mse: 0.77676 |  0:00:07s\n",
      "epoch 24 | loss: 0.586   | val_0_mse: 0.8343  |  0:00:07s\n",
      "epoch 25 | loss: 0.63809 | val_0_mse: 0.72554 |  0:00:08s\n",
      "epoch 26 | loss: 0.56891 | val_0_mse: 0.63386 |  0:00:08s\n",
      "epoch 27 | loss: 0.552   | val_0_mse: 0.71781 |  0:00:08s\n",
      "epoch 28 | loss: 0.53003 | val_0_mse: 0.66427 |  0:00:09s\n",
      "epoch 29 | loss: 0.50687 | val_0_mse: 0.68556 |  0:00:09s\n",
      "epoch 30 | loss: 0.51943 | val_0_mse: 0.66389 |  0:00:09s\n",
      "epoch 31 | loss: 0.51515 | val_0_mse: 0.74974 |  0:00:10s\n",
      "epoch 32 | loss: 0.52993 | val_0_mse: 0.6856  |  0:00:10s\n",
      "epoch 33 | loss: 0.51369 | val_0_mse: 0.67504 |  0:00:10s\n",
      "epoch 34 | loss: 0.51744 | val_0_mse: 0.69053 |  0:00:11s\n",
      "epoch 35 | loss: 0.52677 | val_0_mse: 0.68477 |  0:00:11s\n",
      "epoch 36 | loss: 0.49799 | val_0_mse: 0.69194 |  0:00:11s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_mse = 0.63386\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4087... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76968</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">autumn-sweep-12</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/6i3ibxet\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/6i3ibxet</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044502-6i3ibxet/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 822j3efn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.08806862747575044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/822j3efn\" target=\"_blank\">solar-sweep-13</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.91083 | val_0_mse: 3.06092 |  0:00:00s\n",
      "epoch 1  | loss: 1.32839 | val_0_mse: 1.3679  |  0:00:00s\n",
      "epoch 2  | loss: 1.06306 | val_0_mse: 1.14148 |  0:00:01s\n",
      "epoch 3  | loss: 0.83914 | val_0_mse: 0.7589  |  0:00:01s\n",
      "epoch 4  | loss: 0.79839 | val_0_mse: 1.15434 |  0:00:01s\n",
      "epoch 5  | loss: 0.71538 | val_0_mse: 1.23124 |  0:00:02s\n",
      "epoch 6  | loss: 0.68132 | val_0_mse: 1.11544 |  0:00:02s\n",
      "epoch 7  | loss: 0.68848 | val_0_mse: 0.95314 |  0:00:02s\n",
      "epoch 8  | loss: 0.70293 | val_0_mse: 1.10231 |  0:00:03s\n",
      "epoch 9  | loss: 0.62426 | val_0_mse: 0.87982 |  0:00:03s\n",
      "epoch 10 | loss: 0.71253 | val_0_mse: 1.32251 |  0:00:04s\n",
      "epoch 11 | loss: 0.73978 | val_0_mse: 0.87138 |  0:00:04s\n",
      "epoch 12 | loss: 0.66246 | val_0_mse: 0.7999  |  0:00:04s\n",
      "epoch 13 | loss: 0.57553 | val_0_mse: 0.8552  |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_mse = 0.7589\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4133... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.75584</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">solar-sweep-13</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/822j3efn\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/822j3efn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044519-822j3efn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zemd6r8q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0914193020316306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/zemd6r8q\" target=\"_blank\">lively-sweep-14</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 10.79756| val_0_mse: 1.89516 |  0:00:00s\n",
      "epoch 1  | loss: 2.7711  | val_0_mse: 1.54703 |  0:00:00s\n",
      "epoch 2  | loss: 1.62006 | val_0_mse: 1.60937 |  0:00:00s\n",
      "epoch 3  | loss: 1.11952 | val_0_mse: 1.34646 |  0:00:00s\n",
      "epoch 4  | loss: 0.98989 | val_0_mse: 1.18206 |  0:00:00s\n",
      "epoch 5  | loss: 0.80315 | val_0_mse: 1.27773 |  0:00:00s\n",
      "epoch 6  | loss: 0.76287 | val_0_mse: 1.39998 |  0:00:01s\n",
      "epoch 7  | loss: 0.72272 | val_0_mse: 1.20133 |  0:00:01s\n",
      "epoch 8  | loss: 0.71203 | val_0_mse: 1.01932 |  0:00:01s\n",
      "epoch 9  | loss: 0.72232 | val_0_mse: 0.97191 |  0:00:01s\n",
      "epoch 10 | loss: 0.70207 | val_0_mse: 1.30152 |  0:00:01s\n",
      "epoch 11 | loss: 0.70693 | val_0_mse: 0.89147 |  0:00:01s\n",
      "epoch 12 | loss: 0.81623 | val_0_mse: 1.00192 |  0:00:02s\n",
      "epoch 13 | loss: 0.74955 | val_0_mse: 1.02869 |  0:00:02s\n",
      "epoch 14 | loss: 0.61588 | val_0_mse: 0.95944 |  0:00:02s\n",
      "epoch 15 | loss: 0.62121 | val_0_mse: 0.95102 |  0:00:02s\n",
      "epoch 16 | loss: 0.60294 | val_0_mse: 1.08394 |  0:00:02s\n",
      "epoch 17 | loss: 0.61077 | val_0_mse: 0.88256 |  0:00:02s\n",
      "epoch 18 | loss: 0.59447 | val_0_mse: 0.90654 |  0:00:03s\n",
      "epoch 19 | loss: 0.6279  | val_0_mse: 0.78974 |  0:00:03s\n",
      "epoch 20 | loss: 0.68525 | val_0_mse: 0.92781 |  0:00:03s\n",
      "epoch 21 | loss: 0.58181 | val_0_mse: 0.85565 |  0:00:03s\n",
      "epoch 22 | loss: 0.56213 | val_0_mse: 0.78114 |  0:00:03s\n",
      "epoch 23 | loss: 0.52963 | val_0_mse: 0.74957 |  0:00:03s\n",
      "epoch 24 | loss: 0.5439  | val_0_mse: 0.80702 |  0:00:04s\n",
      "epoch 25 | loss: 0.55853 | val_0_mse: 0.7443  |  0:00:04s\n",
      "epoch 26 | loss: 0.54316 | val_0_mse: 0.74811 |  0:00:04s\n",
      "epoch 27 | loss: 0.55662 | val_0_mse: 0.77555 |  0:00:04s\n",
      "epoch 28 | loss: 0.53121 | val_0_mse: 0.72873 |  0:00:04s\n",
      "epoch 29 | loss: 0.52032 | val_0_mse: 0.81641 |  0:00:04s\n",
      "epoch 30 | loss: 0.53047 | val_0_mse: 0.71267 |  0:00:04s\n",
      "epoch 31 | loss: 0.51013 | val_0_mse: 0.68177 |  0:00:05s\n",
      "epoch 32 | loss: 0.51981 | val_0_mse: 0.69802 |  0:00:05s\n",
      "epoch 33 | loss: 0.51071 | val_0_mse: 0.78265 |  0:00:05s\n",
      "epoch 34 | loss: 0.54127 | val_0_mse: 0.71879 |  0:00:05s\n",
      "epoch 35 | loss: 0.54162 | val_0_mse: 0.7879  |  0:00:05s\n",
      "epoch 36 | loss: 0.51168 | val_0_mse: 0.71561 |  0:00:05s\n",
      "epoch 37 | loss: 0.5046  | val_0_mse: 0.68179 |  0:00:06s\n",
      "epoch 38 | loss: 0.51754 | val_0_mse: 0.73819 |  0:00:06s\n",
      "epoch 39 | loss: 0.52405 | val_0_mse: 0.6846  |  0:00:06s\n",
      "epoch 40 | loss: 0.51651 | val_0_mse: 0.64384 |  0:00:06s\n",
      "epoch 41 | loss: 0.50709 | val_0_mse: 0.66939 |  0:00:06s\n",
      "epoch 42 | loss: 0.50799 | val_0_mse: 0.63255 |  0:00:06s\n",
      "epoch 43 | loss: 0.52346 | val_0_mse: 0.7398  |  0:00:07s\n",
      "epoch 44 | loss: 0.5646  | val_0_mse: 0.60064 |  0:00:07s\n",
      "epoch 45 | loss: 0.53642 | val_0_mse: 0.70362 |  0:00:07s\n",
      "epoch 46 | loss: 0.53114 | val_0_mse: 0.61437 |  0:00:07s\n",
      "epoch 47 | loss: 0.51523 | val_0_mse: 0.64856 |  0:00:07s\n",
      "epoch 48 | loss: 0.50483 | val_0_mse: 0.60505 |  0:00:07s\n",
      "epoch 49 | loss: 0.50099 | val_0_mse: 0.61158 |  0:00:08s\n",
      "epoch 50 | loss: 0.49293 | val_0_mse: 0.63256 |  0:00:08s\n",
      "epoch 51 | loss: 0.49652 | val_0_mse: 0.62607 |  0:00:08s\n",
      "epoch 52 | loss: 0.48403 | val_0_mse: 0.57917 |  0:00:08s\n",
      "epoch 53 | loss: 0.49208 | val_0_mse: 0.58753 |  0:00:08s\n",
      "epoch 54 | loss: 0.49003 | val_0_mse: 0.60815 |  0:00:09s\n",
      "epoch 55 | loss: 0.4789  | val_0_mse: 0.57105 |  0:00:09s\n",
      "epoch 56 | loss: 0.48614 | val_0_mse: 0.60105 |  0:00:09s\n",
      "epoch 57 | loss: 0.48316 | val_0_mse: 0.58325 |  0:00:09s\n",
      "epoch 58 | loss: 0.4897  | val_0_mse: 0.57812 |  0:00:09s\n",
      "epoch 59 | loss: 0.48843 | val_0_mse: 0.55434 |  0:00:09s\n",
      "epoch 60 | loss: 0.47655 | val_0_mse: 0.5824  |  0:00:10s\n",
      "epoch 61 | loss: 0.47843 | val_0_mse: 0.56261 |  0:00:10s\n",
      "epoch 62 | loss: 0.48338 | val_0_mse: 0.55154 |  0:00:10s\n",
      "epoch 63 | loss: 0.51793 | val_0_mse: 0.58704 |  0:00:10s\n",
      "epoch 64 | loss: 0.5178  | val_0_mse: 0.54112 |  0:00:10s\n",
      "epoch 65 | loss: 0.50608 | val_0_mse: 0.60857 |  0:00:10s\n",
      "epoch 66 | loss: 0.51925 | val_0_mse: 0.53196 |  0:00:11s\n",
      "epoch 67 | loss: 0.49382 | val_0_mse: 0.58427 |  0:00:11s\n",
      "epoch 68 | loss: 0.52    | val_0_mse: 0.52417 |  0:00:11s\n",
      "epoch 69 | loss: 0.51887 | val_0_mse: 0.55864 |  0:00:11s\n",
      "epoch 70 | loss: 0.50443 | val_0_mse: 0.52484 |  0:00:11s\n",
      "epoch 71 | loss: 0.49733 | val_0_mse: 0.52711 |  0:00:11s\n",
      "epoch 72 | loss: 0.52018 | val_0_mse: 0.55951 |  0:00:12s\n",
      "epoch 73 | loss: 0.49834 | val_0_mse: 0.51209 |  0:00:12s\n",
      "epoch 74 | loss: 0.49046 | val_0_mse: 0.54022 |  0:00:12s\n",
      "epoch 75 | loss: 0.4857  | val_0_mse: 0.55203 |  0:00:12s\n",
      "epoch 76 | loss: 0.49142 | val_0_mse: 0.53263 |  0:00:12s\n",
      "epoch 77 | loss: 0.49549 | val_0_mse: 0.54907 |  0:00:12s\n",
      "epoch 78 | loss: 0.48122 | val_0_mse: 0.528   |  0:00:12s\n",
      "epoch 79 | loss: 0.47961 | val_0_mse: 0.53562 |  0:00:13s\n",
      "epoch 80 | loss: 0.48649 | val_0_mse: 0.53552 |  0:00:13s\n",
      "epoch 81 | loss: 0.49047 | val_0_mse: 0.52871 |  0:00:13s\n",
      "epoch 82 | loss: 0.51423 | val_0_mse: 0.5337  |  0:00:13s\n",
      "epoch 83 | loss: 0.50121 | val_0_mse: 0.54665 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 0.51209\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4180... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78634</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">lively-sweep-14</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/zemd6r8q\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/zemd6r8q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044529-zemd6r8q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2fvwfqha with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.11276895991003348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/2fvwfqha\" target=\"_blank\">worthy-sweep-15</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.40241 | val_0_mse: 2.48192 |  0:00:00s\n",
      "epoch 1  | loss: 1.53955 | val_0_mse: 1.4811  |  0:00:00s\n",
      "epoch 2  | loss: 0.97308 | val_0_mse: 1.3473  |  0:00:00s\n",
      "epoch 3  | loss: 0.79576 | val_0_mse: 1.29531 |  0:00:00s\n",
      "epoch 4  | loss: 0.69147 | val_0_mse: 1.32347 |  0:00:00s\n",
      "epoch 5  | loss: 1.02174 | val_0_mse: 0.89273 |  0:00:00s\n",
      "epoch 6  | loss: 0.86936 | val_0_mse: 1.28818 |  0:00:00s\n",
      "epoch 7  | loss: 0.90532 | val_0_mse: 0.85383 |  0:00:01s\n",
      "epoch 8  | loss: 0.6246  | val_0_mse: 1.09093 |  0:00:01s\n",
      "epoch 9  | loss: 0.6297  | val_0_mse: 0.88174 |  0:00:01s\n",
      "epoch 10 | loss: 0.61129 | val_0_mse: 1.01151 |  0:00:01s\n",
      "epoch 11 | loss: 0.5709  | val_0_mse: 0.95766 |  0:00:01s\n",
      "epoch 12 | loss: 0.54906 | val_0_mse: 0.86891 |  0:00:01s\n",
      "epoch 13 | loss: 0.54274 | val_0_mse: 0.83398 |  0:00:01s\n",
      "epoch 14 | loss: 0.55886 | val_0_mse: 0.81295 |  0:00:02s\n",
      "epoch 15 | loss: 0.54038 | val_0_mse: 0.86523 |  0:00:02s\n",
      "epoch 16 | loss: 0.5641  | val_0_mse: 0.89513 |  0:00:02s\n",
      "epoch 17 | loss: 0.54076 | val_0_mse: 0.86707 |  0:00:02s\n",
      "epoch 18 | loss: 0.52919 | val_0_mse: 0.84826 |  0:00:02s\n",
      "epoch 19 | loss: 0.52695 | val_0_mse: 0.87683 |  0:00:02s\n",
      "epoch 20 | loss: 0.52861 | val_0_mse: 0.85404 |  0:00:02s\n",
      "epoch 21 | loss: 0.54589 | val_0_mse: 0.75654 |  0:00:03s\n",
      "epoch 22 | loss: 0.52909 | val_0_mse: 0.77331 |  0:00:03s\n",
      "epoch 23 | loss: 0.51714 | val_0_mse: 0.84944 |  0:00:03s\n",
      "epoch 24 | loss: 0.51132 | val_0_mse: 0.75159 |  0:00:03s\n",
      "epoch 25 | loss: 0.50065 | val_0_mse: 0.78046 |  0:00:03s\n",
      "epoch 26 | loss: 0.49847 | val_0_mse: 0.82585 |  0:00:03s\n",
      "epoch 27 | loss: 0.50856 | val_0_mse: 0.7282  |  0:00:03s\n",
      "epoch 28 | loss: 0.49917 | val_0_mse: 0.80249 |  0:00:04s\n",
      "epoch 29 | loss: 0.5025  | val_0_mse: 0.78084 |  0:00:04s\n",
      "epoch 30 | loss: 0.4987  | val_0_mse: 0.69541 |  0:00:04s\n",
      "epoch 31 | loss: 0.50591 | val_0_mse: 0.85942 |  0:00:04s\n",
      "epoch 32 | loss: 0.52813 | val_0_mse: 0.71501 |  0:00:04s\n",
      "epoch 33 | loss: 0.53293 | val_0_mse: 0.845   |  0:00:04s\n",
      "epoch 34 | loss: 0.56327 | val_0_mse: 0.68584 |  0:00:04s\n",
      "epoch 35 | loss: 0.55072 | val_0_mse: 0.75303 |  0:00:05s\n",
      "epoch 36 | loss: 0.57733 | val_0_mse: 0.62516 |  0:00:05s\n",
      "epoch 37 | loss: 0.58035 | val_0_mse: 0.63821 |  0:00:05s\n",
      "epoch 38 | loss: 0.51556 | val_0_mse: 0.61837 |  0:00:05s\n",
      "epoch 39 | loss: 0.5032  | val_0_mse: 0.64072 |  0:00:05s\n",
      "epoch 40 | loss: 0.50536 | val_0_mse: 0.63384 |  0:00:05s\n",
      "epoch 41 | loss: 0.50525 | val_0_mse: 0.68156 |  0:00:06s\n",
      "epoch 42 | loss: 0.49931 | val_0_mse: 0.60978 |  0:00:06s\n",
      "epoch 43 | loss: 0.49794 | val_0_mse: 0.6087  |  0:00:06s\n",
      "epoch 44 | loss: 0.49805 | val_0_mse: 0.63789 |  0:00:06s\n",
      "epoch 45 | loss: 0.49974 | val_0_mse: 0.66404 |  0:00:06s\n",
      "epoch 46 | loss: 0.51181 | val_0_mse: 0.62514 |  0:00:06s\n",
      "epoch 47 | loss: 0.50983 | val_0_mse: 0.64315 |  0:00:06s\n",
      "epoch 48 | loss: 0.4873  | val_0_mse: 0.62109 |  0:00:07s\n",
      "epoch 49 | loss: 0.49175 | val_0_mse: 0.63615 |  0:00:07s\n",
      "epoch 50 | loss: 0.4902  | val_0_mse: 0.59258 |  0:00:07s\n",
      "epoch 51 | loss: 0.48972 | val_0_mse: 0.61179 |  0:00:07s\n",
      "epoch 52 | loss: 0.49316 | val_0_mse: 0.59494 |  0:00:07s\n",
      "epoch 53 | loss: 0.50583 | val_0_mse: 0.58552 |  0:00:07s\n",
      "epoch 54 | loss: 0.49189 | val_0_mse: 0.60134 |  0:00:07s\n",
      "epoch 55 | loss: 0.47902 | val_0_mse: 0.60171 |  0:00:08s\n",
      "epoch 56 | loss: 0.49117 | val_0_mse: 0.57171 |  0:00:08s\n",
      "epoch 57 | loss: 0.48518 | val_0_mse: 0.61743 |  0:00:08s\n",
      "epoch 58 | loss: 0.48011 | val_0_mse: 0.60631 |  0:00:08s\n",
      "epoch 59 | loss: 0.57737 | val_0_mse: 0.60629 |  0:00:08s\n",
      "epoch 60 | loss: 0.5401  | val_0_mse: 0.56354 |  0:00:08s\n",
      "epoch 61 | loss: 0.49604 | val_0_mse: 0.63608 |  0:00:08s\n",
      "epoch 62 | loss: 0.4942  | val_0_mse: 0.54663 |  0:00:09s\n",
      "epoch 63 | loss: 0.50371 | val_0_mse: 0.57178 |  0:00:09s\n",
      "epoch 64 | loss: 0.47937 | val_0_mse: 0.54652 |  0:00:09s\n",
      "epoch 65 | loss: 0.49383 | val_0_mse: 0.57537 |  0:00:09s\n",
      "epoch 66 | loss: 0.47185 | val_0_mse: 0.55627 |  0:00:09s\n",
      "epoch 67 | loss: 0.48964 | val_0_mse: 0.59909 |  0:00:09s\n",
      "epoch 68 | loss: 0.47927 | val_0_mse: 0.55081 |  0:00:09s\n",
      "epoch 69 | loss: 0.48839 | val_0_mse: 0.59158 |  0:00:10s\n",
      "epoch 70 | loss: 0.48701 | val_0_mse: 0.58469 |  0:00:10s\n",
      "epoch 71 | loss: 0.47351 | val_0_mse: 0.55941 |  0:00:10s\n",
      "epoch 72 | loss: 0.48933 | val_0_mse: 0.55924 |  0:00:10s\n",
      "epoch 73 | loss: 0.47559 | val_0_mse: 0.53838 |  0:00:10s\n",
      "epoch 74 | loss: 0.46664 | val_0_mse: 0.52666 |  0:00:10s\n",
      "epoch 75 | loss: 0.46815 | val_0_mse: 0.53373 |  0:00:10s\n",
      "epoch 76 | loss: 0.48283 | val_0_mse: 0.55625 |  0:00:11s\n",
      "epoch 77 | loss: 0.47621 | val_0_mse: 0.52767 |  0:00:11s\n",
      "epoch 78 | loss: 0.4747  | val_0_mse: 0.53333 |  0:00:11s\n",
      "epoch 79 | loss: 0.46518 | val_0_mse: 0.55672 |  0:00:11s\n",
      "epoch 80 | loss: 0.48589 | val_0_mse: 0.57631 |  0:00:11s\n",
      "epoch 81 | loss: 0.52855 | val_0_mse: 0.59012 |  0:00:11s\n",
      "epoch 82 | loss: 0.48277 | val_0_mse: 0.58188 |  0:00:11s\n",
      "epoch 83 | loss: 0.52314 | val_0_mse: 0.60799 |  0:00:12s\n",
      "epoch 84 | loss: 0.50631 | val_0_mse: 0.58272 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.52666\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4226... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77626</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">worthy-sweep-15</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/2fvwfqha\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/2fvwfqha</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044548-2fvwfqha/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kjnztl0b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.17734566065572524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/kjnztl0b\" target=\"_blank\">cosmic-sweep-16</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 10.79756| val_0_mse: 1.97464 |  0:00:00s\n",
      "epoch 1  | loss: 2.7711  | val_0_mse: 1.46454 |  0:00:00s\n",
      "epoch 2  | loss: 1.62006 | val_0_mse: 1.60795 |  0:00:00s\n",
      "epoch 3  | loss: 1.11952 | val_0_mse: 1.34065 |  0:00:00s\n",
      "epoch 4  | loss: 0.98989 | val_0_mse: 1.16712 |  0:00:00s\n",
      "epoch 5  | loss: 0.80315 | val_0_mse: 1.29381 |  0:00:00s\n",
      "epoch 6  | loss: 0.76287 | val_0_mse: 1.43919 |  0:00:01s\n",
      "epoch 7  | loss: 0.72272 | val_0_mse: 1.15871 |  0:00:01s\n",
      "epoch 8  | loss: 0.71203 | val_0_mse: 1.0232  |  0:00:01s\n",
      "epoch 9  | loss: 0.72232 | val_0_mse: 0.99423 |  0:00:01s\n",
      "epoch 10 | loss: 0.70207 | val_0_mse: 1.25842 |  0:00:01s\n",
      "epoch 11 | loss: 0.70693 | val_0_mse: 0.86129 |  0:00:01s\n",
      "epoch 12 | loss: 0.81623 | val_0_mse: 0.97034 |  0:00:02s\n",
      "epoch 13 | loss: 0.74955 | val_0_mse: 1.02626 |  0:00:02s\n",
      "epoch 14 | loss: 0.61588 | val_0_mse: 0.96638 |  0:00:02s\n",
      "epoch 15 | loss: 0.62121 | val_0_mse: 0.96294 |  0:00:02s\n",
      "epoch 16 | loss: 0.60294 | val_0_mse: 1.08445 |  0:00:02s\n",
      "epoch 17 | loss: 0.61077 | val_0_mse: 0.88064 |  0:00:02s\n",
      "epoch 18 | loss: 0.59447 | val_0_mse: 0.91075 |  0:00:03s\n",
      "epoch 19 | loss: 0.6279  | val_0_mse: 0.79481 |  0:00:03s\n",
      "epoch 20 | loss: 0.68525 | val_0_mse: 0.9276  |  0:00:03s\n",
      "epoch 21 | loss: 0.58181 | val_0_mse: 0.84317 |  0:00:03s\n",
      "epoch 22 | loss: 0.56213 | val_0_mse: 0.78646 |  0:00:03s\n",
      "epoch 23 | loss: 0.52963 | val_0_mse: 0.74014 |  0:00:03s\n",
      "epoch 24 | loss: 0.5439  | val_0_mse: 0.80674 |  0:00:04s\n",
      "epoch 25 | loss: 0.55853 | val_0_mse: 0.75389 |  0:00:04s\n",
      "epoch 26 | loss: 0.54316 | val_0_mse: 0.7431  |  0:00:04s\n",
      "epoch 27 | loss: 0.55662 | val_0_mse: 0.78361 |  0:00:04s\n",
      "epoch 28 | loss: 0.53121 | val_0_mse: 0.71854 |  0:00:04s\n",
      "epoch 29 | loss: 0.52032 | val_0_mse: 0.82936 |  0:00:04s\n",
      "epoch 30 | loss: 0.53047 | val_0_mse: 0.71014 |  0:00:05s\n",
      "epoch 31 | loss: 0.51013 | val_0_mse: 0.68706 |  0:00:05s\n",
      "epoch 32 | loss: 0.51981 | val_0_mse: 0.69128 |  0:00:05s\n",
      "epoch 33 | loss: 0.51071 | val_0_mse: 0.79097 |  0:00:05s\n",
      "epoch 34 | loss: 0.54127 | val_0_mse: 0.726   |  0:00:05s\n",
      "epoch 35 | loss: 0.54162 | val_0_mse: 0.79567 |  0:00:05s\n",
      "epoch 36 | loss: 0.51168 | val_0_mse: 0.7119  |  0:00:06s\n",
      "epoch 37 | loss: 0.5046  | val_0_mse: 0.68387 |  0:00:06s\n",
      "epoch 38 | loss: 0.51754 | val_0_mse: 0.73539 |  0:00:06s\n",
      "epoch 39 | loss: 0.52405 | val_0_mse: 0.68946 |  0:00:06s\n",
      "epoch 40 | loss: 0.51651 | val_0_mse: 0.64415 |  0:00:06s\n",
      "epoch 41 | loss: 0.50709 | val_0_mse: 0.6683  |  0:00:06s\n",
      "epoch 42 | loss: 0.50799 | val_0_mse: 0.62643 |  0:00:07s\n",
      "epoch 43 | loss: 0.52346 | val_0_mse: 0.7613  |  0:00:07s\n",
      "epoch 44 | loss: 0.5646  | val_0_mse: 0.60729 |  0:00:07s\n",
      "epoch 45 | loss: 0.53642 | val_0_mse: 0.71163 |  0:00:07s\n",
      "epoch 46 | loss: 0.53114 | val_0_mse: 0.6059  |  0:00:07s\n",
      "epoch 47 | loss: 0.51523 | val_0_mse: 0.64496 |  0:00:07s\n",
      "epoch 48 | loss: 0.50483 | val_0_mse: 0.6045  |  0:00:08s\n",
      "epoch 49 | loss: 0.50099 | val_0_mse: 0.6113  |  0:00:08s\n",
      "epoch 50 | loss: 0.49293 | val_0_mse: 0.62732 |  0:00:08s\n",
      "epoch 51 | loss: 0.49652 | val_0_mse: 0.62845 |  0:00:08s\n",
      "epoch 52 | loss: 0.48403 | val_0_mse: 0.57849 |  0:00:08s\n",
      "epoch 53 | loss: 0.49208 | val_0_mse: 0.5866  |  0:00:08s\n",
      "epoch 54 | loss: 0.49003 | val_0_mse: 0.60923 |  0:00:09s\n",
      "epoch 55 | loss: 0.4789  | val_0_mse: 0.57359 |  0:00:09s\n",
      "epoch 56 | loss: 0.48614 | val_0_mse: 0.60079 |  0:00:09s\n",
      "epoch 57 | loss: 0.48316 | val_0_mse: 0.58691 |  0:00:09s\n",
      "epoch 58 | loss: 0.4897  | val_0_mse: 0.58198 |  0:00:09s\n",
      "epoch 59 | loss: 0.48843 | val_0_mse: 0.54792 |  0:00:09s\n",
      "epoch 60 | loss: 0.47655 | val_0_mse: 0.57395 |  0:00:10s\n",
      "epoch 61 | loss: 0.47843 | val_0_mse: 0.56362 |  0:00:10s\n",
      "epoch 62 | loss: 0.48338 | val_0_mse: 0.56037 |  0:00:10s\n",
      "epoch 63 | loss: 0.51793 | val_0_mse: 0.58596 |  0:00:10s\n",
      "epoch 64 | loss: 0.5178  | val_0_mse: 0.54376 |  0:00:10s\n",
      "epoch 65 | loss: 0.50608 | val_0_mse: 0.61002 |  0:00:10s\n",
      "epoch 66 | loss: 0.51925 | val_0_mse: 0.5357  |  0:00:11s\n",
      "epoch 67 | loss: 0.49382 | val_0_mse: 0.58672 |  0:00:11s\n",
      "epoch 68 | loss: 0.52    | val_0_mse: 0.52704 |  0:00:11s\n",
      "epoch 69 | loss: 0.51887 | val_0_mse: 0.56606 |  0:00:11s\n",
      "epoch 70 | loss: 0.50443 | val_0_mse: 0.52874 |  0:00:11s\n",
      "epoch 71 | loss: 0.49733 | val_0_mse: 0.52791 |  0:00:11s\n",
      "epoch 72 | loss: 0.52018 | val_0_mse: 0.56145 |  0:00:12s\n",
      "epoch 73 | loss: 0.49834 | val_0_mse: 0.51579 |  0:00:12s\n",
      "epoch 74 | loss: 0.49046 | val_0_mse: 0.54036 |  0:00:12s\n",
      "epoch 75 | loss: 0.4857  | val_0_mse: 0.55381 |  0:00:12s\n",
      "epoch 76 | loss: 0.49142 | val_0_mse: 0.53775 |  0:00:12s\n",
      "epoch 77 | loss: 0.49549 | val_0_mse: 0.54908 |  0:00:12s\n",
      "epoch 78 | loss: 0.48122 | val_0_mse: 0.5288  |  0:00:13s\n",
      "epoch 79 | loss: 0.47961 | val_0_mse: 0.54186 |  0:00:13s\n",
      "epoch 80 | loss: 0.48649 | val_0_mse: 0.53889 |  0:00:13s\n",
      "epoch 81 | loss: 0.49047 | val_0_mse: 0.52844 |  0:00:13s\n",
      "epoch 82 | loss: 0.51423 | val_0_mse: 0.53339 |  0:00:13s\n",
      "epoch 83 | loss: 0.50121 | val_0_mse: 0.53985 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 0.51579\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4269... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78537</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cosmic-sweep-16</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/kjnztl0b\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/kjnztl0b</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044607-kjnztl0b/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4dx51h4m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.16712350101562293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/4dx51h4m\" target=\"_blank\">breezy-sweep-17</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.24944 | val_0_mse: 1.35402 |  0:00:00s\n",
      "epoch 1  | loss: 1.47371 | val_0_mse: 1.30771 |  0:00:00s\n",
      "epoch 2  | loss: 1.0744  | val_0_mse: 1.12185 |  0:00:00s\n",
      "epoch 3  | loss: 0.83335 | val_0_mse: 0.9064  |  0:00:01s\n",
      "epoch 4  | loss: 0.87268 | val_0_mse: 0.8572  |  0:00:01s\n",
      "epoch 5  | loss: 0.81626 | val_0_mse: 1.10804 |  0:00:01s\n",
      "epoch 6  | loss: 0.95751 | val_0_mse: 0.91911 |  0:00:01s\n",
      "epoch 7  | loss: 0.92844 | val_0_mse: 1.03135 |  0:00:01s\n",
      "epoch 8  | loss: 0.95578 | val_0_mse: 0.82932 |  0:00:02s\n",
      "epoch 9  | loss: 0.74441 | val_0_mse: 0.97195 |  0:00:02s\n",
      "epoch 10 | loss: 0.71103 | val_0_mse: 0.82237 |  0:00:02s\n",
      "epoch 11 | loss: 0.67483 | val_0_mse: 1.07447 |  0:00:02s\n",
      "epoch 12 | loss: 0.70269 | val_0_mse: 0.78436 |  0:00:03s\n",
      "epoch 13 | loss: 0.61071 | val_0_mse: 0.78522 |  0:00:03s\n",
      "epoch 14 | loss: 0.56556 | val_0_mse: 0.83732 |  0:00:03s\n",
      "epoch 15 | loss: 0.56459 | val_0_mse: 0.80856 |  0:00:03s\n",
      "epoch 16 | loss: 0.543   | val_0_mse: 0.78594 |  0:00:03s\n",
      "epoch 17 | loss: 0.56029 | val_0_mse: 0.84302 |  0:00:04s\n",
      "epoch 18 | loss: 0.54573 | val_0_mse: 0.80333 |  0:00:04s\n",
      "epoch 19 | loss: 0.55155 | val_0_mse: 0.74006 |  0:00:04s\n",
      "epoch 20 | loss: 0.55924 | val_0_mse: 0.7948  |  0:00:04s\n",
      "epoch 21 | loss: 0.55074 | val_0_mse: 0.71491 |  0:00:05s\n",
      "epoch 22 | loss: 0.5601  | val_0_mse: 0.69472 |  0:00:05s\n",
      "epoch 23 | loss: 0.54098 | val_0_mse: 0.74779 |  0:00:05s\n",
      "epoch 24 | loss: 0.53658 | val_0_mse: 0.76365 |  0:00:05s\n",
      "epoch 25 | loss: 0.60695 | val_0_mse: 0.63714 |  0:00:05s\n",
      "epoch 26 | loss: 0.62415 | val_0_mse: 0.83375 |  0:00:06s\n",
      "epoch 27 | loss: 0.6466  | val_0_mse: 0.7296  |  0:00:06s\n",
      "epoch 28 | loss: 0.74325 | val_0_mse: 0.6335  |  0:00:06s\n",
      "epoch 29 | loss: 0.57722 | val_0_mse: 0.66905 |  0:00:06s\n",
      "epoch 30 | loss: 0.57494 | val_0_mse: 0.68679 |  0:00:07s\n",
      "epoch 31 | loss: 0.56665 | val_0_mse: 0.64683 |  0:00:07s\n",
      "epoch 32 | loss: 0.5444  | val_0_mse: 0.66818 |  0:00:07s\n",
      "epoch 33 | loss: 0.55425 | val_0_mse: 0.73598 |  0:00:07s\n",
      "epoch 34 | loss: 0.54863 | val_0_mse: 0.66472 |  0:00:08s\n",
      "epoch 35 | loss: 0.52803 | val_0_mse: 0.65626 |  0:00:08s\n",
      "epoch 36 | loss: 0.53272 | val_0_mse: 0.64734 |  0:00:08s\n",
      "epoch 37 | loss: 0.54704 | val_0_mse: 0.62119 |  0:00:08s\n",
      "epoch 38 | loss: 0.53735 | val_0_mse: 0.61528 |  0:00:08s\n",
      "epoch 39 | loss: 0.52928 | val_0_mse: 0.60654 |  0:00:09s\n",
      "epoch 40 | loss: 0.5466  | val_0_mse: 0.66194 |  0:00:09s\n",
      "epoch 41 | loss: 0.5364  | val_0_mse: 0.61598 |  0:00:09s\n",
      "epoch 42 | loss: 0.52097 | val_0_mse: 0.60158 |  0:00:09s\n",
      "epoch 43 | loss: 0.5279  | val_0_mse: 0.61084 |  0:00:10s\n",
      "epoch 44 | loss: 0.51529 | val_0_mse: 0.62367 |  0:00:10s\n",
      "epoch 45 | loss: 0.52236 | val_0_mse: 0.61323 |  0:00:10s\n",
      "epoch 46 | loss: 0.51142 | val_0_mse: 0.59862 |  0:00:10s\n",
      "epoch 47 | loss: 0.5205  | val_0_mse: 0.60228 |  0:00:11s\n",
      "epoch 48 | loss: 0.53573 | val_0_mse: 0.58461 |  0:00:11s\n",
      "epoch 49 | loss: 0.52252 | val_0_mse: 0.59042 |  0:00:11s\n",
      "epoch 50 | loss: 0.51302 | val_0_mse: 0.57414 |  0:00:11s\n",
      "epoch 51 | loss: 0.51045 | val_0_mse: 0.56552 |  0:00:11s\n",
      "epoch 52 | loss: 0.50391 | val_0_mse: 0.57215 |  0:00:12s\n",
      "epoch 53 | loss: 0.51062 | val_0_mse: 0.60537 |  0:00:12s\n",
      "epoch 54 | loss: 0.51155 | val_0_mse: 0.55067 |  0:00:12s\n",
      "epoch 55 | loss: 0.50928 | val_0_mse: 0.57219 |  0:00:12s\n",
      "epoch 56 | loss: 0.51818 | val_0_mse: 0.66471 |  0:00:13s\n",
      "epoch 57 | loss: 0.53453 | val_0_mse: 0.58649 |  0:00:13s\n",
      "epoch 58 | loss: 0.65765 | val_0_mse: 0.5836  |  0:00:13s\n",
      "epoch 59 | loss: 0.56794 | val_0_mse: 0.57083 |  0:00:13s\n",
      "epoch 60 | loss: 0.54378 | val_0_mse: 0.57919 |  0:00:14s\n",
      "epoch 61 | loss: 0.54681 | val_0_mse: 0.6061  |  0:00:14s\n",
      "epoch 62 | loss: 0.53591 | val_0_mse: 0.58916 |  0:00:14s\n",
      "epoch 63 | loss: 0.52503 | val_0_mse: 0.56073 |  0:00:14s\n",
      "epoch 64 | loss: 0.51032 | val_0_mse: 0.57608 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 0.55067\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4313... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76759</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">breezy-sweep-17</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/4dx51h4m\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/4dx51h4m</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044626-4dx51h4m/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zkofhj5k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0972148546031939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/zkofhj5k\" target=\"_blank\">divine-sweep-18</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 28.62728| val_0_mse: 6.90449 |  0:00:00s\n",
      "epoch 1  | loss: 3.70333 | val_0_mse: 2.80701 |  0:00:00s\n",
      "epoch 2  | loss: 1.82638 | val_0_mse: 2.84505 |  0:00:00s\n",
      "epoch 3  | loss: 0.92309 | val_0_mse: 1.32535 |  0:00:00s\n",
      "epoch 4  | loss: 0.78165 | val_0_mse: 1.32014 |  0:00:01s\n",
      "epoch 5  | loss: 0.74101 | val_0_mse: 0.91935 |  0:00:01s\n",
      "epoch 6  | loss: 0.65086 | val_0_mse: 1.0135  |  0:00:01s\n",
      "epoch 7  | loss: 0.60594 | val_0_mse: 0.84033 |  0:00:01s\n",
      "epoch 8  | loss: 0.59447 | val_0_mse: 0.9457  |  0:00:01s\n",
      "epoch 9  | loss: 0.59508 | val_0_mse: 0.87724 |  0:00:02s\n",
      "epoch 10 | loss: 0.60581 | val_0_mse: 0.76894 |  0:00:02s\n",
      "epoch 11 | loss: 0.62279 | val_0_mse: 0.83454 |  0:00:02s\n",
      "epoch 12 | loss: 0.54787 | val_0_mse: 0.87854 |  0:00:02s\n",
      "epoch 13 | loss: 0.56737 | val_0_mse: 0.81028 |  0:00:02s\n",
      "epoch 14 | loss: 0.55934 | val_0_mse: 0.82285 |  0:00:03s\n",
      "epoch 15 | loss: 0.53772 | val_0_mse: 0.93297 |  0:00:03s\n",
      "epoch 16 | loss: 0.5547  | val_0_mse: 0.71964 |  0:00:03s\n",
      "epoch 17 | loss: 0.57532 | val_0_mse: 0.95976 |  0:00:03s\n",
      "epoch 18 | loss: 0.64625 | val_0_mse: 0.76432 |  0:00:03s\n",
      "epoch 19 | loss: 0.58216 | val_0_mse: 0.84351 |  0:00:04s\n",
      "epoch 20 | loss: 0.57292 | val_0_mse: 0.70439 |  0:00:04s\n",
      "epoch 21 | loss: 0.60544 | val_0_mse: 0.70875 |  0:00:04s\n",
      "epoch 22 | loss: 0.51203 | val_0_mse: 0.75539 |  0:00:04s\n",
      "epoch 23 | loss: 0.50373 | val_0_mse: 0.686   |  0:00:04s\n",
      "epoch 24 | loss: 0.50653 | val_0_mse: 0.70287 |  0:00:05s\n",
      "epoch 25 | loss: 0.50564 | val_0_mse: 0.76999 |  0:00:05s\n",
      "epoch 26 | loss: 0.50034 | val_0_mse: 0.72217 |  0:00:05s\n",
      "epoch 27 | loss: 0.5087  | val_0_mse: 0.6516  |  0:00:05s\n",
      "epoch 28 | loss: 0.51589 | val_0_mse: 0.72063 |  0:00:05s\n",
      "epoch 29 | loss: 0.49819 | val_0_mse: 0.71569 |  0:00:06s\n",
      "epoch 30 | loss: 0.51118 | val_0_mse: 0.65652 |  0:00:06s\n",
      "epoch 31 | loss: 0.51859 | val_0_mse: 0.74473 |  0:00:06s\n",
      "epoch 32 | loss: 0.53409 | val_0_mse: 0.61319 |  0:00:06s\n",
      "epoch 33 | loss: 0.5277  | val_0_mse: 0.6675  |  0:00:06s\n",
      "epoch 34 | loss: 0.49758 | val_0_mse: 0.60669 |  0:00:07s\n",
      "epoch 35 | loss: 0.49645 | val_0_mse: 0.59099 |  0:00:07s\n",
      "epoch 36 | loss: 0.48679 | val_0_mse: 0.63234 |  0:00:07s\n",
      "epoch 37 | loss: 0.50627 | val_0_mse: 0.61747 |  0:00:07s\n",
      "epoch 38 | loss: 0.51452 | val_0_mse: 0.66801 |  0:00:08s\n",
      "epoch 39 | loss: 0.52762 | val_0_mse: 0.57161 |  0:00:08s\n",
      "epoch 40 | loss: 0.53701 | val_0_mse: 0.69161 |  0:00:08s\n",
      "epoch 41 | loss: 0.54289 | val_0_mse: 0.55477 |  0:00:08s\n",
      "epoch 42 | loss: 0.5377  | val_0_mse: 0.61671 |  0:00:08s\n",
      "epoch 43 | loss: 0.53273 | val_0_mse: 0.55016 |  0:00:09s\n",
      "epoch 44 | loss: 0.56658 | val_0_mse: 0.58166 |  0:00:09s\n",
      "epoch 45 | loss: 0.53995 | val_0_mse: 0.56209 |  0:00:09s\n",
      "epoch 46 | loss: 0.51684 | val_0_mse: 0.57404 |  0:00:09s\n",
      "epoch 47 | loss: 0.50198 | val_0_mse: 0.56874 |  0:00:09s\n",
      "epoch 48 | loss: 0.5049  | val_0_mse: 0.60292 |  0:00:10s\n",
      "epoch 49 | loss: 0.52366 | val_0_mse: 0.54786 |  0:00:10s\n",
      "epoch 50 | loss: 0.5083  | val_0_mse: 0.6317  |  0:00:10s\n",
      "epoch 51 | loss: 0.51028 | val_0_mse: 0.57205 |  0:00:10s\n",
      "epoch 52 | loss: 0.55542 | val_0_mse: 0.62081 |  0:00:10s\n",
      "epoch 53 | loss: 0.57905 | val_0_mse: 0.60189 |  0:00:11s\n",
      "epoch 54 | loss: 0.57082 | val_0_mse: 0.59314 |  0:00:11s\n",
      "epoch 55 | loss: 0.53102 | val_0_mse: 0.64791 |  0:00:11s\n",
      "epoch 56 | loss: 0.51537 | val_0_mse: 0.56016 |  0:00:11s\n",
      "epoch 57 | loss: 0.49877 | val_0_mse: 0.60977 |  0:00:11s\n",
      "epoch 58 | loss: 0.50282 | val_0_mse: 0.58176 |  0:00:12s\n",
      "epoch 59 | loss: 0.56363 | val_0_mse: 0.6056  |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 0.54786\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4367... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77428</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">divine-sweep-18</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/zkofhj5k\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/zkofhj5k</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044648-zkofhj5k/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fjwyjgca with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.19427166153127728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/fjwyjgca\" target=\"_blank\">playful-sweep-19</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 12.68017| val_0_mse: 2.00573 |  0:00:00s\n",
      "epoch 1  | loss: 2.79206 | val_0_mse: 1.80435 |  0:00:00s\n",
      "epoch 2  | loss: 1.43477 | val_0_mse: 1.15566 |  0:00:00s\n",
      "epoch 3  | loss: 1.16885 | val_0_mse: 1.06426 |  0:00:00s\n",
      "epoch 4  | loss: 0.96327 | val_0_mse: 0.84512 |  0:00:00s\n",
      "epoch 5  | loss: 0.79654 | val_0_mse: 1.19738 |  0:00:01s\n",
      "epoch 6  | loss: 0.70119 | val_0_mse: 0.7288  |  0:00:01s\n",
      "epoch 7  | loss: 0.65578 | val_0_mse: 1.05668 |  0:00:01s\n",
      "epoch 8  | loss: 0.67986 | val_0_mse: 0.71597 |  0:00:01s\n",
      "epoch 9  | loss: 0.62699 | val_0_mse: 0.93966 |  0:00:01s\n",
      "epoch 10 | loss: 0.57589 | val_0_mse: 0.83214 |  0:00:02s\n",
      "epoch 11 | loss: 0.56977 | val_0_mse: 0.92983 |  0:00:02s\n",
      "epoch 12 | loss: 0.58447 | val_0_mse: 0.79639 |  0:00:02s\n",
      "epoch 13 | loss: 0.54559 | val_0_mse: 0.79784 |  0:00:02s\n",
      "epoch 14 | loss: 0.53081 | val_0_mse: 0.82796 |  0:00:02s\n",
      "epoch 15 | loss: 0.53481 | val_0_mse: 0.80191 |  0:00:02s\n",
      "epoch 16 | loss: 0.53443 | val_0_mse: 0.75501 |  0:00:03s\n",
      "epoch 17 | loss: 0.54946 | val_0_mse: 0.8242  |  0:00:03s\n",
      "epoch 18 | loss: 0.53664 | val_0_mse: 0.7222  |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 0.71597\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4415... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76146</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">playful-sweep-19</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/fjwyjgca\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/fjwyjgca</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044706-fjwyjgca/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wbssplyl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.12030274227301864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/wbssplyl\" target=\"_blank\">sage-sweep-20</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.66627 | val_0_mse: 2.30917 |  0:00:00s\n",
      "epoch 1  | loss: 1.44705 | val_0_mse: 0.9253  |  0:00:00s\n",
      "epoch 2  | loss: 1.13321 | val_0_mse: 1.36979 |  0:00:00s\n",
      "epoch 3  | loss: 0.8291  | val_0_mse: 1.21508 |  0:00:00s\n",
      "epoch 4  | loss: 0.70011 | val_0_mse: 1.02154 |  0:00:00s\n",
      "epoch 5  | loss: 0.62486 | val_0_mse: 1.15687 |  0:00:01s\n",
      "epoch 6  | loss: 0.61592 | val_0_mse: 1.31133 |  0:00:01s\n",
      "epoch 7  | loss: 0.59531 | val_0_mse: 0.98233 |  0:00:01s\n",
      "epoch 8  | loss: 0.58011 | val_0_mse: 0.9173  |  0:00:01s\n",
      "epoch 9  | loss: 0.56865 | val_0_mse: 0.8779  |  0:00:01s\n",
      "epoch 10 | loss: 0.55858 | val_0_mse: 0.87208 |  0:00:02s\n",
      "epoch 11 | loss: 0.56073 | val_0_mse: 0.84633 |  0:00:02s\n",
      "epoch 12 | loss: 0.54328 | val_0_mse: 0.90169 |  0:00:02s\n",
      "epoch 13 | loss: 0.53463 | val_0_mse: 0.88339 |  0:00:02s\n",
      "epoch 14 | loss: 0.52775 | val_0_mse: 0.83182 |  0:00:02s\n",
      "epoch 15 | loss: 0.5746  | val_0_mse: 1.05055 |  0:00:03s\n",
      "epoch 16 | loss: 0.59218 | val_0_mse: 0.72859 |  0:00:03s\n",
      "epoch 17 | loss: 0.54455 | val_0_mse: 0.82171 |  0:00:03s\n",
      "epoch 18 | loss: 0.50663 | val_0_mse: 0.74652 |  0:00:03s\n",
      "epoch 19 | loss: 0.51199 | val_0_mse: 0.89832 |  0:00:03s\n",
      "epoch 20 | loss: 0.52097 | val_0_mse: 0.79045 |  0:00:04s\n",
      "epoch 21 | loss: 0.51328 | val_0_mse: 0.81846 |  0:00:04s\n",
      "epoch 22 | loss: 0.51801 | val_0_mse: 0.7179  |  0:00:04s\n",
      "epoch 23 | loss: 0.51093 | val_0_mse: 0.72176 |  0:00:04s\n",
      "epoch 24 | loss: 0.4986  | val_0_mse: 0.71269 |  0:00:04s\n",
      "epoch 25 | loss: 0.49807 | val_0_mse: 0.71865 |  0:00:05s\n",
      "epoch 26 | loss: 0.49601 | val_0_mse: 0.72104 |  0:00:05s\n",
      "epoch 27 | loss: 0.49521 | val_0_mse: 0.77165 |  0:00:05s\n",
      "epoch 28 | loss: 0.49138 | val_0_mse: 0.72351 |  0:00:05s\n",
      "epoch 29 | loss: 0.48414 | val_0_mse: 0.69717 |  0:00:05s\n",
      "epoch 30 | loss: 0.49585 | val_0_mse: 0.71311 |  0:00:06s\n",
      "epoch 31 | loss: 0.48905 | val_0_mse: 0.69214 |  0:00:06s\n",
      "epoch 32 | loss: 0.48553 | val_0_mse: 0.69848 |  0:00:06s\n",
      "epoch 33 | loss: 0.48585 | val_0_mse: 0.63418 |  0:00:06s\n",
      "epoch 34 | loss: 0.53324 | val_0_mse: 0.81974 |  0:00:06s\n",
      "epoch 35 | loss: 0.60109 | val_0_mse: 0.66182 |  0:00:07s\n",
      "epoch 36 | loss: 0.58013 | val_0_mse: 0.69419 |  0:00:07s\n",
      "epoch 37 | loss: 0.51719 | val_0_mse: 0.58581 |  0:00:07s\n",
      "epoch 38 | loss: 0.51325 | val_0_mse: 0.63339 |  0:00:07s\n",
      "epoch 39 | loss: 0.50185 | val_0_mse: 0.75125 |  0:00:07s\n",
      "epoch 40 | loss: 0.54726 | val_0_mse: 0.60043 |  0:00:08s\n",
      "epoch 41 | loss: 0.67957 | val_0_mse: 0.60452 |  0:00:08s\n",
      "epoch 42 | loss: 0.50835 | val_0_mse: 0.65771 |  0:00:08s\n",
      "epoch 43 | loss: 0.50224 | val_0_mse: 0.65144 |  0:00:08s\n",
      "epoch 44 | loss: 0.49118 | val_0_mse: 0.58762 |  0:00:08s\n",
      "epoch 45 | loss: 0.49003 | val_0_mse: 0.58533 |  0:00:09s\n",
      "epoch 46 | loss: 0.48681 | val_0_mse: 0.70405 |  0:00:09s\n",
      "epoch 47 | loss: 0.50988 | val_0_mse: 0.57861 |  0:00:09s\n",
      "epoch 48 | loss: 0.49609 | val_0_mse: 0.58497 |  0:00:09s\n",
      "epoch 49 | loss: 0.4856  | val_0_mse: 0.56015 |  0:00:09s\n",
      "epoch 50 | loss: 0.48554 | val_0_mse: 0.5896  |  0:00:10s\n",
      "epoch 51 | loss: 0.48839 | val_0_mse: 0.57388 |  0:00:10s\n",
      "epoch 52 | loss: 0.47949 | val_0_mse: 0.5749  |  0:00:10s\n",
      "epoch 53 | loss: 0.47878 | val_0_mse: 0.53173 |  0:00:10s\n",
      "epoch 54 | loss: 0.49225 | val_0_mse: 0.54083 |  0:00:10s\n",
      "epoch 55 | loss: 0.49706 | val_0_mse: 0.5627  |  0:00:11s\n",
      "epoch 56 | loss: 0.48033 | val_0_mse: 0.51286 |  0:00:11s\n",
      "epoch 57 | loss: 0.49765 | val_0_mse: 0.5798  |  0:00:11s\n",
      "epoch 58 | loss: 0.49534 | val_0_mse: 0.51885 |  0:00:11s\n",
      "epoch 59 | loss: 0.49198 | val_0_mse: 0.54482 |  0:00:12s\n",
      "epoch 60 | loss: 0.49444 | val_0_mse: 0.58555 |  0:00:12s\n",
      "epoch 61 | loss: 0.50858 | val_0_mse: 0.53013 |  0:00:12s\n",
      "epoch 62 | loss: 0.48824 | val_0_mse: 0.56959 |  0:00:12s\n",
      "epoch 63 | loss: 0.48925 | val_0_mse: 0.51942 |  0:00:12s\n",
      "epoch 64 | loss: 0.47716 | val_0_mse: 0.51492 |  0:00:13s\n",
      "epoch 65 | loss: 0.48052 | val_0_mse: 0.57692 |  0:00:13s\n",
      "epoch 66 | loss: 0.49467 | val_0_mse: 0.5242  |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 0.51286\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4461... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78928</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">sage-sweep-20</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/wbssplyl\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/wbssplyl</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044715-wbssplyl/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jp27sz48 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.10880117621769556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/jp27sz48\" target=\"_blank\">azure-sweep-21</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.14121 | val_0_mse: 1.96914 |  0:00:00s\n",
      "epoch 1  | loss: 1.99429 | val_0_mse: 1.87193 |  0:00:00s\n",
      "epoch 2  | loss: 1.37639 | val_0_mse: 1.72829 |  0:00:00s\n",
      "epoch 3  | loss: 1.08617 | val_0_mse: 1.43403 |  0:00:01s\n",
      "epoch 4  | loss: 1.06126 | val_0_mse: 1.15325 |  0:00:01s\n",
      "epoch 5  | loss: 1.10616 | val_0_mse: 1.70393 |  0:00:01s\n",
      "epoch 6  | loss: 1.18918 | val_0_mse: 1.04288 |  0:00:01s\n",
      "epoch 7  | loss: 1.2027  | val_0_mse: 1.40949 |  0:00:02s\n",
      "epoch 8  | loss: 0.95472 | val_0_mse: 1.01285 |  0:00:02s\n",
      "epoch 9  | loss: 0.82395 | val_0_mse: 1.46371 |  0:00:02s\n",
      "epoch 10 | loss: 1.10189 | val_0_mse: 0.82731 |  0:00:02s\n",
      "epoch 11 | loss: 1.1541  | val_0_mse: 1.32667 |  0:00:03s\n",
      "epoch 12 | loss: 1.8298  | val_0_mse: 1.85127 |  0:00:03s\n",
      "epoch 13 | loss: 1.02867 | val_0_mse: 0.77317 |  0:00:03s\n",
      "epoch 14 | loss: 0.93891 | val_0_mse: 1.19081 |  0:00:03s\n",
      "epoch 15 | loss: 0.70815 | val_0_mse: 0.84645 |  0:00:04s\n",
      "epoch 16 | loss: 0.64729 | val_0_mse: 1.07532 |  0:00:04s\n",
      "epoch 17 | loss: 0.61492 | val_0_mse: 0.94837 |  0:00:04s\n",
      "epoch 18 | loss: 0.66035 | val_0_mse: 1.09853 |  0:00:04s\n",
      "epoch 19 | loss: 0.67552 | val_0_mse: 0.91684 |  0:00:05s\n",
      "epoch 20 | loss: 0.61749 | val_0_mse: 1.15594 |  0:00:05s\n",
      "epoch 21 | loss: 0.68972 | val_0_mse: 0.74271 |  0:00:05s\n",
      "epoch 22 | loss: 0.65212 | val_0_mse: 0.95032 |  0:00:05s\n",
      "epoch 23 | loss: 0.6287  | val_0_mse: 0.82382 |  0:00:06s\n",
      "epoch 24 | loss: 0.59608 | val_0_mse: 0.9742  |  0:00:06s\n",
      "epoch 25 | loss: 0.59282 | val_0_mse: 0.74756 |  0:00:06s\n",
      "epoch 26 | loss: 0.59124 | val_0_mse: 0.89148 |  0:00:06s\n",
      "epoch 27 | loss: 0.55699 | val_0_mse: 0.76347 |  0:00:07s\n",
      "epoch 28 | loss: 0.54897 | val_0_mse: 0.77131 |  0:00:07s\n",
      "epoch 29 | loss: 0.54633 | val_0_mse: 0.87383 |  0:00:07s\n",
      "epoch 30 | loss: 0.56238 | val_0_mse: 0.70796 |  0:00:07s\n",
      "epoch 31 | loss: 0.53795 | val_0_mse: 0.7442  |  0:00:08s\n",
      "epoch 32 | loss: 0.53816 | val_0_mse: 0.73201 |  0:00:08s\n",
      "epoch 33 | loss: 0.53259 | val_0_mse: 0.71381 |  0:00:08s\n",
      "epoch 34 | loss: 0.52626 | val_0_mse: 0.65039 |  0:00:08s\n",
      "epoch 35 | loss: 0.52797 | val_0_mse: 0.66665 |  0:00:09s\n",
      "epoch 36 | loss: 0.53899 | val_0_mse: 0.67365 |  0:00:09s\n",
      "epoch 37 | loss: 0.53109 | val_0_mse: 0.68372 |  0:00:09s\n",
      "epoch 38 | loss: 0.53641 | val_0_mse: 0.69183 |  0:00:09s\n",
      "epoch 39 | loss: 0.53415 | val_0_mse: 0.66402 |  0:00:10s\n",
      "epoch 40 | loss: 0.51827 | val_0_mse: 0.6622  |  0:00:10s\n",
      "epoch 41 | loss: 0.52068 | val_0_mse: 0.67493 |  0:00:10s\n",
      "epoch 42 | loss: 0.51282 | val_0_mse: 0.66565 |  0:00:10s\n",
      "epoch 43 | loss: 0.51933 | val_0_mse: 0.64198 |  0:00:11s\n",
      "epoch 44 | loss: 0.52526 | val_0_mse: 0.65609 |  0:00:11s\n",
      "epoch 45 | loss: 0.52277 | val_0_mse: 0.6871  |  0:00:11s\n",
      "epoch 46 | loss: 0.53043 | val_0_mse: 0.6147  |  0:00:11s\n",
      "epoch 47 | loss: 0.56929 | val_0_mse: 0.68635 |  0:00:12s\n",
      "epoch 48 | loss: 0.53491 | val_0_mse: 0.61038 |  0:00:12s\n",
      "epoch 49 | loss: 0.56889 | val_0_mse: 0.64692 |  0:00:12s\n",
      "epoch 50 | loss: 0.55128 | val_0_mse: 0.60258 |  0:00:12s\n",
      "epoch 51 | loss: 0.56505 | val_0_mse: 0.72446 |  0:00:13s\n",
      "epoch 52 | loss: 0.60803 | val_0_mse: 0.61393 |  0:00:13s\n",
      "epoch 53 | loss: 0.66947 | val_0_mse: 0.68964 |  0:00:13s\n",
      "epoch 54 | loss: 0.58178 | val_0_mse: 0.58028 |  0:00:13s\n",
      "epoch 55 | loss: 0.5242  | val_0_mse: 0.60358 |  0:00:14s\n",
      "epoch 56 | loss: 0.52719 | val_0_mse: 0.57157 |  0:00:14s\n",
      "epoch 57 | loss: 0.54052 | val_0_mse: 0.58316 |  0:00:14s\n",
      "epoch 58 | loss: 0.53059 | val_0_mse: 0.60317 |  0:00:15s\n",
      "epoch 59 | loss: 0.52788 | val_0_mse: 0.62315 |  0:00:15s\n",
      "epoch 60 | loss: 0.53968 | val_0_mse: 0.6395  |  0:00:15s\n",
      "epoch 61 | loss: 0.58593 | val_0_mse: 0.62593 |  0:00:15s\n",
      "epoch 62 | loss: 0.55224 | val_0_mse: 0.55685 |  0:00:16s\n",
      "epoch 63 | loss: 0.54897 | val_0_mse: 0.58699 |  0:00:16s\n",
      "epoch 64 | loss: 0.54584 | val_0_mse: 0.57635 |  0:00:16s\n",
      "epoch 65 | loss: 0.52352 | val_0_mse: 0.56003 |  0:00:16s\n",
      "epoch 66 | loss: 0.52671 | val_0_mse: 0.55772 |  0:00:17s\n",
      "epoch 67 | loss: 0.50478 | val_0_mse: 0.55407 |  0:00:17s\n",
      "epoch 68 | loss: 0.51089 | val_0_mse: 0.58326 |  0:00:17s\n",
      "epoch 69 | loss: 0.59012 | val_0_mse: 0.5457  |  0:00:17s\n",
      "epoch 70 | loss: 0.60982 | val_0_mse: 0.53559 |  0:00:18s\n",
      "epoch 71 | loss: 0.52808 | val_0_mse: 0.55004 |  0:00:18s\n",
      "epoch 72 | loss: 0.51439 | val_0_mse: 0.52783 |  0:00:18s\n",
      "epoch 73 | loss: 0.50732 | val_0_mse: 0.53747 |  0:00:18s\n",
      "epoch 74 | loss: 0.50048 | val_0_mse: 0.56894 |  0:00:19s\n",
      "epoch 75 | loss: 0.50981 | val_0_mse: 0.53833 |  0:00:19s\n",
      "epoch 76 | loss: 0.50525 | val_0_mse: 0.56072 |  0:00:19s\n",
      "epoch 77 | loss: 0.51565 | val_0_mse: 0.58697 |  0:00:19s\n",
      "epoch 78 | loss: 0.50486 | val_0_mse: 0.57052 |  0:00:20s\n",
      "epoch 79 | loss: 0.49526 | val_0_mse: 0.61726 |  0:00:20s\n",
      "epoch 80 | loss: 0.7027  | val_0_mse: 0.55109 |  0:00:20s\n",
      "epoch 81 | loss: 0.5801  | val_0_mse: 0.68556 |  0:00:20s\n",
      "epoch 82 | loss: 0.55673 | val_0_mse: 0.64467 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 0.52783\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4508... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77845</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">azure-sweep-21</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/jp27sz48\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/jp27sz48</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044734-jp27sz48/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yc8nnlra with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.10605881570172862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/yc8nnlra\" target=\"_blank\">deep-sweep-22</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.43705 | val_0_mse: 2.24126 |  0:00:00s\n",
      "epoch 1  | loss: 1.81491 | val_0_mse: 1.11437 |  0:00:00s\n",
      "epoch 2  | loss: 1.33869 | val_0_mse: 1.20937 |  0:00:00s\n",
      "epoch 3  | loss: 1.12989 | val_0_mse: 1.15229 |  0:00:01s\n",
      "epoch 4  | loss: 0.92504 | val_0_mse: 1.07117 |  0:00:01s\n",
      "epoch 5  | loss: 0.78398 | val_0_mse: 1.12148 |  0:00:01s\n",
      "epoch 6  | loss: 0.75045 | val_0_mse: 0.97744 |  0:00:01s\n",
      "epoch 7  | loss: 0.69248 | val_0_mse: 1.07601 |  0:00:02s\n",
      "epoch 8  | loss: 0.76421 | val_0_mse: 1.03469 |  0:00:02s\n",
      "epoch 9  | loss: 0.65235 | val_0_mse: 0.87288 |  0:00:02s\n",
      "epoch 10 | loss: 0.65038 | val_0_mse: 0.84417 |  0:00:02s\n",
      "epoch 11 | loss: 0.60914 | val_0_mse: 0.81426 |  0:00:03s\n",
      "epoch 12 | loss: 0.62102 | val_0_mse: 0.71654 |  0:00:03s\n",
      "epoch 13 | loss: 0.67234 | val_0_mse: 0.99578 |  0:00:03s\n",
      "epoch 14 | loss: 0.64033 | val_0_mse: 0.78501 |  0:00:03s\n",
      "epoch 15 | loss: 0.5816  | val_0_mse: 0.81619 |  0:00:04s\n",
      "epoch 16 | loss: 0.57022 | val_0_mse: 0.82849 |  0:00:04s\n",
      "epoch 17 | loss: 0.53659 | val_0_mse: 0.75366 |  0:00:04s\n",
      "epoch 18 | loss: 0.55546 | val_0_mse: 0.80572 |  0:00:05s\n",
      "epoch 19 | loss: 0.566   | val_0_mse: 0.67737 |  0:00:05s\n",
      "epoch 20 | loss: 0.67966 | val_0_mse: 0.97325 |  0:00:05s\n",
      "epoch 21 | loss: 0.74173 | val_0_mse: 0.72678 |  0:00:05s\n",
      "epoch 22 | loss: 0.7587  | val_0_mse: 1.0822  |  0:00:06s\n",
      "epoch 23 | loss: 0.95158 | val_0_mse: 0.76418 |  0:00:06s\n",
      "epoch 24 | loss: 0.75268 | val_0_mse: 0.74638 |  0:00:06s\n",
      "epoch 25 | loss: 0.55527 | val_0_mse: 0.73088 |  0:00:06s\n",
      "epoch 26 | loss: 0.55478 | val_0_mse: 0.74076 |  0:00:07s\n",
      "epoch 27 | loss: 0.53641 | val_0_mse: 0.68624 |  0:00:07s\n",
      "epoch 28 | loss: 0.55715 | val_0_mse: 0.76353 |  0:00:07s\n",
      "epoch 29 | loss: 0.53908 | val_0_mse: 0.77179 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.67737\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4595... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76426</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deep-sweep-22</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/yc8nnlra\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/yc8nnlra</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044802-yc8nnlra/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1q20c64x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.09286500382700356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1q20c64x\" target=\"_blank\">gallant-sweep-23</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.51396 | val_0_mse: 2.32881 |  0:00:00s\n",
      "epoch 1  | loss: 1.78904 | val_0_mse: 1.05468 |  0:00:00s\n",
      "epoch 2  | loss: 1.26368 | val_0_mse: 1.19971 |  0:00:00s\n",
      "epoch 3  | loss: 1.01651 | val_0_mse: 0.96386 |  0:00:00s\n",
      "epoch 4  | loss: 0.9204  | val_0_mse: 1.10594 |  0:00:00s\n",
      "epoch 5  | loss: 0.8532  | val_0_mse: 0.9721  |  0:00:01s\n",
      "epoch 6  | loss: 0.75411 | val_0_mse: 0.84638 |  0:00:01s\n",
      "epoch 7  | loss: 0.69271 | val_0_mse: 0.88418 |  0:00:01s\n",
      "epoch 8  | loss: 0.73701 | val_0_mse: 1.02468 |  0:00:01s\n",
      "epoch 9  | loss: 0.70119 | val_0_mse: 0.91136 |  0:00:01s\n",
      "epoch 10 | loss: 0.70623 | val_0_mse: 0.93231 |  0:00:01s\n",
      "epoch 11 | loss: 0.68959 | val_0_mse: 0.82758 |  0:00:02s\n",
      "epoch 12 | loss: 0.68964 | val_0_mse: 1.00382 |  0:00:02s\n",
      "epoch 13 | loss: 0.75817 | val_0_mse: 0.85716 |  0:00:02s\n",
      "epoch 14 | loss: 0.62894 | val_0_mse: 0.82281 |  0:00:02s\n",
      "epoch 15 | loss: 0.56732 | val_0_mse: 0.7876  |  0:00:02s\n",
      "epoch 16 | loss: 0.55964 | val_0_mse: 0.77248 |  0:00:02s\n",
      "epoch 17 | loss: 0.54627 | val_0_mse: 0.80774 |  0:00:02s\n",
      "epoch 18 | loss: 0.5507  | val_0_mse: 0.71508 |  0:00:03s\n",
      "epoch 19 | loss: 0.53699 | val_0_mse: 0.77464 |  0:00:03s\n",
      "epoch 20 | loss: 0.53384 | val_0_mse: 0.75183 |  0:00:03s\n",
      "epoch 21 | loss: 0.52011 | val_0_mse: 0.85784 |  0:00:03s\n",
      "epoch 22 | loss: 0.55699 | val_0_mse: 0.77181 |  0:00:03s\n",
      "epoch 23 | loss: 0.68869 | val_0_mse: 0.79985 |  0:00:03s\n",
      "epoch 24 | loss: 0.59998 | val_0_mse: 0.78555 |  0:00:04s\n",
      "epoch 25 | loss: 0.52809 | val_0_mse: 0.8047  |  0:00:04s\n",
      "epoch 26 | loss: 0.58897 | val_0_mse: 0.68182 |  0:00:04s\n",
      "epoch 27 | loss: 0.57388 | val_0_mse: 0.7726  |  0:00:04s\n",
      "epoch 28 | loss: 0.57041 | val_0_mse: 0.71424 |  0:00:04s\n",
      "epoch 29 | loss: 0.62059 | val_0_mse: 0.79174 |  0:00:04s\n",
      "epoch 30 | loss: 0.66811 | val_0_mse: 0.76935 |  0:00:05s\n",
      "epoch 31 | loss: 0.56403 | val_0_mse: 0.66183 |  0:00:05s\n",
      "epoch 32 | loss: 0.51766 | val_0_mse: 0.70054 |  0:00:05s\n",
      "epoch 33 | loss: 0.50477 | val_0_mse: 0.71139 |  0:00:05s\n",
      "epoch 34 | loss: 0.50891 | val_0_mse: 0.65118 |  0:00:05s\n",
      "epoch 35 | loss: 0.50183 | val_0_mse: 0.65548 |  0:00:05s\n",
      "epoch 36 | loss: 0.501   | val_0_mse: 0.61646 |  0:00:06s\n",
      "epoch 37 | loss: 0.50503 | val_0_mse: 0.6361  |  0:00:06s\n",
      "epoch 38 | loss: 0.49289 | val_0_mse: 0.66612 |  0:00:06s\n",
      "epoch 39 | loss: 0.48504 | val_0_mse: 0.60076 |  0:00:06s\n",
      "epoch 40 | loss: 0.49166 | val_0_mse: 0.66409 |  0:00:06s\n",
      "epoch 41 | loss: 0.50065 | val_0_mse: 0.61815 |  0:00:06s\n",
      "epoch 42 | loss: 0.4994  | val_0_mse: 0.6251  |  0:00:07s\n",
      "epoch 43 | loss: 0.50775 | val_0_mse: 0.61942 |  0:00:07s\n",
      "epoch 44 | loss: 0.50892 | val_0_mse: 0.57549 |  0:00:07s\n",
      "epoch 45 | loss: 0.49891 | val_0_mse: 0.56266 |  0:00:07s\n",
      "epoch 46 | loss: 0.51445 | val_0_mse: 0.58233 |  0:00:07s\n",
      "epoch 47 | loss: 0.50678 | val_0_mse: 0.64181 |  0:00:07s\n",
      "epoch 48 | loss: 0.52125 | val_0_mse: 0.6261  |  0:00:08s\n",
      "epoch 49 | loss: 0.51326 | val_0_mse: 0.59077 |  0:00:08s\n",
      "epoch 50 | loss: 0.53195 | val_0_mse: 0.61165 |  0:00:08s\n",
      "epoch 51 | loss: 0.52893 | val_0_mse: 0.57497 |  0:00:08s\n",
      "epoch 52 | loss: 0.53986 | val_0_mse: 0.63886 |  0:00:08s\n",
      "epoch 53 | loss: 0.51596 | val_0_mse: 0.54627 |  0:00:08s\n",
      "epoch 54 | loss: 0.49363 | val_0_mse: 0.58776 |  0:00:09s\n",
      "epoch 55 | loss: 0.50481 | val_0_mse: 0.56742 |  0:00:09s\n",
      "epoch 56 | loss: 0.50822 | val_0_mse: 0.57754 |  0:00:09s\n",
      "epoch 57 | loss: 0.4831  | val_0_mse: 0.56567 |  0:00:09s\n",
      "epoch 58 | loss: 0.49683 | val_0_mse: 0.54911 |  0:00:09s\n",
      "epoch 59 | loss: 0.47904 | val_0_mse: 0.55241 |  0:00:09s\n",
      "epoch 60 | loss: 0.48671 | val_0_mse: 0.52989 |  0:00:10s\n",
      "epoch 61 | loss: 0.47988 | val_0_mse: 0.53425 |  0:00:10s\n",
      "epoch 62 | loss: 0.47217 | val_0_mse: 0.56495 |  0:00:10s\n",
      "epoch 63 | loss: 0.50976 | val_0_mse: 0.57754 |  0:00:10s\n",
      "epoch 64 | loss: 0.60282 | val_0_mse: 0.54605 |  0:00:10s\n",
      "epoch 65 | loss: 0.49903 | val_0_mse: 0.55389 |  0:00:10s\n",
      "epoch 66 | loss: 0.48973 | val_0_mse: 0.52114 |  0:00:11s\n",
      "epoch 67 | loss: 0.48252 | val_0_mse: 0.54831 |  0:00:11s\n",
      "epoch 68 | loss: 0.4867  | val_0_mse: 0.53535 |  0:00:11s\n",
      "epoch 69 | loss: 0.48051 | val_0_mse: 0.52537 |  0:00:11s\n",
      "epoch 70 | loss: 0.48151 | val_0_mse: 0.53587 |  0:00:11s\n",
      "epoch 71 | loss: 0.47828 | val_0_mse: 0.56243 |  0:00:11s\n",
      "epoch 72 | loss: 0.49144 | val_0_mse: 0.54003 |  0:00:12s\n",
      "epoch 73 | loss: 0.5179  | val_0_mse: 0.56252 |  0:00:12s\n",
      "epoch 74 | loss: 0.52317 | val_0_mse: 0.54361 |  0:00:12s\n",
      "epoch 75 | loss: 0.48059 | val_0_mse: 0.53787 |  0:00:12s\n",
      "epoch 76 | loss: 0.46623 | val_0_mse: 0.54389 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.52114\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4638... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77849</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">gallant-sweep-23</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1q20c64x\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/1q20c64x</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044816-1q20c64x/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a4xnxydc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2061181944313308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/a4xnxydc\" target=\"_blank\">electric-sweep-24</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.66627 | val_0_mse: 2.21829 |  0:00:00s\n",
      "epoch 1  | loss: 1.44705 | val_0_mse: 0.93175 |  0:00:00s\n",
      "epoch 2  | loss: 1.13321 | val_0_mse: 1.37237 |  0:00:00s\n",
      "epoch 3  | loss: 0.8291  | val_0_mse: 1.23135 |  0:00:00s\n",
      "epoch 4  | loss: 0.70011 | val_0_mse: 0.99815 |  0:00:00s\n",
      "epoch 5  | loss: 0.62486 | val_0_mse: 1.14409 |  0:00:01s\n",
      "epoch 6  | loss: 0.61592 | val_0_mse: 1.31822 |  0:00:01s\n",
      "epoch 7  | loss: 0.59531 | val_0_mse: 0.9873  |  0:00:01s\n",
      "epoch 8  | loss: 0.58011 | val_0_mse: 0.90262 |  0:00:01s\n",
      "epoch 9  | loss: 0.56865 | val_0_mse: 0.88678 |  0:00:01s\n",
      "epoch 10 | loss: 0.55858 | val_0_mse: 0.85277 |  0:00:02s\n",
      "epoch 11 | loss: 0.56073 | val_0_mse: 0.84504 |  0:00:02s\n",
      "epoch 12 | loss: 0.54328 | val_0_mse: 0.89264 |  0:00:02s\n",
      "epoch 13 | loss: 0.53463 | val_0_mse: 0.88385 |  0:00:02s\n",
      "epoch 14 | loss: 0.52775 | val_0_mse: 0.84459 |  0:00:02s\n",
      "epoch 15 | loss: 0.5746  | val_0_mse: 1.0712  |  0:00:03s\n",
      "epoch 16 | loss: 0.59218 | val_0_mse: 0.72558 |  0:00:03s\n",
      "epoch 17 | loss: 0.54455 | val_0_mse: 0.8369  |  0:00:03s\n",
      "epoch 18 | loss: 0.50663 | val_0_mse: 0.74314 |  0:00:03s\n",
      "epoch 19 | loss: 0.51199 | val_0_mse: 0.8995  |  0:00:03s\n",
      "epoch 20 | loss: 0.52097 | val_0_mse: 0.79138 |  0:00:04s\n",
      "epoch 21 | loss: 0.51328 | val_0_mse: 0.81769 |  0:00:04s\n",
      "epoch 22 | loss: 0.51801 | val_0_mse: 0.72552 |  0:00:04s\n",
      "epoch 23 | loss: 0.51093 | val_0_mse: 0.72237 |  0:00:04s\n",
      "epoch 24 | loss: 0.4986  | val_0_mse: 0.7092  |  0:00:04s\n",
      "epoch 25 | loss: 0.49807 | val_0_mse: 0.7272  |  0:00:05s\n",
      "epoch 26 | loss: 0.49601 | val_0_mse: 0.7122  |  0:00:05s\n",
      "epoch 27 | loss: 0.49521 | val_0_mse: 0.77235 |  0:00:05s\n",
      "epoch 28 | loss: 0.49138 | val_0_mse: 0.72857 |  0:00:05s\n",
      "epoch 29 | loss: 0.48414 | val_0_mse: 0.69146 |  0:00:05s\n",
      "epoch 30 | loss: 0.49585 | val_0_mse: 0.71919 |  0:00:06s\n",
      "epoch 31 | loss: 0.48905 | val_0_mse: 0.68522 |  0:00:06s\n",
      "epoch 32 | loss: 0.48553 | val_0_mse: 0.69597 |  0:00:06s\n",
      "epoch 33 | loss: 0.48585 | val_0_mse: 0.63879 |  0:00:06s\n",
      "epoch 34 | loss: 0.53324 | val_0_mse: 0.82584 |  0:00:06s\n",
      "epoch 35 | loss: 0.60109 | val_0_mse: 0.66163 |  0:00:07s\n",
      "epoch 36 | loss: 0.58013 | val_0_mse: 0.70271 |  0:00:07s\n",
      "epoch 37 | loss: 0.51719 | val_0_mse: 0.58912 |  0:00:07s\n",
      "epoch 38 | loss: 0.51325 | val_0_mse: 0.63375 |  0:00:07s\n",
      "epoch 39 | loss: 0.50185 | val_0_mse: 0.761   |  0:00:07s\n",
      "epoch 40 | loss: 0.54726 | val_0_mse: 0.60032 |  0:00:08s\n",
      "epoch 41 | loss: 0.67957 | val_0_mse: 0.61108 |  0:00:08s\n",
      "epoch 42 | loss: 0.50835 | val_0_mse: 0.65159 |  0:00:08s\n",
      "epoch 43 | loss: 0.50224 | val_0_mse: 0.64964 |  0:00:08s\n",
      "epoch 44 | loss: 0.49118 | val_0_mse: 0.59004 |  0:00:08s\n",
      "epoch 45 | loss: 0.49003 | val_0_mse: 0.59332 |  0:00:09s\n",
      "epoch 46 | loss: 0.48681 | val_0_mse: 0.71237 |  0:00:09s\n",
      "epoch 47 | loss: 0.50988 | val_0_mse: 0.58134 |  0:00:09s\n",
      "epoch 48 | loss: 0.49609 | val_0_mse: 0.58483 |  0:00:09s\n",
      "epoch 49 | loss: 0.4856  | val_0_mse: 0.56226 |  0:00:09s\n",
      "epoch 50 | loss: 0.48554 | val_0_mse: 0.58674 |  0:00:10s\n",
      "epoch 51 | loss: 0.48839 | val_0_mse: 0.57867 |  0:00:10s\n",
      "epoch 52 | loss: 0.47949 | val_0_mse: 0.58022 |  0:00:10s\n",
      "epoch 53 | loss: 0.47878 | val_0_mse: 0.52911 |  0:00:10s\n",
      "epoch 54 | loss: 0.49225 | val_0_mse: 0.54249 |  0:00:10s\n",
      "epoch 55 | loss: 0.49706 | val_0_mse: 0.56368 |  0:00:11s\n",
      "epoch 56 | loss: 0.48033 | val_0_mse: 0.51648 |  0:00:11s\n",
      "epoch 57 | loss: 0.49765 | val_0_mse: 0.57843 |  0:00:11s\n",
      "epoch 58 | loss: 0.49534 | val_0_mse: 0.5207  |  0:00:11s\n",
      "epoch 59 | loss: 0.49198 | val_0_mse: 0.54869 |  0:00:11s\n",
      "epoch 60 | loss: 0.49444 | val_0_mse: 0.58036 |  0:00:12s\n",
      "epoch 61 | loss: 0.50858 | val_0_mse: 0.53128 |  0:00:12s\n",
      "epoch 62 | loss: 0.48824 | val_0_mse: 0.56794 |  0:00:12s\n",
      "epoch 63 | loss: 0.48925 | val_0_mse: 0.52258 |  0:00:12s\n",
      "epoch 64 | loss: 0.47716 | val_0_mse: 0.51647 |  0:00:13s\n",
      "epoch 65 | loss: 0.48052 | val_0_mse: 0.57884 |  0:00:13s\n",
      "epoch 66 | loss: 0.49467 | val_0_mse: 0.524   |  0:00:13s\n",
      "epoch 67 | loss: 0.48415 | val_0_mse: 0.51449 |  0:00:13s\n",
      "epoch 68 | loss: 0.48104 | val_0_mse: 0.56406 |  0:00:13s\n",
      "epoch 69 | loss: 0.49384 | val_0_mse: 0.53086 |  0:00:14s\n",
      "epoch 70 | loss: 0.48567 | val_0_mse: 0.51689 |  0:00:14s\n",
      "epoch 71 | loss: 0.48391 | val_0_mse: 0.5144  |  0:00:14s\n",
      "epoch 72 | loss: 0.47308 | val_0_mse: 0.51739 |  0:00:14s\n",
      "epoch 73 | loss: 0.47727 | val_0_mse: 0.50897 |  0:00:14s\n",
      "epoch 74 | loss: 0.46795 | val_0_mse: 0.53496 |  0:00:15s\n",
      "epoch 75 | loss: 0.48082 | val_0_mse: 0.51367 |  0:00:15s\n",
      "epoch 76 | loss: 0.48063 | val_0_mse: 0.52367 |  0:00:15s\n",
      "epoch 77 | loss: 0.48182 | val_0_mse: 0.51094 |  0:00:15s\n",
      "epoch 78 | loss: 0.49587 | val_0_mse: 0.50361 |  0:00:15s\n",
      "epoch 79 | loss: 0.48894 | val_0_mse: 0.51946 |  0:00:16s\n",
      "epoch 80 | loss: 0.47595 | val_0_mse: 0.50785 |  0:00:16s\n",
      "epoch 81 | loss: 0.47308 | val_0_mse: 0.50395 |  0:00:16s\n",
      "epoch 82 | loss: 0.47529 | val_0_mse: 0.5438  |  0:00:16s\n",
      "epoch 83 | loss: 0.49128 | val_0_mse: 0.56296 |  0:00:16s\n",
      "epoch 84 | loss: 0.49706 | val_0_mse: 0.58366 |  0:00:17s\n",
      "epoch 85 | loss: 0.64685 | val_0_mse: 0.53845 |  0:00:17s\n",
      "epoch 86 | loss: 0.49954 | val_0_mse: 0.5595  |  0:00:17s\n",
      "epoch 87 | loss: 0.47056 | val_0_mse: 0.51156 |  0:00:17s\n",
      "epoch 88 | loss: 0.47642 | val_0_mse: 0.49941 |  0:00:17s\n",
      "epoch 89 | loss: 0.49831 | val_0_mse: 0.60287 |  0:00:18s\n",
      "epoch 90 | loss: 0.57518 | val_0_mse: 0.54076 |  0:00:18s\n",
      "epoch 91 | loss: 0.52005 | val_0_mse: 0.55787 |  0:00:18s\n",
      "epoch 92 | loss: 0.51464 | val_0_mse: 0.51544 |  0:00:18s\n",
      "epoch 93 | loss: 0.48967 | val_0_mse: 0.5748  |  0:00:18s\n",
      "epoch 94 | loss: 0.49573 | val_0_mse: 0.52515 |  0:00:19s\n",
      "epoch 95 | loss: 0.50148 | val_0_mse: 0.54964 |  0:00:19s\n",
      "epoch 96 | loss: 0.51744 | val_0_mse: 0.51318 |  0:00:19s\n",
      "epoch 97 | loss: 0.49532 | val_0_mse: 0.53867 |  0:00:19s\n",
      "epoch 98 | loss: 0.49628 | val_0_mse: 0.50538 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 98 with best_epoch = 88 and best_val_0_mse = 0.49941\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4687... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.79359</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">electric-sweep-24</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/a4xnxydc\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/a4xnxydc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044834-a4xnxydc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s0n8s4vg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.15147238326410728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/s0n8s4vg\" target=\"_blank\">fine-sweep-25</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 15.31974| val_0_mse: 1.52697 |  0:00:00s\n",
      "epoch 1  | loss: 3.66572 | val_0_mse: 1.55869 |  0:00:00s\n",
      "epoch 2  | loss: 2.05441 | val_0_mse: 1.41801 |  0:00:00s\n",
      "epoch 3  | loss: 1.28888 | val_0_mse: 0.84515 |  0:00:00s\n",
      "epoch 4  | loss: 0.98457 | val_0_mse: 0.88362 |  0:00:00s\n",
      "epoch 5  | loss: 0.75133 | val_0_mse: 0.90454 |  0:00:01s\n",
      "epoch 6  | loss: 0.64545 | val_0_mse: 0.91819 |  0:00:01s\n",
      "epoch 7  | loss: 0.6125  | val_0_mse: 0.83646 |  0:00:01s\n",
      "epoch 8  | loss: 0.59041 | val_0_mse: 0.83644 |  0:00:01s\n",
      "epoch 9  | loss: 0.55383 | val_0_mse: 0.84926 |  0:00:01s\n",
      "epoch 10 | loss: 0.55014 | val_0_mse: 0.79807 |  0:00:01s\n",
      "epoch 11 | loss: 0.52711 | val_0_mse: 0.74923 |  0:00:02s\n",
      "epoch 12 | loss: 0.52946 | val_0_mse: 0.76154 |  0:00:02s\n",
      "epoch 13 | loss: 0.51628 | val_0_mse: 0.76995 |  0:00:02s\n",
      "epoch 14 | loss: 0.5181  | val_0_mse: 0.76114 |  0:00:02s\n",
      "epoch 15 | loss: 0.51979 | val_0_mse: 0.71238 |  0:00:02s\n",
      "epoch 16 | loss: 0.54188 | val_0_mse: 0.85714 |  0:00:02s\n",
      "epoch 17 | loss: 0.54462 | val_0_mse: 0.67496 |  0:00:03s\n",
      "epoch 18 | loss: 0.52764 | val_0_mse: 0.70715 |  0:00:03s\n",
      "epoch 19 | loss: 0.52202 | val_0_mse: 0.70953 |  0:00:03s\n",
      "epoch 20 | loss: 0.524   | val_0_mse: 0.69695 |  0:00:03s\n",
      "epoch 21 | loss: 0.51616 | val_0_mse: 0.70357 |  0:00:03s\n",
      "epoch 22 | loss: 0.50099 | val_0_mse: 0.67593 |  0:00:03s\n",
      "epoch 23 | loss: 0.50806 | val_0_mse: 0.66372 |  0:00:04s\n",
      "epoch 24 | loss: 0.51872 | val_0_mse: 0.66747 |  0:00:04s\n",
      "epoch 25 | loss: 0.5316  | val_0_mse: 0.75139 |  0:00:04s\n",
      "epoch 26 | loss: 0.51435 | val_0_mse: 0.71116 |  0:00:04s\n",
      "epoch 27 | loss: 0.51667 | val_0_mse: 0.77599 |  0:00:04s\n",
      "epoch 28 | loss: 0.52301 | val_0_mse: 0.68283 |  0:00:04s\n",
      "epoch 29 | loss: 0.52683 | val_0_mse: 0.74228 |  0:00:05s\n",
      "epoch 30 | loss: 0.52524 | val_0_mse: 0.64933 |  0:00:05s\n",
      "epoch 31 | loss: 0.51194 | val_0_mse: 0.67565 |  0:00:05s\n",
      "epoch 32 | loss: 0.50508 | val_0_mse: 0.65794 |  0:00:05s\n",
      "epoch 33 | loss: 0.49674 | val_0_mse: 0.62125 |  0:00:05s\n",
      "epoch 34 | loss: 0.48668 | val_0_mse: 0.61256 |  0:00:06s\n",
      "epoch 35 | loss: 0.5088  | val_0_mse: 0.60721 |  0:00:06s\n",
      "epoch 36 | loss: 0.51284 | val_0_mse: 0.63149 |  0:00:06s\n",
      "epoch 37 | loss: 0.51419 | val_0_mse: 0.63152 |  0:00:06s\n",
      "epoch 38 | loss: 0.51645 | val_0_mse: 0.63342 |  0:00:06s\n",
      "epoch 39 | loss: 0.51204 | val_0_mse: 0.6328  |  0:00:07s\n",
      "epoch 40 | loss: 0.51246 | val_0_mse: 0.64409 |  0:00:07s\n",
      "epoch 41 | loss: 0.50466 | val_0_mse: 0.62095 |  0:00:07s\n",
      "epoch 42 | loss: 0.50881 | val_0_mse: 0.63223 |  0:00:07s\n",
      "epoch 43 | loss: 0.50299 | val_0_mse: 0.61184 |  0:00:07s\n",
      "epoch 44 | loss: 0.49982 | val_0_mse: 0.61429 |  0:00:07s\n",
      "epoch 45 | loss: 0.49289 | val_0_mse: 0.59844 |  0:00:08s\n",
      "epoch 46 | loss: 0.49609 | val_0_mse: 0.58754 |  0:00:08s\n",
      "epoch 47 | loss: 0.48762 | val_0_mse: 0.56962 |  0:00:08s\n",
      "epoch 48 | loss: 0.49151 | val_0_mse: 0.59578 |  0:00:08s\n",
      "epoch 49 | loss: 0.50085 | val_0_mse: 0.58733 |  0:00:08s\n",
      "epoch 50 | loss: 0.49659 | val_0_mse: 0.62156 |  0:00:08s\n",
      "epoch 51 | loss: 0.50497 | val_0_mse: 0.58079 |  0:00:09s\n",
      "epoch 52 | loss: 0.49996 | val_0_mse: 0.62075 |  0:00:09s\n",
      "epoch 53 | loss: 0.49014 | val_0_mse: 0.55889 |  0:00:09s\n",
      "epoch 54 | loss: 0.48892 | val_0_mse: 0.61334 |  0:00:09s\n",
      "epoch 55 | loss: 0.51654 | val_0_mse: 0.54944 |  0:00:09s\n",
      "epoch 56 | loss: 0.50663 | val_0_mse: 0.58641 |  0:00:10s\n",
      "epoch 57 | loss: 0.48886 | val_0_mse: 0.57323 |  0:00:10s\n",
      "epoch 58 | loss: 0.50094 | val_0_mse: 0.56942 |  0:00:10s\n",
      "epoch 59 | loss: 0.5427  | val_0_mse: 0.63762 |  0:00:10s\n",
      "epoch 60 | loss: 0.55464 | val_0_mse: 0.57071 |  0:00:10s\n",
      "epoch 61 | loss: 0.51695 | val_0_mse: 0.55303 |  0:00:10s\n",
      "epoch 62 | loss: 0.49322 | val_0_mse: 0.56337 |  0:00:11s\n",
      "epoch 63 | loss: 0.49283 | val_0_mse: 0.58058 |  0:00:11s\n",
      "epoch 64 | loss: 0.4893  | val_0_mse: 0.54566 |  0:00:11s\n",
      "epoch 65 | loss: 0.49457 | val_0_mse: 0.55046 |  0:00:11s\n",
      "epoch 66 | loss: 0.48177 | val_0_mse: 0.55169 |  0:00:11s\n",
      "epoch 67 | loss: 0.49601 | val_0_mse: 0.57378 |  0:00:11s\n",
      "epoch 68 | loss: 0.4933  | val_0_mse: 0.56909 |  0:00:12s\n",
      "epoch 69 | loss: 0.50244 | val_0_mse: 0.58562 |  0:00:12s\n",
      "epoch 70 | loss: 0.4969  | val_0_mse: 0.55778 |  0:00:12s\n",
      "epoch 71 | loss: 0.50292 | val_0_mse: 0.58325 |  0:00:12s\n",
      "epoch 72 | loss: 0.50059 | val_0_mse: 0.54769 |  0:00:12s\n",
      "epoch 73 | loss: 0.49522 | val_0_mse: 0.54376 |  0:00:12s\n",
      "epoch 74 | loss: 0.48302 | val_0_mse: 0.52102 |  0:00:13s\n",
      "epoch 75 | loss: 0.48226 | val_0_mse: 0.5454  |  0:00:13s\n",
      "epoch 76 | loss: 0.48385 | val_0_mse: 0.51996 |  0:00:13s\n",
      "epoch 77 | loss: 0.48492 | val_0_mse: 0.53573 |  0:00:13s\n",
      "epoch 78 | loss: 0.51481 | val_0_mse: 0.54924 |  0:00:13s\n",
      "epoch 79 | loss: 0.50262 | val_0_mse: 0.53808 |  0:00:14s\n",
      "epoch 80 | loss: 0.4987  | val_0_mse: 0.55757 |  0:00:14s\n",
      "epoch 81 | loss: 0.53021 | val_0_mse: 0.54728 |  0:00:14s\n",
      "epoch 82 | loss: 0.54288 | val_0_mse: 0.5267  |  0:00:14s\n",
      "epoch 83 | loss: 0.49485 | val_0_mse: 0.53446 |  0:00:14s\n",
      "epoch 84 | loss: 0.49951 | val_0_mse: 0.5703  |  0:00:14s\n",
      "epoch 85 | loss: 0.51132 | val_0_mse: 0.54998 |  0:00:15s\n",
      "epoch 86 | loss: 0.51434 | val_0_mse: 0.54287 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.51996\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4735... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78091</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fine-sweep-25</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/s0n8s4vg\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/s0n8s4vg</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044900-s0n8s4vg/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z8uzrbzi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2764450955224207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/z8uzrbzi\" target=\"_blank\">balmy-sweep-26</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.57774 | val_0_mse: 2.71865 |  0:00:00s\n",
      "epoch 1  | loss: 2.73406 | val_0_mse: 1.95405 |  0:00:00s\n",
      "epoch 2  | loss: 1.51013 | val_0_mse: 1.68479 |  0:00:00s\n",
      "epoch 3  | loss: 1.04828 | val_0_mse: 0.96062 |  0:00:00s\n",
      "epoch 4  | loss: 0.81406 | val_0_mse: 1.15053 |  0:00:01s\n",
      "epoch 5  | loss: 0.65837 | val_0_mse: 0.87807 |  0:00:01s\n",
      "epoch 6  | loss: 0.65601 | val_0_mse: 0.85878 |  0:00:01s\n",
      "epoch 7  | loss: 0.59509 | val_0_mse: 0.83287 |  0:00:01s\n",
      "epoch 8  | loss: 0.57252 | val_0_mse: 0.78073 |  0:00:02s\n",
      "epoch 9  | loss: 0.58469 | val_0_mse: 0.77138 |  0:00:02s\n",
      "epoch 10 | loss: 0.56087 | val_0_mse: 0.8484  |  0:00:02s\n",
      "epoch 11 | loss: 0.5595  | val_0_mse: 0.79622 |  0:00:02s\n",
      "epoch 12 | loss: 0.54215 | val_0_mse: 0.79227 |  0:00:03s\n",
      "epoch 13 | loss: 0.55354 | val_0_mse: 0.92848 |  0:00:03s\n",
      "epoch 14 | loss: 0.59838 | val_0_mse: 0.69521 |  0:00:03s\n",
      "epoch 15 | loss: 0.58038 | val_0_mse: 0.8775  |  0:00:03s\n",
      "epoch 16 | loss: 0.55883 | val_0_mse: 0.766   |  0:00:03s\n",
      "epoch 17 | loss: 0.54431 | val_0_mse: 0.70154 |  0:00:04s\n",
      "epoch 18 | loss: 0.52346 | val_0_mse: 0.81486 |  0:00:04s\n",
      "epoch 19 | loss: 0.58928 | val_0_mse: 0.69923 |  0:00:04s\n",
      "epoch 20 | loss: 0.62007 | val_0_mse: 0.75701 |  0:00:04s\n",
      "epoch 21 | loss: 0.56439 | val_0_mse: 0.70539 |  0:00:05s\n",
      "epoch 22 | loss: 0.58062 | val_0_mse: 0.76489 |  0:00:05s\n",
      "epoch 23 | loss: 0.5532  | val_0_mse: 0.63963 |  0:00:05s\n",
      "epoch 24 | loss: 0.5594  | val_0_mse: 0.76175 |  0:00:05s\n",
      "epoch 25 | loss: 0.54566 | val_0_mse: 0.7175  |  0:00:05s\n",
      "epoch 26 | loss: 0.52474 | val_0_mse: 0.71498 |  0:00:06s\n",
      "epoch 27 | loss: 0.51639 | val_0_mse: 0.72456 |  0:00:06s\n",
      "epoch 28 | loss: 0.52733 | val_0_mse: 0.76671 |  0:00:06s\n",
      "epoch 29 | loss: 0.52332 | val_0_mse: 0.75636 |  0:00:06s\n",
      "epoch 30 | loss: 0.52838 | val_0_mse: 0.65755 |  0:00:07s\n",
      "epoch 31 | loss: 0.54268 | val_0_mse: 0.7283  |  0:00:07s\n",
      "epoch 32 | loss: 0.51192 | val_0_mse: 0.72708 |  0:00:07s\n",
      "epoch 33 | loss: 0.52541 | val_0_mse: 0.79675 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.63963\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4780... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77427</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">balmy-sweep-26</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/z8uzrbzi\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/z8uzrbzi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044922-z8uzrbzi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iwgaehvq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.15733718434263816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/iwgaehvq\" target=\"_blank\">ethereal-sweep-27</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 17.96384| val_0_mse: 3.27236 |  0:00:00s\n",
      "epoch 1  | loss: 3.52661 | val_0_mse: 1.72933 |  0:00:00s\n",
      "epoch 2  | loss: 2.58111 | val_0_mse: 2.45113 |  0:00:00s\n",
      "epoch 3  | loss: 1.86608 | val_0_mse: 2.53825 |  0:00:00s\n",
      "epoch 4  | loss: 1.39572 | val_0_mse: 1.62289 |  0:00:00s\n",
      "epoch 5  | loss: 1.27848 | val_0_mse: 1.40987 |  0:00:01s\n",
      "epoch 6  | loss: 0.77946 | val_0_mse: 1.21432 |  0:00:01s\n",
      "epoch 7  | loss: 0.6891  | val_0_mse: 1.24284 |  0:00:01s\n",
      "epoch 8  | loss: 0.65789 | val_0_mse: 1.15554 |  0:00:01s\n",
      "epoch 9  | loss: 0.60697 | val_0_mse: 0.99328 |  0:00:01s\n",
      "epoch 10 | loss: 0.59788 | val_0_mse: 1.1097  |  0:00:01s\n",
      "epoch 11 | loss: 0.56687 | val_0_mse: 1.00523 |  0:00:02s\n",
      "epoch 12 | loss: 0.5436  | val_0_mse: 0.86495 |  0:00:02s\n",
      "epoch 13 | loss: 0.56488 | val_0_mse: 0.87908 |  0:00:02s\n",
      "epoch 14 | loss: 0.53068 | val_0_mse: 1.01905 |  0:00:02s\n",
      "epoch 15 | loss: 0.54272 | val_0_mse: 0.80373 |  0:00:02s\n",
      "epoch 16 | loss: 0.53182 | val_0_mse: 0.77701 |  0:00:03s\n",
      "epoch 17 | loss: 0.51583 | val_0_mse: 0.79641 |  0:00:03s\n",
      "epoch 18 | loss: 0.51192 | val_0_mse: 0.74805 |  0:00:03s\n",
      "epoch 19 | loss: 0.51204 | val_0_mse: 0.84677 |  0:00:03s\n",
      "epoch 20 | loss: 0.54835 | val_0_mse: 0.73421 |  0:00:03s\n",
      "epoch 21 | loss: 0.53358 | val_0_mse: 0.89068 |  0:00:03s\n",
      "epoch 22 | loss: 0.55667 | val_0_mse: 0.72687 |  0:00:04s\n",
      "epoch 23 | loss: 0.55496 | val_0_mse: 0.84802 |  0:00:04s\n",
      "epoch 24 | loss: 0.54564 | val_0_mse: 0.69655 |  0:00:04s\n",
      "epoch 25 | loss: 0.57262 | val_0_mse: 0.86795 |  0:00:04s\n",
      "epoch 26 | loss: 0.69017 | val_0_mse: 0.72799 |  0:00:04s\n",
      "epoch 27 | loss: 0.54881 | val_0_mse: 0.68845 |  0:00:05s\n",
      "epoch 28 | loss: 0.53134 | val_0_mse: 0.69788 |  0:00:05s\n",
      "epoch 29 | loss: 0.53211 | val_0_mse: 0.69142 |  0:00:05s\n",
      "epoch 30 | loss: 0.51537 | val_0_mse: 0.71117 |  0:00:05s\n",
      "epoch 31 | loss: 0.5138  | val_0_mse: 0.61129 |  0:00:05s\n",
      "epoch 32 | loss: 0.54214 | val_0_mse: 0.70282 |  0:00:06s\n",
      "epoch 33 | loss: 0.54223 | val_0_mse: 0.62805 |  0:00:06s\n",
      "epoch 34 | loss: 0.49808 | val_0_mse: 0.66771 |  0:00:06s\n",
      "epoch 35 | loss: 0.49648 | val_0_mse: 0.6496  |  0:00:06s\n",
      "epoch 36 | loss: 0.4995  | val_0_mse: 0.63251 |  0:00:06s\n",
      "epoch 37 | loss: 0.50113 | val_0_mse: 0.63991 |  0:00:06s\n",
      "epoch 38 | loss: 0.48692 | val_0_mse: 0.61973 |  0:00:07s\n",
      "epoch 39 | loss: 0.49004 | val_0_mse: 0.6482  |  0:00:07s\n",
      "epoch 40 | loss: 0.49611 | val_0_mse: 0.58704 |  0:00:07s\n",
      "epoch 41 | loss: 0.4935  | val_0_mse: 0.59671 |  0:00:07s\n",
      "epoch 42 | loss: 0.50232 | val_0_mse: 0.60301 |  0:00:07s\n",
      "epoch 43 | loss: 0.50496 | val_0_mse: 0.60435 |  0:00:07s\n",
      "epoch 44 | loss: 0.50424 | val_0_mse: 0.57323 |  0:00:08s\n",
      "epoch 45 | loss: 0.52775 | val_0_mse: 0.63922 |  0:00:08s\n",
      "epoch 46 | loss: 0.5167  | val_0_mse: 0.58882 |  0:00:08s\n",
      "epoch 47 | loss: 0.53132 | val_0_mse: 0.65077 |  0:00:08s\n",
      "epoch 48 | loss: 0.52132 | val_0_mse: 0.57546 |  0:00:09s\n",
      "epoch 49 | loss: 0.5154  | val_0_mse: 0.62181 |  0:00:09s\n",
      "epoch 50 | loss: 0.52041 | val_0_mse: 0.62262 |  0:00:09s\n",
      "epoch 51 | loss: 0.52966 | val_0_mse: 0.56709 |  0:00:09s\n",
      "epoch 52 | loss: 0.51853 | val_0_mse: 0.54727 |  0:00:09s\n",
      "epoch 53 | loss: 0.51074 | val_0_mse: 0.56395 |  0:00:09s\n",
      "epoch 54 | loss: 0.49729 | val_0_mse: 0.57965 |  0:00:10s\n",
      "epoch 55 | loss: 0.51236 | val_0_mse: 0.53526 |  0:00:10s\n",
      "epoch 56 | loss: 0.51815 | val_0_mse: 0.60604 |  0:00:10s\n",
      "epoch 57 | loss: 0.50405 | val_0_mse: 0.531   |  0:00:10s\n",
      "epoch 58 | loss: 0.49152 | val_0_mse: 0.53987 |  0:00:10s\n",
      "epoch 59 | loss: 0.50376 | val_0_mse: 0.56987 |  0:00:11s\n",
      "epoch 60 | loss: 0.49523 | val_0_mse: 0.57038 |  0:00:11s\n",
      "epoch 61 | loss: 0.51941 | val_0_mse: 0.53549 |  0:00:11s\n",
      "epoch 62 | loss: 0.52128 | val_0_mse: 0.59877 |  0:00:11s\n",
      "epoch 63 | loss: 0.50539 | val_0_mse: 0.54735 |  0:00:11s\n",
      "epoch 64 | loss: 0.5371  | val_0_mse: 0.57744 |  0:00:11s\n",
      "epoch 65 | loss: 0.50508 | val_0_mse: 0.53142 |  0:00:12s\n",
      "epoch 66 | loss: 0.48837 | val_0_mse: 0.53768 |  0:00:12s\n",
      "epoch 67 | loss: 0.53684 | val_0_mse: 0.61847 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 0.531\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4835... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78145</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-27</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/iwgaehvq\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/iwgaehvq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044935-iwgaehvq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0hxb9qyz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2735409937820468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/0hxb9qyz\" target=\"_blank\">cosmic-sweep-28</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 18.06232| val_0_mse: 3.03886 |  0:00:00s\n",
      "epoch 1  | loss: 3.05062 | val_0_mse: 0.99681 |  0:00:00s\n",
      "epoch 2  | loss: 1.78386 | val_0_mse: 1.11818 |  0:00:00s\n",
      "epoch 3  | loss: 1.15519 | val_0_mse: 0.79174 |  0:00:00s\n",
      "epoch 4  | loss: 1.03856 | val_0_mse: 1.40884 |  0:00:01s\n",
      "epoch 5  | loss: 0.81486 | val_0_mse: 0.90532 |  0:00:01s\n",
      "epoch 6  | loss: 0.68038 | val_0_mse: 0.87752 |  0:00:01s\n",
      "epoch 7  | loss: 0.59859 | val_0_mse: 1.11942 |  0:00:01s\n",
      "epoch 8  | loss: 0.61668 | val_0_mse: 0.75512 |  0:00:02s\n",
      "epoch 9  | loss: 0.688   | val_0_mse: 1.01071 |  0:00:02s\n",
      "epoch 10 | loss: 0.7645  | val_0_mse: 0.90503 |  0:00:02s\n",
      "epoch 11 | loss: 0.65977 | val_0_mse: 0.70221 |  0:00:02s\n",
      "epoch 12 | loss: 0.59171 | val_0_mse: 0.74748 |  0:00:03s\n",
      "epoch 13 | loss: 0.59567 | val_0_mse: 0.8461  |  0:00:03s\n",
      "epoch 14 | loss: 0.62299 | val_0_mse: 0.89536 |  0:00:03s\n",
      "epoch 15 | loss: 0.61122 | val_0_mse: 0.91274 |  0:00:03s\n",
      "epoch 16 | loss: 0.57702 | val_0_mse: 0.84358 |  0:00:03s\n",
      "epoch 17 | loss: 0.55954 | val_0_mse: 0.70083 |  0:00:04s\n",
      "epoch 18 | loss: 0.56754 | val_0_mse: 0.77756 |  0:00:04s\n",
      "epoch 19 | loss: 0.56081 | val_0_mse: 0.79505 |  0:00:04s\n",
      "epoch 20 | loss: 0.58479 | val_0_mse: 0.83662 |  0:00:04s\n",
      "epoch 21 | loss: 0.70535 | val_0_mse: 0.80228 |  0:00:05s\n",
      "epoch 22 | loss: 0.67591 | val_0_mse: 0.87751 |  0:00:05s\n",
      "epoch 23 | loss: 0.58577 | val_0_mse: 0.86238 |  0:00:05s\n",
      "epoch 24 | loss: 0.57513 | val_0_mse: 0.85352 |  0:00:05s\n",
      "epoch 25 | loss: 0.56284 | val_0_mse: 0.8088  |  0:00:06s\n",
      "epoch 26 | loss: 0.54255 | val_0_mse: 0.81131 |  0:00:06s\n",
      "epoch 27 | loss: 0.53637 | val_0_mse: 0.79634 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 0.70083\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4912... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.75749</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cosmic-sweep-28</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/0hxb9qyz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/0hxb9qyz</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_044954-0hxb9qyz/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k4wzdwu4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2019712423444414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/k4wzdwu4\" target=\"_blank\">royal-sweep-29</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 24.7485 | val_0_mse: 2.95939 |  0:00:00s\n",
      "epoch 1  | loss: 5.42432 | val_0_mse: 2.91286 |  0:00:00s\n",
      "epoch 2  | loss: 3.04344 | val_0_mse: 1.88133 |  0:00:00s\n",
      "epoch 3  | loss: 1.47217 | val_0_mse: 1.17877 |  0:00:00s\n",
      "epoch 4  | loss: 1.07367 | val_0_mse: 1.43604 |  0:00:01s\n",
      "epoch 5  | loss: 0.87509 | val_0_mse: 1.71613 |  0:00:01s\n",
      "epoch 6  | loss: 0.82205 | val_0_mse: 1.04672 |  0:00:01s\n",
      "epoch 7  | loss: 0.7548  | val_0_mse: 1.14116 |  0:00:01s\n",
      "epoch 8  | loss: 0.67923 | val_0_mse: 1.12289 |  0:00:01s\n",
      "epoch 9  | loss: 0.64967 | val_0_mse: 0.88148 |  0:00:02s\n",
      "epoch 10 | loss: 0.59947 | val_0_mse: 0.86941 |  0:00:02s\n",
      "epoch 11 | loss: 0.62659 | val_0_mse: 1.05369 |  0:00:02s\n",
      "epoch 12 | loss: 0.65436 | val_0_mse: 0.87821 |  0:00:02s\n",
      "epoch 13 | loss: 0.63978 | val_0_mse: 0.8211  |  0:00:03s\n",
      "epoch 14 | loss: 0.58974 | val_0_mse: 0.85072 |  0:00:03s\n",
      "epoch 15 | loss: 0.58948 | val_0_mse: 0.92867 |  0:00:03s\n",
      "epoch 16 | loss: 0.62855 | val_0_mse: 0.99275 |  0:00:03s\n",
      "epoch 17 | loss: 0.63558 | val_0_mse: 0.79798 |  0:00:03s\n",
      "epoch 18 | loss: 0.63671 | val_0_mse: 0.84814 |  0:00:04s\n",
      "epoch 19 | loss: 0.56599 | val_0_mse: 0.73494 |  0:00:04s\n",
      "epoch 20 | loss: 0.57744 | val_0_mse: 0.74835 |  0:00:04s\n",
      "epoch 21 | loss: 0.55145 | val_0_mse: 0.75812 |  0:00:05s\n",
      "epoch 22 | loss: 0.55929 | val_0_mse: 0.68905 |  0:00:05s\n",
      "epoch 23 | loss: 0.58429 | val_0_mse: 0.81248 |  0:00:05s\n",
      "epoch 24 | loss: 0.56961 | val_0_mse: 0.76813 |  0:00:05s\n",
      "epoch 25 | loss: 0.59153 | val_0_mse: 0.7857  |  0:00:05s\n",
      "epoch 26 | loss: 0.56463 | val_0_mse: 0.66252 |  0:00:06s\n",
      "epoch 27 | loss: 0.55971 | val_0_mse: 0.65637 |  0:00:06s\n",
      "epoch 28 | loss: 0.63769 | val_0_mse: 0.70998 |  0:00:06s\n",
      "epoch 29 | loss: 0.56135 | val_0_mse: 0.64767 |  0:00:06s\n",
      "epoch 30 | loss: 0.58453 | val_0_mse: 0.76196 |  0:00:07s\n",
      "epoch 31 | loss: 0.56354 | val_0_mse: 0.629   |  0:00:07s\n",
      "epoch 32 | loss: 0.55245 | val_0_mse: 0.61281 |  0:00:07s\n",
      "epoch 33 | loss: 0.53517 | val_0_mse: 0.64517 |  0:00:07s\n",
      "epoch 34 | loss: 0.59154 | val_0_mse: 0.58439 |  0:00:07s\n",
      "epoch 35 | loss: 0.53921 | val_0_mse: 0.65892 |  0:00:08s\n",
      "epoch 36 | loss: 0.54952 | val_0_mse: 0.62295 |  0:00:08s\n",
      "epoch 37 | loss: 0.54777 | val_0_mse: 0.66435 |  0:00:08s\n",
      "epoch 38 | loss: 0.53362 | val_0_mse: 0.60212 |  0:00:08s\n",
      "epoch 39 | loss: 0.51251 | val_0_mse: 0.57907 |  0:00:09s\n",
      "epoch 40 | loss: 0.52736 | val_0_mse: 0.62962 |  0:00:09s\n",
      "epoch 41 | loss: 0.52525 | val_0_mse: 0.5939  |  0:00:09s\n",
      "epoch 42 | loss: 0.49958 | val_0_mse: 0.57463 |  0:00:09s\n",
      "epoch 43 | loss: 0.5137  | val_0_mse: 0.64489 |  0:00:10s\n",
      "epoch 44 | loss: 0.53881 | val_0_mse: 0.57859 |  0:00:10s\n",
      "epoch 45 | loss: 0.50318 | val_0_mse: 0.60559 |  0:00:10s\n",
      "epoch 46 | loss: 0.51809 | val_0_mse: 0.62157 |  0:00:10s\n",
      "epoch 47 | loss: 0.51786 | val_0_mse: 0.56891 |  0:00:10s\n",
      "epoch 48 | loss: 0.55327 | val_0_mse: 0.65591 |  0:00:11s\n",
      "epoch 49 | loss: 0.55353 | val_0_mse: 0.56846 |  0:00:11s\n",
      "epoch 50 | loss: 0.50155 | val_0_mse: 0.67722 |  0:00:11s\n",
      "epoch 51 | loss: 0.61924 | val_0_mse: 0.59434 |  0:00:11s\n",
      "epoch 52 | loss: 0.52991 | val_0_mse: 0.65491 |  0:00:12s\n",
      "epoch 53 | loss: 0.50921 | val_0_mse: 0.54189 |  0:00:12s\n",
      "epoch 54 | loss: 0.52109 | val_0_mse: 0.58105 |  0:00:12s\n",
      "epoch 55 | loss: 0.49394 | val_0_mse: 0.62335 |  0:00:12s\n",
      "epoch 56 | loss: 0.49859 | val_0_mse: 0.58006 |  0:00:13s\n",
      "epoch 57 | loss: 0.5188  | val_0_mse: 0.53995 |  0:00:13s\n",
      "epoch 58 | loss: 0.50216 | val_0_mse: 0.60051 |  0:00:13s\n",
      "epoch 59 | loss: 0.49808 | val_0_mse: 0.53821 |  0:00:13s\n",
      "epoch 60 | loss: 0.48289 | val_0_mse: 0.55293 |  0:00:13s\n",
      "epoch 61 | loss: 0.48957 | val_0_mse: 0.55376 |  0:00:14s\n",
      "epoch 62 | loss: 0.48615 | val_0_mse: 0.55473 |  0:00:14s\n",
      "epoch 63 | loss: 0.48789 | val_0_mse: 0.5852  |  0:00:14s\n",
      "epoch 64 | loss: 0.50365 | val_0_mse: 0.55589 |  0:00:14s\n",
      "epoch 65 | loss: 0.50233 | val_0_mse: 0.56134 |  0:00:15s\n",
      "epoch 66 | loss: 0.48672 | val_0_mse: 0.52985 |  0:00:15s\n",
      "epoch 67 | loss: 0.4846  | val_0_mse: 0.53747 |  0:00:15s\n",
      "epoch 68 | loss: 0.48469 | val_0_mse: 0.53594 |  0:00:15s\n",
      "epoch 69 | loss: 0.49168 | val_0_mse: 0.53013 |  0:00:15s\n",
      "epoch 70 | loss: 0.48189 | val_0_mse: 0.52583 |  0:00:16s\n",
      "epoch 71 | loss: 0.48873 | val_0_mse: 0.53472 |  0:00:16s\n",
      "epoch 72 | loss: 0.49218 | val_0_mse: 0.54579 |  0:00:16s\n",
      "epoch 73 | loss: 0.49994 | val_0_mse: 0.56412 |  0:00:16s\n",
      "epoch 74 | loss: 0.50542 | val_0_mse: 0.55882 |  0:00:17s\n",
      "epoch 75 | loss: 0.57321 | val_0_mse: 0.53535 |  0:00:17s\n",
      "epoch 76 | loss: 0.50551 | val_0_mse: 0.54402 |  0:00:17s\n",
      "epoch 77 | loss: 0.49168 | val_0_mse: 0.52144 |  0:00:17s\n",
      "epoch 78 | loss: 0.48496 | val_0_mse: 0.54284 |  0:00:18s\n",
      "epoch 79 | loss: 0.50998 | val_0_mse: 0.51457 |  0:00:18s\n",
      "epoch 80 | loss: 0.4923  | val_0_mse: 0.52249 |  0:00:18s\n",
      "epoch 81 | loss: 0.493   | val_0_mse: 0.51848 |  0:00:18s\n",
      "epoch 82 | loss: 0.49523 | val_0_mse: 0.56101 |  0:00:18s\n",
      "epoch 83 | loss: 0.4962  | val_0_mse: 0.57358 |  0:00:19s\n",
      "epoch 84 | loss: 0.5193  | val_0_mse: 0.54866 |  0:00:19s\n",
      "epoch 85 | loss: 0.49347 | val_0_mse: 0.53949 |  0:00:19s\n",
      "epoch 86 | loss: 0.48136 | val_0_mse: 0.53769 |  0:00:19s\n",
      "epoch 87 | loss: 0.48473 | val_0_mse: 0.57716 |  0:00:20s\n",
      "epoch 88 | loss: 0.53348 | val_0_mse: 0.519   |  0:00:20s\n",
      "epoch 89 | loss: 0.52045 | val_0_mse: 0.55029 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.51457\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4958... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78226</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">royal-sweep-29</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/k4wzdwu4\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/k4wzdwu4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045007-k4wzdwu4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w1xomrrh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.17388383686543044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/w1xomrrh\" target=\"_blank\">golden-sweep-30</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 24.7485 | val_0_mse: 2.95848 |  0:00:00s\n",
      "epoch 1  | loss: 5.42432 | val_0_mse: 2.89187 |  0:00:00s\n",
      "epoch 2  | loss: 3.04344 | val_0_mse: 1.91751 |  0:00:00s\n",
      "epoch 3  | loss: 1.47217 | val_0_mse: 1.19805 |  0:00:00s\n",
      "epoch 4  | loss: 1.07367 | val_0_mse: 1.46594 |  0:00:01s\n",
      "epoch 5  | loss: 0.87509 | val_0_mse: 1.71848 |  0:00:01s\n",
      "epoch 6  | loss: 0.82205 | val_0_mse: 1.06543 |  0:00:01s\n",
      "epoch 7  | loss: 0.7548  | val_0_mse: 1.14711 |  0:00:01s\n",
      "epoch 8  | loss: 0.67923 | val_0_mse: 1.11678 |  0:00:02s\n",
      "epoch 9  | loss: 0.64967 | val_0_mse: 0.88924 |  0:00:02s\n",
      "epoch 10 | loss: 0.59947 | val_0_mse: 0.87101 |  0:00:02s\n",
      "epoch 11 | loss: 0.62659 | val_0_mse: 1.06352 |  0:00:02s\n",
      "epoch 12 | loss: 0.65436 | val_0_mse: 0.88406 |  0:00:02s\n",
      "epoch 13 | loss: 0.63978 | val_0_mse: 0.82457 |  0:00:03s\n",
      "epoch 14 | loss: 0.58974 | val_0_mse: 0.85372 |  0:00:03s\n",
      "epoch 15 | loss: 0.58948 | val_0_mse: 0.9286  |  0:00:03s\n",
      "epoch 16 | loss: 0.62855 | val_0_mse: 0.99543 |  0:00:03s\n",
      "epoch 17 | loss: 0.63558 | val_0_mse: 0.80195 |  0:00:04s\n",
      "epoch 18 | loss: 0.63671 | val_0_mse: 0.84798 |  0:00:04s\n",
      "epoch 19 | loss: 0.56599 | val_0_mse: 0.733   |  0:00:04s\n",
      "epoch 20 | loss: 0.57744 | val_0_mse: 0.74362 |  0:00:04s\n",
      "epoch 21 | loss: 0.55145 | val_0_mse: 0.75472 |  0:00:04s\n",
      "epoch 22 | loss: 0.55929 | val_0_mse: 0.68991 |  0:00:05s\n",
      "epoch 23 | loss: 0.58429 | val_0_mse: 0.81407 |  0:00:05s\n",
      "epoch 24 | loss: 0.56961 | val_0_mse: 0.76672 |  0:00:05s\n",
      "epoch 25 | loss: 0.59153 | val_0_mse: 0.78339 |  0:00:05s\n",
      "epoch 26 | loss: 0.56463 | val_0_mse: 0.66118 |  0:00:06s\n",
      "epoch 27 | loss: 0.55971 | val_0_mse: 0.65341 |  0:00:06s\n",
      "epoch 28 | loss: 0.63769 | val_0_mse: 0.70882 |  0:00:06s\n",
      "epoch 29 | loss: 0.56135 | val_0_mse: 0.64716 |  0:00:06s\n",
      "epoch 30 | loss: 0.58453 | val_0_mse: 0.7599  |  0:00:07s\n",
      "epoch 31 | loss: 0.56354 | val_0_mse: 0.62851 |  0:00:07s\n",
      "epoch 32 | loss: 0.55245 | val_0_mse: 0.61254 |  0:00:07s\n",
      "epoch 33 | loss: 0.53517 | val_0_mse: 0.64752 |  0:00:07s\n",
      "epoch 34 | loss: 0.59154 | val_0_mse: 0.58437 |  0:00:07s\n",
      "epoch 35 | loss: 0.53921 | val_0_mse: 0.65538 |  0:00:08s\n",
      "epoch 36 | loss: 0.54952 | val_0_mse: 0.62187 |  0:00:08s\n",
      "epoch 37 | loss: 0.54777 | val_0_mse: 0.66296 |  0:00:08s\n",
      "epoch 38 | loss: 0.53362 | val_0_mse: 0.60323 |  0:00:08s\n",
      "epoch 39 | loss: 0.51251 | val_0_mse: 0.57907 |  0:00:09s\n",
      "epoch 40 | loss: 0.52736 | val_0_mse: 0.62702 |  0:00:09s\n",
      "epoch 41 | loss: 0.52525 | val_0_mse: 0.59239 |  0:00:09s\n",
      "epoch 42 | loss: 0.49958 | val_0_mse: 0.57372 |  0:00:09s\n",
      "epoch 43 | loss: 0.5137  | val_0_mse: 0.64409 |  0:00:10s\n",
      "epoch 44 | loss: 0.53881 | val_0_mse: 0.57688 |  0:00:10s\n",
      "epoch 45 | loss: 0.50318 | val_0_mse: 0.60418 |  0:00:10s\n",
      "epoch 46 | loss: 0.51809 | val_0_mse: 0.62018 |  0:00:10s\n",
      "epoch 47 | loss: 0.51786 | val_0_mse: 0.56952 |  0:00:10s\n",
      "epoch 48 | loss: 0.55327 | val_0_mse: 0.65412 |  0:00:11s\n",
      "epoch 49 | loss: 0.55353 | val_0_mse: 0.56779 |  0:00:11s\n",
      "epoch 50 | loss: 0.50155 | val_0_mse: 0.67618 |  0:00:11s\n",
      "epoch 51 | loss: 0.61924 | val_0_mse: 0.59345 |  0:00:11s\n",
      "epoch 52 | loss: 0.52991 | val_0_mse: 0.65509 |  0:00:12s\n",
      "epoch 53 | loss: 0.50921 | val_0_mse: 0.54255 |  0:00:12s\n",
      "epoch 54 | loss: 0.52109 | val_0_mse: 0.57966 |  0:00:12s\n",
      "epoch 55 | loss: 0.49394 | val_0_mse: 0.62067 |  0:00:12s\n",
      "epoch 56 | loss: 0.49859 | val_0_mse: 0.57842 |  0:00:12s\n",
      "epoch 57 | loss: 0.5188  | val_0_mse: 0.5399  |  0:00:13s\n",
      "epoch 58 | loss: 0.50216 | val_0_mse: 0.59915 |  0:00:13s\n",
      "epoch 59 | loss: 0.49808 | val_0_mse: 0.5384  |  0:00:13s\n",
      "epoch 60 | loss: 0.48289 | val_0_mse: 0.55178 |  0:00:13s\n",
      "epoch 61 | loss: 0.48957 | val_0_mse: 0.55361 |  0:00:14s\n",
      "epoch 62 | loss: 0.48615 | val_0_mse: 0.55456 |  0:00:14s\n",
      "epoch 63 | loss: 0.48789 | val_0_mse: 0.58513 |  0:00:14s\n",
      "epoch 64 | loss: 0.50365 | val_0_mse: 0.55464 |  0:00:14s\n",
      "epoch 65 | loss: 0.50233 | val_0_mse: 0.56128 |  0:00:14s\n",
      "epoch 66 | loss: 0.48672 | val_0_mse: 0.53015 |  0:00:15s\n",
      "epoch 67 | loss: 0.4846  | val_0_mse: 0.53831 |  0:00:15s\n",
      "epoch 68 | loss: 0.48469 | val_0_mse: 0.53506 |  0:00:15s\n",
      "epoch 69 | loss: 0.49168 | val_0_mse: 0.53132 |  0:00:15s\n",
      "epoch 70 | loss: 0.48189 | val_0_mse: 0.52701 |  0:00:16s\n",
      "epoch 71 | loss: 0.48873 | val_0_mse: 0.53328 |  0:00:16s\n",
      "epoch 72 | loss: 0.49218 | val_0_mse: 0.54378 |  0:00:16s\n",
      "epoch 73 | loss: 0.49994 | val_0_mse: 0.56335 |  0:00:16s\n",
      "epoch 74 | loss: 0.50542 | val_0_mse: 0.56012 |  0:00:17s\n",
      "epoch 75 | loss: 0.57321 | val_0_mse: 0.53525 |  0:00:17s\n",
      "epoch 76 | loss: 0.50551 | val_0_mse: 0.53891 |  0:00:17s\n",
      "epoch 77 | loss: 0.49168 | val_0_mse: 0.52159 |  0:00:17s\n",
      "epoch 78 | loss: 0.48496 | val_0_mse: 0.54511 |  0:00:18s\n",
      "epoch 79 | loss: 0.50998 | val_0_mse: 0.51454 |  0:00:18s\n",
      "epoch 80 | loss: 0.4923  | val_0_mse: 0.52181 |  0:00:18s\n",
      "epoch 81 | loss: 0.493   | val_0_mse: 0.51919 |  0:00:18s\n",
      "epoch 82 | loss: 0.49523 | val_0_mse: 0.55933 |  0:00:18s\n",
      "epoch 83 | loss: 0.4962  | val_0_mse: 0.57176 |  0:00:19s\n",
      "epoch 84 | loss: 0.5193  | val_0_mse: 0.54883 |  0:00:19s\n",
      "epoch 85 | loss: 0.49347 | val_0_mse: 0.53785 |  0:00:19s\n",
      "epoch 86 | loss: 0.48136 | val_0_mse: 0.53711 |  0:00:19s\n",
      "epoch 87 | loss: 0.48473 | val_0_mse: 0.57852 |  0:00:20s\n",
      "epoch 88 | loss: 0.53348 | val_0_mse: 0.51969 |  0:00:20s\n",
      "epoch 89 | loss: 0.52045 | val_0_mse: 0.54923 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.51454\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5001... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78226</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">golden-sweep-30</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/w1xomrrh\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/w1xomrrh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045033-w1xomrrh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8s8gcigo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.13444166727820928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/8s8gcigo\" target=\"_blank\">fiery-sweep-31</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 11.0994 | val_0_mse: 1.75483 |  0:00:00s\n",
      "epoch 1  | loss: 3.15579 | val_0_mse: 2.42277 |  0:00:00s\n",
      "epoch 2  | loss: 2.13096 | val_0_mse: 1.53721 |  0:00:00s\n",
      "epoch 3  | loss: 1.17028 | val_0_mse: 1.43662 |  0:00:00s\n",
      "epoch 4  | loss: 0.88402 | val_0_mse: 0.924   |  0:00:01s\n",
      "epoch 5  | loss: 0.9839  | val_0_mse: 1.09255 |  0:00:01s\n",
      "epoch 6  | loss: 0.75212 | val_0_mse: 0.88068 |  0:00:01s\n",
      "epoch 7  | loss: 0.93528 | val_0_mse: 1.4592  |  0:00:01s\n",
      "epoch 8  | loss: 0.80499 | val_0_mse: 1.02943 |  0:00:01s\n",
      "epoch 9  | loss: 0.72494 | val_0_mse: 0.88088 |  0:00:02s\n",
      "epoch 10 | loss: 0.63324 | val_0_mse: 1.24123 |  0:00:02s\n",
      "epoch 11 | loss: 0.70782 | val_0_mse: 0.83071 |  0:00:02s\n",
      "epoch 12 | loss: 0.62506 | val_0_mse: 0.8719  |  0:00:02s\n",
      "epoch 13 | loss: 0.58275 | val_0_mse: 0.75899 |  0:00:02s\n",
      "epoch 14 | loss: 0.59738 | val_0_mse: 0.76341 |  0:00:03s\n",
      "epoch 15 | loss: 0.59152 | val_0_mse: 0.74994 |  0:00:03s\n",
      "epoch 16 | loss: 0.59114 | val_0_mse: 0.8078  |  0:00:03s\n",
      "epoch 17 | loss: 0.58289 | val_0_mse: 1.0693  |  0:00:03s\n",
      "epoch 18 | loss: 0.66058 | val_0_mse: 0.85535 |  0:00:03s\n",
      "epoch 19 | loss: 0.55867 | val_0_mse: 0.7166  |  0:00:04s\n",
      "epoch 20 | loss: 0.60603 | val_0_mse: 0.78376 |  0:00:04s\n",
      "epoch 21 | loss: 0.56884 | val_0_mse: 1.04209 |  0:00:04s\n",
      "epoch 22 | loss: 0.93255 | val_0_mse: 0.76604 |  0:00:04s\n",
      "epoch 23 | loss: 0.57274 | val_0_mse: 0.86744 |  0:00:04s\n",
      "epoch 24 | loss: 0.60492 | val_0_mse: 0.67721 |  0:00:05s\n",
      "epoch 25 | loss: 0.57033 | val_0_mse: 0.85753 |  0:00:05s\n",
      "epoch 26 | loss: 0.54108 | val_0_mse: 0.72236 |  0:00:05s\n",
      "epoch 27 | loss: 0.53703 | val_0_mse: 0.74712 |  0:00:05s\n",
      "epoch 28 | loss: 0.53184 | val_0_mse: 0.71909 |  0:00:05s\n",
      "epoch 29 | loss: 0.51296 | val_0_mse: 0.7502  |  0:00:06s\n",
      "epoch 30 | loss: 0.51488 | val_0_mse: 0.7584  |  0:00:06s\n",
      "epoch 31 | loss: 0.5205  | val_0_mse: 0.63694 |  0:00:06s\n",
      "epoch 32 | loss: 0.54948 | val_0_mse: 0.66928 |  0:00:06s\n",
      "epoch 33 | loss: 0.52591 | val_0_mse: 0.70875 |  0:00:06s\n",
      "epoch 34 | loss: 0.54972 | val_0_mse: 0.62884 |  0:00:07s\n",
      "epoch 35 | loss: 0.5301  | val_0_mse: 0.59735 |  0:00:07s\n",
      "epoch 36 | loss: 0.56814 | val_0_mse: 0.79812 |  0:00:07s\n",
      "epoch 37 | loss: 0.68797 | val_0_mse: 0.63143 |  0:00:07s\n",
      "epoch 38 | loss: 0.54475 | val_0_mse: 0.6923  |  0:00:07s\n",
      "epoch 39 | loss: 0.55278 | val_0_mse: 0.61593 |  0:00:08s\n",
      "epoch 40 | loss: 0.53812 | val_0_mse: 0.70323 |  0:00:08s\n",
      "epoch 41 | loss: 0.53428 | val_0_mse: 0.59094 |  0:00:08s\n",
      "epoch 42 | loss: 0.57744 | val_0_mse: 0.75917 |  0:00:08s\n",
      "epoch 43 | loss: 0.58255 | val_0_mse: 0.60987 |  0:00:08s\n",
      "epoch 44 | loss: 0.57232 | val_0_mse: 0.65721 |  0:00:09s\n",
      "epoch 45 | loss: 0.544   | val_0_mse: 0.58929 |  0:00:09s\n",
      "epoch 46 | loss: 0.54588 | val_0_mse: 0.64729 |  0:00:09s\n",
      "epoch 47 | loss: 0.55219 | val_0_mse: 0.6439  |  0:00:09s\n",
      "epoch 48 | loss: 0.5478  | val_0_mse: 0.59226 |  0:00:10s\n",
      "epoch 49 | loss: 0.55625 | val_0_mse: 0.74462 |  0:00:10s\n",
      "epoch 50 | loss: 0.6775  | val_0_mse: 0.60494 |  0:00:10s\n",
      "epoch 51 | loss: 0.60303 | val_0_mse: 0.59454 |  0:00:10s\n",
      "epoch 52 | loss: 0.53974 | val_0_mse: 0.618   |  0:00:10s\n",
      "epoch 53 | loss: 0.51965 | val_0_mse: 0.62626 |  0:00:11s\n",
      "epoch 54 | loss: 0.50768 | val_0_mse: 0.60863 |  0:00:11s\n",
      "epoch 55 | loss: 0.52032 | val_0_mse: 0.57688 |  0:00:11s\n",
      "epoch 56 | loss: 0.51712 | val_0_mse: 0.59283 |  0:00:11s\n",
      "epoch 57 | loss: 0.51741 | val_0_mse: 0.56948 |  0:00:11s\n",
      "epoch 58 | loss: 0.51329 | val_0_mse: 0.58769 |  0:00:12s\n",
      "epoch 59 | loss: 0.51434 | val_0_mse: 0.57558 |  0:00:12s\n",
      "epoch 60 | loss: 0.516   | val_0_mse: 0.63606 |  0:00:12s\n",
      "epoch 61 | loss: 0.58404 | val_0_mse: 0.56852 |  0:00:12s\n",
      "epoch 62 | loss: 0.52776 | val_0_mse: 0.61253 |  0:00:12s\n",
      "epoch 63 | loss: 0.53556 | val_0_mse: 0.55176 |  0:00:13s\n",
      "epoch 64 | loss: 0.5239  | val_0_mse: 0.56179 |  0:00:13s\n",
      "epoch 65 | loss: 0.52069 | val_0_mse: 0.56283 |  0:00:13s\n",
      "epoch 66 | loss: 0.50592 | val_0_mse: 0.54484 |  0:00:13s\n",
      "epoch 67 | loss: 0.51017 | val_0_mse: 0.56869 |  0:00:13s\n",
      "epoch 68 | loss: 0.52133 | val_0_mse: 0.54556 |  0:00:14s\n",
      "epoch 69 | loss: 0.51252 | val_0_mse: 0.55122 |  0:00:14s\n",
      "epoch 70 | loss: 0.504   | val_0_mse: 0.55608 |  0:00:14s\n",
      "epoch 71 | loss: 0.49837 | val_0_mse: 0.57542 |  0:00:14s\n",
      "epoch 72 | loss: 0.534   | val_0_mse: 0.53209 |  0:00:14s\n",
      "epoch 73 | loss: 0.51084 | val_0_mse: 0.53951 |  0:00:15s\n",
      "epoch 74 | loss: 0.50374 | val_0_mse: 0.54005 |  0:00:15s\n",
      "epoch 75 | loss: 0.5135  | val_0_mse: 0.55802 |  0:00:15s\n",
      "epoch 76 | loss: 0.50975 | val_0_mse: 0.56182 |  0:00:15s\n",
      "epoch 77 | loss: 0.50205 | val_0_mse: 0.5603  |  0:00:16s\n",
      "epoch 78 | loss: 0.50874 | val_0_mse: 0.54733 |  0:00:16s\n",
      "epoch 79 | loss: 0.50444 | val_0_mse: 0.54414 |  0:00:16s\n",
      "epoch 80 | loss: 0.50378 | val_0_mse: 0.53831 |  0:00:16s\n",
      "epoch 81 | loss: 0.4953  | val_0_mse: 0.53933 |  0:00:16s\n",
      "epoch 82 | loss: 0.50185 | val_0_mse: 0.53213 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 0.53209\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5054... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77328</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fiery-sweep-31</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/8s8gcigo\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/8s8gcigo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045059-8s8gcigo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8r9se7vi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.09739598276358104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/8r9se7vi\" target=\"_blank\">rare-sweep-32</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 11.46286| val_0_mse: 4.58201 |  0:00:00s\n",
      "epoch 1  | loss: 2.57267 | val_0_mse: 2.71357 |  0:00:00s\n",
      "epoch 2  | loss: 1.37892 | val_0_mse: 2.2095  |  0:00:00s\n",
      "epoch 3  | loss: 1.01723 | val_0_mse: 1.15018 |  0:00:00s\n",
      "epoch 4  | loss: 0.89659 | val_0_mse: 1.35084 |  0:00:00s\n",
      "epoch 5  | loss: 0.73286 | val_0_mse: 1.00326 |  0:00:01s\n",
      "epoch 6  | loss: 0.68678 | val_0_mse: 0.99423 |  0:00:01s\n",
      "epoch 7  | loss: 0.66104 | val_0_mse: 1.20755 |  0:00:01s\n",
      "epoch 8  | loss: 0.63488 | val_0_mse: 0.84622 |  0:00:01s\n",
      "epoch 9  | loss: 0.631   | val_0_mse: 1.00769 |  0:00:01s\n",
      "epoch 10 | loss: 0.65549 | val_0_mse: 0.79162 |  0:00:01s\n",
      "epoch 11 | loss: 0.7009  | val_0_mse: 0.88995 |  0:00:02s\n",
      "epoch 12 | loss: 0.59373 | val_0_mse: 0.82908 |  0:00:02s\n",
      "epoch 13 | loss: 0.57906 | val_0_mse: 0.88782 |  0:00:02s\n",
      "epoch 14 | loss: 0.55275 | val_0_mse: 0.82803 |  0:00:02s\n",
      "epoch 15 | loss: 0.55081 | val_0_mse: 0.85502 |  0:00:02s\n",
      "epoch 16 | loss: 0.53734 | val_0_mse: 0.76713 |  0:00:03s\n",
      "epoch 17 | loss: 0.54166 | val_0_mse: 0.861   |  0:00:03s\n",
      "epoch 18 | loss: 0.53131 | val_0_mse: 0.74055 |  0:00:03s\n",
      "epoch 19 | loss: 0.51935 | val_0_mse: 0.76533 |  0:00:03s\n",
      "epoch 20 | loss: 0.50491 | val_0_mse: 0.75799 |  0:00:03s\n",
      "epoch 21 | loss: 0.53026 | val_0_mse: 0.81502 |  0:00:03s\n",
      "epoch 22 | loss: 0.52638 | val_0_mse: 0.74667 |  0:00:04s\n",
      "epoch 23 | loss: 0.51273 | val_0_mse: 0.78823 |  0:00:04s\n",
      "epoch 24 | loss: 0.58589 | val_0_mse: 0.86526 |  0:00:04s\n",
      "epoch 25 | loss: 0.5951  | val_0_mse: 0.76686 |  0:00:04s\n",
      "epoch 26 | loss: 0.55755 | val_0_mse: 0.85047 |  0:00:04s\n",
      "epoch 27 | loss: 0.56306 | val_0_mse: 0.68496 |  0:00:05s\n",
      "epoch 28 | loss: 0.54004 | val_0_mse: 0.86903 |  0:00:05s\n",
      "epoch 29 | loss: 0.58018 | val_0_mse: 0.7171  |  0:00:05s\n",
      "epoch 30 | loss: 0.68736 | val_0_mse: 0.70923 |  0:00:05s\n",
      "epoch 31 | loss: 0.55235 | val_0_mse: 0.77118 |  0:00:05s\n",
      "epoch 32 | loss: 0.52646 | val_0_mse: 0.71281 |  0:00:05s\n",
      "epoch 33 | loss: 0.62305 | val_0_mse: 0.74555 |  0:00:06s\n",
      "epoch 34 | loss: 0.56186 | val_0_mse: 0.71093 |  0:00:06s\n",
      "epoch 35 | loss: 0.51789 | val_0_mse: 0.68499 |  0:00:06s\n",
      "epoch 36 | loss: 0.50927 | val_0_mse: 0.64923 |  0:00:06s\n",
      "epoch 37 | loss: 0.4955  | val_0_mse: 0.6539  |  0:00:07s\n",
      "epoch 38 | loss: 0.4897  | val_0_mse: 0.64738 |  0:00:07s\n",
      "epoch 39 | loss: 0.49023 | val_0_mse: 0.6244  |  0:00:07s\n",
      "epoch 40 | loss: 0.48923 | val_0_mse: 0.63701 |  0:00:07s\n",
      "epoch 41 | loss: 0.50027 | val_0_mse: 0.60474 |  0:00:07s\n",
      "epoch 42 | loss: 0.49382 | val_0_mse: 0.58379 |  0:00:07s\n",
      "epoch 43 | loss: 0.50751 | val_0_mse: 0.6775  |  0:00:08s\n",
      "epoch 44 | loss: 0.54298 | val_0_mse: 0.60304 |  0:00:08s\n",
      "epoch 45 | loss: 0.51348 | val_0_mse: 0.66123 |  0:00:08s\n",
      "epoch 46 | loss: 0.5279  | val_0_mse: 0.58674 |  0:00:08s\n",
      "epoch 47 | loss: 0.52717 | val_0_mse: 0.67298 |  0:00:08s\n",
      "epoch 48 | loss: 0.54382 | val_0_mse: 0.57588 |  0:00:09s\n",
      "epoch 49 | loss: 0.56417 | val_0_mse: 0.62958 |  0:00:09s\n",
      "epoch 50 | loss: 0.53223 | val_0_mse: 0.59006 |  0:00:09s\n",
      "epoch 51 | loss: 0.49725 | val_0_mse: 0.58463 |  0:00:09s\n",
      "epoch 52 | loss: 0.49609 | val_0_mse: 0.57216 |  0:00:09s\n",
      "epoch 53 | loss: 0.5026  | val_0_mse: 0.57052 |  0:00:09s\n",
      "epoch 54 | loss: 0.5002  | val_0_mse: 0.61397 |  0:00:10s\n",
      "epoch 55 | loss: 0.51089 | val_0_mse: 0.55979 |  0:00:10s\n",
      "epoch 56 | loss: 0.50473 | val_0_mse: 0.61191 |  0:00:10s\n",
      "epoch 57 | loss: 0.50803 | val_0_mse: 0.57968 |  0:00:10s\n",
      "epoch 58 | loss: 0.49852 | val_0_mse: 0.53858 |  0:00:10s\n",
      "epoch 59 | loss: 0.49292 | val_0_mse: 0.54204 |  0:00:11s\n",
      "epoch 60 | loss: 0.48519 | val_0_mse: 0.54678 |  0:00:11s\n",
      "epoch 61 | loss: 0.48703 | val_0_mse: 0.52731 |  0:00:11s\n",
      "epoch 62 | loss: 0.4924  | val_0_mse: 0.58346 |  0:00:11s\n",
      "epoch 63 | loss: 0.51912 | val_0_mse: 0.52443 |  0:00:11s\n",
      "epoch 64 | loss: 0.55554 | val_0_mse: 0.52287 |  0:00:12s\n",
      "epoch 65 | loss: 0.49965 | val_0_mse: 0.51366 |  0:00:12s\n",
      "epoch 66 | loss: 0.4986  | val_0_mse: 0.54492 |  0:00:12s\n",
      "epoch 67 | loss: 0.49367 | val_0_mse: 0.51051 |  0:00:12s\n",
      "epoch 68 | loss: 0.49204 | val_0_mse: 0.51795 |  0:00:12s\n",
      "epoch 69 | loss: 0.48402 | val_0_mse: 0.5312  |  0:00:12s\n",
      "epoch 70 | loss: 0.49806 | val_0_mse: 0.5407  |  0:00:13s\n",
      "epoch 71 | loss: 0.4828  | val_0_mse: 0.51596 |  0:00:13s\n",
      "epoch 72 | loss: 0.4882  | val_0_mse: 0.55541 |  0:00:13s\n",
      "epoch 73 | loss: 0.49795 | val_0_mse: 0.53835 |  0:00:13s\n",
      "epoch 74 | loss: 0.50938 | val_0_mse: 0.64156 |  0:00:13s\n",
      "epoch 75 | loss: 0.61256 | val_0_mse: 0.58039 |  0:00:14s\n",
      "epoch 76 | loss: 0.50423 | val_0_mse: 0.53218 |  0:00:14s\n",
      "epoch 77 | loss: 0.50383 | val_0_mse: 0.53678 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_mse = 0.51051\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5105... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78623</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">rare-sweep-32</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/8r9se7vi\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/8r9se7vi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045123-8r9se7vi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ikr4k2uw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.17222697036315107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ikr4k2uw\" target=\"_blank\">jumping-sweep-33</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.14636 | val_0_mse: 2.84901 |  0:00:00s\n",
      "epoch 1  | loss: 2.09054 | val_0_mse: 1.85776 |  0:00:00s\n",
      "epoch 2  | loss: 1.1945  | val_0_mse: 1.13608 |  0:00:00s\n",
      "epoch 3  | loss: 0.87746 | val_0_mse: 1.26745 |  0:00:00s\n",
      "epoch 4  | loss: 0.84535 | val_0_mse: 0.8129  |  0:00:01s\n",
      "epoch 5  | loss: 0.72174 | val_0_mse: 1.03833 |  0:00:01s\n",
      "epoch 6  | loss: 0.63632 | val_0_mse: 1.0282  |  0:00:01s\n",
      "epoch 7  | loss: 0.66541 | val_0_mse: 0.84378 |  0:00:01s\n",
      "epoch 8  | loss: 0.61518 | val_0_mse: 0.88931 |  0:00:01s\n",
      "epoch 9  | loss: 0.58969 | val_0_mse: 0.8308  |  0:00:01s\n",
      "epoch 10 | loss: 0.56717 | val_0_mse: 0.8959  |  0:00:02s\n",
      "epoch 11 | loss: 0.57366 | val_0_mse: 0.87768 |  0:00:02s\n",
      "epoch 12 | loss: 0.5761  | val_0_mse: 0.82054 |  0:00:02s\n",
      "epoch 13 | loss: 0.5654  | val_0_mse: 0.75286 |  0:00:02s\n",
      "epoch 14 | loss: 0.66526 | val_0_mse: 0.75293 |  0:00:02s\n",
      "epoch 15 | loss: 0.58252 | val_0_mse: 0.77494 |  0:00:03s\n",
      "epoch 16 | loss: 0.58851 | val_0_mse: 0.88176 |  0:00:03s\n",
      "epoch 17 | loss: 0.59997 | val_0_mse: 0.72884 |  0:00:03s\n",
      "epoch 18 | loss: 0.5585  | val_0_mse: 0.80273 |  0:00:03s\n",
      "epoch 19 | loss: 0.54653 | val_0_mse: 0.84808 |  0:00:03s\n",
      "epoch 20 | loss: 0.5523  | val_0_mse: 0.78367 |  0:00:04s\n",
      "epoch 21 | loss: 0.53928 | val_0_mse: 0.76091 |  0:00:04s\n",
      "epoch 22 | loss: 0.54546 | val_0_mse: 0.79433 |  0:00:04s\n",
      "epoch 23 | loss: 0.53719 | val_0_mse: 0.66766 |  0:00:04s\n",
      "epoch 24 | loss: 0.56265 | val_0_mse: 0.85281 |  0:00:04s\n",
      "epoch 25 | loss: 0.55893 | val_0_mse: 0.73056 |  0:00:05s\n",
      "epoch 26 | loss: 0.55108 | val_0_mse: 0.75415 |  0:00:05s\n",
      "epoch 27 | loss: 0.53191 | val_0_mse: 0.73126 |  0:00:05s\n",
      "epoch 28 | loss: 0.53565 | val_0_mse: 0.72626 |  0:00:05s\n",
      "epoch 29 | loss: 0.52034 | val_0_mse: 0.71542 |  0:00:05s\n",
      "epoch 30 | loss: 0.533   | val_0_mse: 0.744   |  0:00:06s\n",
      "epoch 31 | loss: 0.52938 | val_0_mse: 0.73971 |  0:00:06s\n",
      "epoch 32 | loss: 0.5233  | val_0_mse: 0.69506 |  0:00:06s\n",
      "epoch 33 | loss: 0.53878 | val_0_mse: 0.66394 |  0:00:06s\n",
      "epoch 34 | loss: 0.51971 | val_0_mse: 0.6582  |  0:00:07s\n",
      "epoch 35 | loss: 0.51639 | val_0_mse: 0.77512 |  0:00:07s\n",
      "epoch 36 | loss: 0.52864 | val_0_mse: 0.61875 |  0:00:07s\n",
      "epoch 37 | loss: 0.54216 | val_0_mse: 0.65089 |  0:00:07s\n",
      "epoch 38 | loss: 0.56187 | val_0_mse: 0.67865 |  0:00:07s\n",
      "epoch 39 | loss: 0.50868 | val_0_mse: 0.62921 |  0:00:08s\n",
      "epoch 40 | loss: 0.50549 | val_0_mse: 0.61843 |  0:00:08s\n",
      "epoch 41 | loss: 0.51039 | val_0_mse: 0.69446 |  0:00:08s\n",
      "epoch 42 | loss: 0.54682 | val_0_mse: 0.65515 |  0:00:08s\n",
      "epoch 43 | loss: 0.51086 | val_0_mse: 0.67177 |  0:00:08s\n",
      "epoch 44 | loss: 0.51598 | val_0_mse: 0.60013 |  0:00:09s\n",
      "epoch 45 | loss: 0.50917 | val_0_mse: 0.63098 |  0:00:09s\n",
      "epoch 46 | loss: 0.49959 | val_0_mse: 0.64548 |  0:00:09s\n",
      "epoch 47 | loss: 0.50118 | val_0_mse: 0.61497 |  0:00:09s\n",
      "epoch 48 | loss: 0.49727 | val_0_mse: 0.57822 |  0:00:09s\n",
      "epoch 49 | loss: 0.49273 | val_0_mse: 0.61052 |  0:00:10s\n",
      "epoch 50 | loss: 0.49037 | val_0_mse: 0.63037 |  0:00:10s\n",
      "epoch 51 | loss: 0.5046  | val_0_mse: 0.6337  |  0:00:10s\n",
      "epoch 52 | loss: 0.50816 | val_0_mse: 0.57404 |  0:00:10s\n",
      "epoch 53 | loss: 0.50579 | val_0_mse: 0.58042 |  0:00:10s\n",
      "epoch 54 | loss: 0.50526 | val_0_mse: 0.62536 |  0:00:11s\n",
      "epoch 55 | loss: 0.50412 | val_0_mse: 0.60156 |  0:00:11s\n",
      "epoch 56 | loss: 0.49702 | val_0_mse: 0.57239 |  0:00:11s\n",
      "epoch 57 | loss: 0.50731 | val_0_mse: 0.56767 |  0:00:11s\n",
      "epoch 58 | loss: 0.50567 | val_0_mse: 0.61871 |  0:00:12s\n",
      "epoch 59 | loss: 0.51196 | val_0_mse: 0.57763 |  0:00:12s\n",
      "epoch 60 | loss: 0.50348 | val_0_mse: 0.60128 |  0:00:12s\n",
      "epoch 61 | loss: 0.50665 | val_0_mse: 0.56409 |  0:00:12s\n",
      "epoch 62 | loss: 0.50262 | val_0_mse: 0.55801 |  0:00:12s\n",
      "epoch 63 | loss: 0.50487 | val_0_mse: 0.5636  |  0:00:13s\n",
      "epoch 64 | loss: 0.50068 | val_0_mse: 0.57014 |  0:00:13s\n",
      "epoch 65 | loss: 0.50083 | val_0_mse: 0.58107 |  0:00:13s\n",
      "epoch 66 | loss: 0.51221 | val_0_mse: 0.53513 |  0:00:13s\n",
      "epoch 67 | loss: 0.50924 | val_0_mse: 0.56182 |  0:00:13s\n",
      "epoch 68 | loss: 0.51615 | val_0_mse: 0.56344 |  0:00:14s\n",
      "epoch 69 | loss: 0.51148 | val_0_mse: 0.54473 |  0:00:14s\n",
      "epoch 70 | loss: 0.53735 | val_0_mse: 0.59475 |  0:00:14s\n",
      "epoch 71 | loss: 0.52027 | val_0_mse: 0.59547 |  0:00:14s\n",
      "epoch 72 | loss: 0.55067 | val_0_mse: 0.62789 |  0:00:14s\n",
      "epoch 73 | loss: 0.53502 | val_0_mse: 0.60349 |  0:00:15s\n",
      "epoch 74 | loss: 0.54426 | val_0_mse: 0.60047 |  0:00:15s\n",
      "epoch 75 | loss: 0.53006 | val_0_mse: 0.55567 |  0:00:15s\n",
      "epoch 76 | loss: 0.51983 | val_0_mse: 0.5911  |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.53513\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5190... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77218</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">jumping-sweep-33</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ikr4k2uw\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/ikr4k2uw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045143-ikr4k2uw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1caybynz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.15723351468568791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1caybynz\" target=\"_blank\">misunderstood-sweep-34</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 24.7485 | val_0_mse: 2.95652 |  0:00:00s\n",
      "epoch 1  | loss: 5.42432 | val_0_mse: 2.88166 |  0:00:00s\n",
      "epoch 2  | loss: 3.04344 | val_0_mse: 1.94036 |  0:00:00s\n",
      "epoch 3  | loss: 1.47217 | val_0_mse: 1.21061 |  0:00:00s\n",
      "epoch 4  | loss: 1.07367 | val_0_mse: 1.48376 |  0:00:01s\n",
      "epoch 5  | loss: 0.87509 | val_0_mse: 1.71953 |  0:00:01s\n",
      "epoch 6  | loss: 0.82205 | val_0_mse: 1.07659 |  0:00:01s\n",
      "epoch 7  | loss: 0.7548  | val_0_mse: 1.15068 |  0:00:01s\n",
      "epoch 8  | loss: 0.67923 | val_0_mse: 1.11338 |  0:00:02s\n",
      "epoch 9  | loss: 0.64967 | val_0_mse: 0.89408 |  0:00:02s\n",
      "epoch 10 | loss: 0.59947 | val_0_mse: 0.87191 |  0:00:02s\n",
      "epoch 11 | loss: 0.62659 | val_0_mse: 1.06958 |  0:00:02s\n",
      "epoch 12 | loss: 0.65436 | val_0_mse: 0.88739 |  0:00:02s\n",
      "epoch 13 | loss: 0.63978 | val_0_mse: 0.82686 |  0:00:03s\n",
      "epoch 14 | loss: 0.58974 | val_0_mse: 0.85567 |  0:00:03s\n",
      "epoch 15 | loss: 0.58948 | val_0_mse: 0.92816 |  0:00:03s\n",
      "epoch 16 | loss: 0.62855 | val_0_mse: 0.99693 |  0:00:03s\n",
      "epoch 17 | loss: 0.63558 | val_0_mse: 0.80474 |  0:00:04s\n",
      "epoch 18 | loss: 0.63671 | val_0_mse: 0.84781 |  0:00:04s\n",
      "epoch 19 | loss: 0.56599 | val_0_mse: 0.73212 |  0:00:04s\n",
      "epoch 20 | loss: 0.57744 | val_0_mse: 0.74217 |  0:00:04s\n",
      "epoch 21 | loss: 0.55145 | val_0_mse: 0.75325 |  0:00:04s\n",
      "epoch 22 | loss: 0.55929 | val_0_mse: 0.69045 |  0:00:05s\n",
      "epoch 23 | loss: 0.58429 | val_0_mse: 0.81517 |  0:00:05s\n",
      "epoch 24 | loss: 0.56961 | val_0_mse: 0.76616 |  0:00:05s\n",
      "epoch 25 | loss: 0.59153 | val_0_mse: 0.7821  |  0:00:05s\n",
      "epoch 26 | loss: 0.56463 | val_0_mse: 0.66003 |  0:00:06s\n",
      "epoch 27 | loss: 0.55971 | val_0_mse: 0.65136 |  0:00:06s\n",
      "epoch 28 | loss: 0.63769 | val_0_mse: 0.70815 |  0:00:06s\n",
      "epoch 29 | loss: 0.56135 | val_0_mse: 0.64685 |  0:00:06s\n",
      "epoch 30 | loss: 0.58453 | val_0_mse: 0.75806 |  0:00:07s\n",
      "epoch 31 | loss: 0.56354 | val_0_mse: 0.62807 |  0:00:07s\n",
      "epoch 32 | loss: 0.55245 | val_0_mse: 0.61251 |  0:00:07s\n",
      "epoch 33 | loss: 0.53517 | val_0_mse: 0.64912 |  0:00:07s\n",
      "epoch 34 | loss: 0.59154 | val_0_mse: 0.58415 |  0:00:08s\n",
      "epoch 35 | loss: 0.53921 | val_0_mse: 0.6536  |  0:00:08s\n",
      "epoch 36 | loss: 0.54952 | val_0_mse: 0.62117 |  0:00:08s\n",
      "epoch 37 | loss: 0.54777 | val_0_mse: 0.66208 |  0:00:08s\n",
      "epoch 38 | loss: 0.53362 | val_0_mse: 0.6039  |  0:00:08s\n",
      "epoch 39 | loss: 0.51251 | val_0_mse: 0.57926 |  0:00:09s\n",
      "epoch 40 | loss: 0.52736 | val_0_mse: 0.62556 |  0:00:09s\n",
      "epoch 41 | loss: 0.52525 | val_0_mse: 0.59147 |  0:00:09s\n",
      "epoch 42 | loss: 0.49958 | val_0_mse: 0.57277 |  0:00:09s\n",
      "epoch 43 | loss: 0.5137  | val_0_mse: 0.64362 |  0:00:10s\n",
      "epoch 44 | loss: 0.53881 | val_0_mse: 0.57596 |  0:00:10s\n",
      "epoch 45 | loss: 0.50318 | val_0_mse: 0.60301 |  0:00:10s\n",
      "epoch 46 | loss: 0.51809 | val_0_mse: 0.61913 |  0:00:10s\n",
      "epoch 47 | loss: 0.51786 | val_0_mse: 0.56945 |  0:00:11s\n",
      "epoch 48 | loss: 0.55327 | val_0_mse: 0.65277 |  0:00:11s\n",
      "epoch 49 | loss: 0.55353 | val_0_mse: 0.56749 |  0:00:11s\n",
      "epoch 50 | loss: 0.50155 | val_0_mse: 0.67562 |  0:00:11s\n",
      "epoch 51 | loss: 0.61924 | val_0_mse: 0.59317 |  0:00:11s\n",
      "epoch 52 | loss: 0.52991 | val_0_mse: 0.65494 |  0:00:12s\n",
      "epoch 53 | loss: 0.50921 | val_0_mse: 0.54262 |  0:00:12s\n",
      "epoch 54 | loss: 0.52109 | val_0_mse: 0.57874 |  0:00:12s\n",
      "epoch 55 | loss: 0.49394 | val_0_mse: 0.62005 |  0:00:12s\n",
      "epoch 56 | loss: 0.49859 | val_0_mse: 0.57811 |  0:00:13s\n",
      "epoch 57 | loss: 0.5188  | val_0_mse: 0.53954 |  0:00:13s\n",
      "epoch 58 | loss: 0.50216 | val_0_mse: 0.59833 |  0:00:13s\n",
      "epoch 59 | loss: 0.49808 | val_0_mse: 0.53841 |  0:00:13s\n",
      "epoch 60 | loss: 0.48289 | val_0_mse: 0.55108 |  0:00:13s\n",
      "epoch 61 | loss: 0.48957 | val_0_mse: 0.55357 |  0:00:14s\n",
      "epoch 62 | loss: 0.48615 | val_0_mse: 0.5543  |  0:00:14s\n",
      "epoch 63 | loss: 0.48789 | val_0_mse: 0.58552 |  0:00:14s\n",
      "epoch 64 | loss: 0.50365 | val_0_mse: 0.55383 |  0:00:14s\n",
      "epoch 65 | loss: 0.50233 | val_0_mse: 0.56083 |  0:00:15s\n",
      "epoch 66 | loss: 0.48672 | val_0_mse: 0.53015 |  0:00:15s\n",
      "epoch 67 | loss: 0.4846  | val_0_mse: 0.5376  |  0:00:15s\n",
      "epoch 68 | loss: 0.48469 | val_0_mse: 0.53545 |  0:00:15s\n",
      "epoch 69 | loss: 0.49168 | val_0_mse: 0.5316  |  0:00:16s\n",
      "epoch 70 | loss: 0.48189 | val_0_mse: 0.52772 |  0:00:16s\n",
      "epoch 71 | loss: 0.48873 | val_0_mse: 0.53237 |  0:00:16s\n",
      "epoch 72 | loss: 0.49218 | val_0_mse: 0.54311 |  0:00:16s\n",
      "epoch 73 | loss: 0.49994 | val_0_mse: 0.56231 |  0:00:16s\n",
      "epoch 74 | loss: 0.50542 | val_0_mse: 0.56206 |  0:00:17s\n",
      "epoch 75 | loss: 0.57321 | val_0_mse: 0.53494 |  0:00:17s\n",
      "epoch 76 | loss: 0.50551 | val_0_mse: 0.5397  |  0:00:17s\n",
      "epoch 77 | loss: 0.49168 | val_0_mse: 0.52179 |  0:00:17s\n",
      "epoch 78 | loss: 0.48496 | val_0_mse: 0.54607 |  0:00:18s\n",
      "epoch 79 | loss: 0.50998 | val_0_mse: 0.51439 |  0:00:18s\n",
      "epoch 80 | loss: 0.4923  | val_0_mse: 0.52166 |  0:00:18s\n",
      "epoch 81 | loss: 0.493   | val_0_mse: 0.51927 |  0:00:18s\n",
      "epoch 82 | loss: 0.49523 | val_0_mse: 0.55823 |  0:00:18s\n",
      "epoch 83 | loss: 0.4962  | val_0_mse: 0.56986 |  0:00:19s\n",
      "epoch 84 | loss: 0.5193  | val_0_mse: 0.54877 |  0:00:19s\n",
      "epoch 85 | loss: 0.49347 | val_0_mse: 0.53775 |  0:00:19s\n",
      "epoch 86 | loss: 0.48136 | val_0_mse: 0.53718 |  0:00:19s\n",
      "epoch 87 | loss: 0.48473 | val_0_mse: 0.57909 |  0:00:20s\n",
      "epoch 88 | loss: 0.53348 | val_0_mse: 0.51985 |  0:00:20s\n",
      "epoch 89 | loss: 0.52045 | val_0_mse: 0.5477  |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.51439\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5248... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78233</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">misunderstood-sweep-34</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1caybynz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/1caybynz</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045205-1caybynz/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b5fgg061 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.18904404306200157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/b5fgg061\" target=\"_blank\">fearless-sweep-35</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.75148 | val_0_mse: 1.79445 |  0:00:00s\n",
      "epoch 1  | loss: 1.69899 | val_0_mse: 1.17977 |  0:00:00s\n",
      "epoch 2  | loss: 1.15589 | val_0_mse: 0.89771 |  0:00:00s\n",
      "epoch 3  | loss: 1.00345 | val_0_mse: 0.93258 |  0:00:01s\n",
      "epoch 4  | loss: 0.8238  | val_0_mse: 1.05981 |  0:00:01s\n",
      "epoch 5  | loss: 0.87374 | val_0_mse: 0.86923 |  0:00:01s\n",
      "epoch 6  | loss: 0.77363 | val_0_mse: 1.09163 |  0:00:02s\n",
      "epoch 7  | loss: 0.74103 | val_0_mse: 1.01215 |  0:00:02s\n",
      "epoch 8  | loss: 0.7389  | val_0_mse: 0.86507 |  0:00:02s\n",
      "epoch 9  | loss: 0.82853 | val_0_mse: 0.80322 |  0:00:03s\n",
      "epoch 10 | loss: 0.70438 | val_0_mse: 0.88973 |  0:00:03s\n",
      "epoch 11 | loss: 0.72527 | val_0_mse: 0.89533 |  0:00:03s\n",
      "epoch 12 | loss: 0.67918 | val_0_mse: 1.00938 |  0:00:04s\n",
      "epoch 13 | loss: 0.65554 | val_0_mse: 0.99486 |  0:00:04s\n",
      "epoch 14 | loss: 0.59838 | val_0_mse: 0.80572 |  0:00:04s\n",
      "epoch 15 | loss: 0.72064 | val_0_mse: 0.88641 |  0:00:05s\n",
      "epoch 16 | loss: 0.72829 | val_0_mse: 0.78426 |  0:00:05s\n",
      "epoch 17 | loss: 0.57774 | val_0_mse: 0.89501 |  0:00:05s\n",
      "epoch 18 | loss: 0.56799 | val_0_mse: 0.86298 |  0:00:06s\n",
      "epoch 19 | loss: 0.5926  | val_0_mse: 0.78267 |  0:00:06s\n",
      "epoch 20 | loss: 0.59388 | val_0_mse: 0.74031 |  0:00:06s\n",
      "epoch 21 | loss: 0.54055 | val_0_mse: 0.86312 |  0:00:06s\n",
      "epoch 22 | loss: 0.53379 | val_0_mse: 0.75447 |  0:00:07s\n",
      "epoch 23 | loss: 0.55362 | val_0_mse: 0.7399  |  0:00:07s\n",
      "epoch 24 | loss: 0.53499 | val_0_mse: 0.70052 |  0:00:07s\n",
      "epoch 25 | loss: 0.53239 | val_0_mse: 0.80351 |  0:00:08s\n",
      "epoch 26 | loss: 0.56128 | val_0_mse: 0.67382 |  0:00:08s\n",
      "epoch 27 | loss: 0.56883 | val_0_mse: 0.71757 |  0:00:08s\n",
      "epoch 28 | loss: 0.52188 | val_0_mse: 0.74796 |  0:00:09s\n",
      "epoch 29 | loss: 0.51499 | val_0_mse: 0.70102 |  0:00:09s\n",
      "epoch 30 | loss: 0.51471 | val_0_mse: 0.7099  |  0:00:09s\n",
      "epoch 31 | loss: 0.5202  | val_0_mse: 0.65033 |  0:00:10s\n",
      "epoch 32 | loss: 0.53041 | val_0_mse: 0.7226  |  0:00:10s\n",
      "epoch 33 | loss: 0.51519 | val_0_mse: 0.69063 |  0:00:10s\n",
      "epoch 34 | loss: 0.51557 | val_0_mse: 0.73121 |  0:00:11s\n",
      "epoch 35 | loss: 0.50875 | val_0_mse: 0.72352 |  0:00:11s\n",
      "epoch 36 | loss: 0.52558 | val_0_mse: 0.70986 |  0:00:11s\n",
      "epoch 37 | loss: 0.51631 | val_0_mse: 0.68152 |  0:00:12s\n",
      "epoch 38 | loss: 0.49694 | val_0_mse: 0.67004 |  0:00:12s\n",
      "epoch 39 | loss: 0.53093 | val_0_mse: 0.6631  |  0:00:12s\n",
      "epoch 40 | loss: 0.52942 | val_0_mse: 0.61911 |  0:00:12s\n",
      "epoch 41 | loss: 0.57339 | val_0_mse: 0.66079 |  0:00:13s\n",
      "epoch 42 | loss: 0.6143  | val_0_mse: 0.66574 |  0:00:13s\n",
      "epoch 43 | loss: 0.70094 | val_0_mse: 0.66124 |  0:00:13s\n",
      "epoch 44 | loss: 0.62086 | val_0_mse: 0.59729 |  0:00:14s\n",
      "epoch 45 | loss: 0.56825 | val_0_mse: 0.6733  |  0:00:14s\n",
      "epoch 46 | loss: 0.53955 | val_0_mse: 0.61479 |  0:00:14s\n",
      "epoch 47 | loss: 0.52024 | val_0_mse: 0.56206 |  0:00:15s\n",
      "epoch 48 | loss: 0.5248  | val_0_mse: 0.60594 |  0:00:15s\n",
      "epoch 49 | loss: 0.50886 | val_0_mse: 0.6133  |  0:00:15s\n",
      "epoch 50 | loss: 0.5169  | val_0_mse: 0.6082  |  0:00:16s\n",
      "epoch 51 | loss: 0.60859 | val_0_mse: 0.59787 |  0:00:16s\n",
      "epoch 52 | loss: 0.59594 | val_0_mse: 0.56747 |  0:00:16s\n",
      "epoch 53 | loss: 0.54271 | val_0_mse: 0.56985 |  0:00:17s\n",
      "epoch 54 | loss: 0.53041 | val_0_mse: 0.56999 |  0:00:17s\n",
      "epoch 55 | loss: 0.49215 | val_0_mse: 0.55935 |  0:00:17s\n",
      "epoch 56 | loss: 0.50025 | val_0_mse: 0.58403 |  0:00:17s\n",
      "epoch 57 | loss: 0.50339 | val_0_mse: 0.56838 |  0:00:18s\n",
      "epoch 58 | loss: 0.51502 | val_0_mse: 0.56755 |  0:00:18s\n",
      "epoch 59 | loss: 0.50599 | val_0_mse: 0.57318 |  0:00:18s\n",
      "epoch 60 | loss: 0.53366 | val_0_mse: 0.61147 |  0:00:19s\n",
      "epoch 61 | loss: 0.55036 | val_0_mse: 0.6013  |  0:00:19s\n",
      "epoch 62 | loss: 0.63736 | val_0_mse: 0.58207 |  0:00:19s\n",
      "epoch 63 | loss: 0.56959 | val_0_mse: 0.551   |  0:00:20s\n",
      "epoch 64 | loss: 0.52334 | val_0_mse: 0.57365 |  0:00:20s\n",
      "epoch 65 | loss: 0.51743 | val_0_mse: 0.5507  |  0:00:20s\n",
      "epoch 66 | loss: 0.52328 | val_0_mse: 0.54321 |  0:00:21s\n",
      "epoch 67 | loss: 0.51831 | val_0_mse: 0.5582  |  0:00:21s\n",
      "epoch 68 | loss: 0.52893 | val_0_mse: 0.59762 |  0:00:21s\n",
      "epoch 69 | loss: 0.53856 | val_0_mse: 0.64991 |  0:00:22s\n",
      "epoch 70 | loss: 0.569   | val_0_mse: 0.61266 |  0:00:22s\n",
      "epoch 71 | loss: 0.71869 | val_0_mse: 0.64846 |  0:00:22s\n",
      "epoch 72 | loss: 0.56914 | val_0_mse: 0.61583 |  0:00:22s\n",
      "epoch 73 | loss: 0.56115 | val_0_mse: 0.64431 |  0:00:23s\n",
      "epoch 74 | loss: 0.64914 | val_0_mse: 0.55157 |  0:00:23s\n",
      "epoch 75 | loss: 0.53464 | val_0_mse: 0.56198 |  0:00:23s\n",
      "epoch 76 | loss: 0.5418  | val_0_mse: 0.54494 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.54321\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5292... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77714</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fearless-sweep-35</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/b5fgg061\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/b5fgg061</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045231-b5fgg061/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: snzqyzft with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.18047339536644627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/snzqyzft\" target=\"_blank\">colorful-sweep-36</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 53.02158| val_0_mse: 4.04994 |  0:00:00s\n",
      "epoch 1  | loss: 6.80354 | val_0_mse: 1.83084 |  0:00:00s\n",
      "epoch 2  | loss: 3.849   | val_0_mse: 1.68629 |  0:00:00s\n",
      "epoch 3  | loss: 1.77823 | val_0_mse: 1.28827 |  0:00:01s\n",
      "epoch 4  | loss: 1.44549 | val_0_mse: 1.58963 |  0:00:01s\n",
      "epoch 5  | loss: 1.21985 | val_0_mse: 1.19335 |  0:00:01s\n",
      "epoch 6  | loss: 0.92449 | val_0_mse: 1.26977 |  0:00:01s\n",
      "epoch 7  | loss: 0.88115 | val_0_mse: 1.00717 |  0:00:02s\n",
      "epoch 8  | loss: 0.80173 | val_0_mse: 1.16694 |  0:00:02s\n",
      "epoch 9  | loss: 0.74427 | val_0_mse: 0.94884 |  0:00:02s\n",
      "epoch 10 | loss: 0.70567 | val_0_mse: 0.89294 |  0:00:02s\n",
      "epoch 11 | loss: 0.64322 | val_0_mse: 0.91782 |  0:00:03s\n",
      "epoch 12 | loss: 0.60674 | val_0_mse: 0.8073  |  0:00:03s\n",
      "epoch 13 | loss: 0.58252 | val_0_mse: 0.75924 |  0:00:03s\n",
      "epoch 14 | loss: 0.6333  | val_0_mse: 0.84485 |  0:00:04s\n",
      "epoch 15 | loss: 0.60361 | val_0_mse: 0.89442 |  0:00:04s\n",
      "epoch 16 | loss: 0.6258  | val_0_mse: 0.89322 |  0:00:04s\n",
      "epoch 17 | loss: 0.59671 | val_0_mse: 0.87727 |  0:00:04s\n",
      "epoch 18 | loss: 0.59229 | val_0_mse: 0.80719 |  0:00:05s\n",
      "epoch 19 | loss: 0.58431 | val_0_mse: 0.9606  |  0:00:05s\n",
      "epoch 20 | loss: 0.60447 | val_0_mse: 0.86001 |  0:00:05s\n",
      "epoch 21 | loss: 0.57376 | val_0_mse: 0.85384 |  0:00:05s\n",
      "epoch 22 | loss: 0.57236 | val_0_mse: 0.75529 |  0:00:06s\n",
      "epoch 23 | loss: 0.57034 | val_0_mse: 0.72229 |  0:00:06s\n",
      "epoch 24 | loss: 0.54447 | val_0_mse: 0.7624  |  0:00:06s\n",
      "epoch 25 | loss: 0.53113 | val_0_mse: 0.76014 |  0:00:06s\n",
      "epoch 26 | loss: 0.53008 | val_0_mse: 0.75954 |  0:00:07s\n",
      "epoch 27 | loss: 0.54154 | val_0_mse: 0.79827 |  0:00:07s\n",
      "epoch 28 | loss: 0.5803  | val_0_mse: 0.72371 |  0:00:07s\n",
      "epoch 29 | loss: 0.55281 | val_0_mse: 0.79936 |  0:00:08s\n",
      "epoch 30 | loss: 0.55476 | val_0_mse: 0.67408 |  0:00:08s\n",
      "epoch 31 | loss: 0.58649 | val_0_mse: 0.66925 |  0:00:08s\n",
      "epoch 32 | loss: 0.54016 | val_0_mse: 0.65043 |  0:00:08s\n",
      "epoch 33 | loss: 0.52907 | val_0_mse: 0.62497 |  0:00:09s\n",
      "epoch 34 | loss: 0.52215 | val_0_mse: 0.67196 |  0:00:09s\n",
      "epoch 35 | loss: 0.52882 | val_0_mse: 0.67098 |  0:00:09s\n",
      "epoch 36 | loss: 0.51776 | val_0_mse: 0.65431 |  0:00:09s\n",
      "epoch 37 | loss: 0.51325 | val_0_mse: 0.65754 |  0:00:10s\n",
      "epoch 38 | loss: 0.50682 | val_0_mse: 0.64136 |  0:00:10s\n",
      "epoch 39 | loss: 0.49622 | val_0_mse: 0.63905 |  0:00:10s\n",
      "epoch 40 | loss: 0.49832 | val_0_mse: 0.62705 |  0:00:11s\n",
      "epoch 41 | loss: 0.49355 | val_0_mse: 0.60216 |  0:00:11s\n",
      "epoch 42 | loss: 0.50708 | val_0_mse: 0.66152 |  0:00:11s\n",
      "epoch 43 | loss: 0.52885 | val_0_mse: 0.56839 |  0:00:11s\n",
      "epoch 44 | loss: 0.54776 | val_0_mse: 0.63656 |  0:00:12s\n",
      "epoch 45 | loss: 0.51844 | val_0_mse: 0.64896 |  0:00:12s\n",
      "epoch 46 | loss: 0.52149 | val_0_mse: 0.61011 |  0:00:12s\n",
      "epoch 47 | loss: 0.52134 | val_0_mse: 0.62497 |  0:00:12s\n",
      "epoch 48 | loss: 0.51329 | val_0_mse: 0.60533 |  0:00:13s\n",
      "epoch 49 | loss: 0.61022 | val_0_mse: 0.61587 |  0:00:13s\n",
      "epoch 50 | loss: 0.53344 | val_0_mse: 0.62131 |  0:00:13s\n",
      "epoch 51 | loss: 0.50954 | val_0_mse: 0.58524 |  0:00:14s\n",
      "epoch 52 | loss: 0.52487 | val_0_mse: 0.57321 |  0:00:14s\n",
      "epoch 53 | loss: 0.51225 | val_0_mse: 0.59707 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_mse = 0.56839\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5340... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76604</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">colorful-sweep-36</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/snzqyzft\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/snzqyzft</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045301-snzqyzft/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vjdinjjc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.10448713404824336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/vjdinjjc\" target=\"_blank\">misty-sweep-37</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.66186 | val_0_mse: 2.41064 |  0:00:00s\n",
      "epoch 1  | loss: 2.22243 | val_0_mse: 1.0833  |  0:00:00s\n",
      "epoch 2  | loss: 1.82106 | val_0_mse: 1.12425 |  0:00:00s\n",
      "epoch 3  | loss: 1.11788 | val_0_mse: 1.1856  |  0:00:00s\n",
      "epoch 4  | loss: 0.97552 | val_0_mse: 1.10514 |  0:00:01s\n",
      "epoch 5  | loss: 0.84945 | val_0_mse: 0.92007 |  0:00:01s\n",
      "epoch 6  | loss: 0.91969 | val_0_mse: 1.05837 |  0:00:01s\n",
      "epoch 7  | loss: 0.72652 | val_0_mse: 1.12625 |  0:00:01s\n",
      "epoch 8  | loss: 0.72763 | val_0_mse: 0.88598 |  0:00:01s\n",
      "epoch 9  | loss: 0.76843 | val_0_mse: 1.21681 |  0:00:02s\n",
      "epoch 10 | loss: 0.79796 | val_0_mse: 0.92784 |  0:00:02s\n",
      "epoch 11 | loss: 1.11182 | val_0_mse: 1.12029 |  0:00:02s\n",
      "epoch 12 | loss: 0.96711 | val_0_mse: 1.03373 |  0:00:02s\n",
      "epoch 13 | loss: 0.65032 | val_0_mse: 0.95159 |  0:00:03s\n",
      "epoch 14 | loss: 0.62248 | val_0_mse: 0.865   |  0:00:03s\n",
      "epoch 15 | loss: 0.58313 | val_0_mse: 0.88844 |  0:00:03s\n",
      "epoch 16 | loss: 0.5983  | val_0_mse: 0.86528 |  0:00:03s\n",
      "epoch 17 | loss: 0.56223 | val_0_mse: 0.90937 |  0:00:04s\n",
      "epoch 18 | loss: 0.62242 | val_0_mse: 0.79737 |  0:00:04s\n",
      "epoch 19 | loss: 0.59615 | val_0_mse: 0.80591 |  0:00:04s\n",
      "epoch 20 | loss: 0.58437 | val_0_mse: 0.73742 |  0:00:04s\n",
      "epoch 21 | loss: 0.53321 | val_0_mse: 0.78031 |  0:00:05s\n",
      "epoch 22 | loss: 0.55472 | val_0_mse: 0.7744  |  0:00:05s\n",
      "epoch 23 | loss: 0.53894 | val_0_mse: 0.74693 |  0:00:05s\n",
      "epoch 24 | loss: 0.55916 | val_0_mse: 0.799   |  0:00:05s\n",
      "epoch 25 | loss: 0.55445 | val_0_mse: 0.8792  |  0:00:05s\n",
      "epoch 26 | loss: 0.61514 | val_0_mse: 0.74962 |  0:00:06s\n",
      "epoch 27 | loss: 0.753   | val_0_mse: 0.77462 |  0:00:06s\n",
      "epoch 28 | loss: 0.78183 | val_0_mse: 0.74376 |  0:00:06s\n",
      "epoch 29 | loss: 0.64848 | val_0_mse: 0.74986 |  0:00:06s\n",
      "epoch 30 | loss: 0.61176 | val_0_mse: 0.68224 |  0:00:07s\n",
      "epoch 31 | loss: 0.51664 | val_0_mse: 0.682   |  0:00:07s\n",
      "epoch 32 | loss: 0.52946 | val_0_mse: 0.65015 |  0:00:07s\n",
      "epoch 33 | loss: 0.52155 | val_0_mse: 0.68297 |  0:00:07s\n",
      "epoch 34 | loss: 0.52067 | val_0_mse: 0.75307 |  0:00:08s\n",
      "epoch 35 | loss: 0.53133 | val_0_mse: 0.6803  |  0:00:08s\n",
      "epoch 36 | loss: 0.49733 | val_0_mse: 0.61616 |  0:00:08s\n",
      "epoch 37 | loss: 0.4943  | val_0_mse: 0.65517 |  0:00:08s\n",
      "epoch 38 | loss: 0.52029 | val_0_mse: 0.7136  |  0:00:08s\n",
      "epoch 39 | loss: 0.50281 | val_0_mse: 0.64716 |  0:00:09s\n",
      "epoch 40 | loss: 0.50258 | val_0_mse: 0.69104 |  0:00:09s\n",
      "epoch 41 | loss: 0.5265  | val_0_mse: 0.61407 |  0:00:09s\n",
      "epoch 42 | loss: 0.51209 | val_0_mse: 0.6367  |  0:00:09s\n",
      "epoch 43 | loss: 0.50459 | val_0_mse: 0.5953  |  0:00:10s\n",
      "epoch 44 | loss: 0.49207 | val_0_mse: 0.63533 |  0:00:10s\n",
      "epoch 45 | loss: 0.51394 | val_0_mse: 0.59548 |  0:00:10s\n",
      "epoch 46 | loss: 0.5047  | val_0_mse: 0.57467 |  0:00:10s\n",
      "epoch 47 | loss: 0.50339 | val_0_mse: 0.57293 |  0:00:10s\n",
      "epoch 48 | loss: 0.50046 | val_0_mse: 0.57122 |  0:00:11s\n",
      "epoch 49 | loss: 0.49614 | val_0_mse: 0.56341 |  0:00:11s\n",
      "epoch 50 | loss: 0.49223 | val_0_mse: 0.56227 |  0:00:11s\n",
      "epoch 51 | loss: 0.50876 | val_0_mse: 0.67225 |  0:00:11s\n",
      "epoch 52 | loss: 0.54806 | val_0_mse: 0.55616 |  0:00:12s\n",
      "epoch 53 | loss: 0.51513 | val_0_mse: 0.58286 |  0:00:12s\n",
      "epoch 54 | loss: 0.511   | val_0_mse: 0.54196 |  0:00:12s\n",
      "epoch 55 | loss: 0.51252 | val_0_mse: 0.55729 |  0:00:12s\n",
      "epoch 56 | loss: 0.49941 | val_0_mse: 0.58306 |  0:00:13s\n",
      "epoch 57 | loss: 0.51039 | val_0_mse: 0.54867 |  0:00:13s\n",
      "epoch 58 | loss: 0.50137 | val_0_mse: 0.59118 |  0:00:13s\n",
      "epoch 59 | loss: 0.51167 | val_0_mse: 0.55413 |  0:00:13s\n",
      "epoch 60 | loss: 0.51247 | val_0_mse: 0.55955 |  0:00:13s\n",
      "epoch 61 | loss: 0.51076 | val_0_mse: 0.59015 |  0:00:14s\n",
      "epoch 62 | loss: 0.56713 | val_0_mse: 0.56117 |  0:00:14s\n",
      "epoch 63 | loss: 0.54454 | val_0_mse: 0.61975 |  0:00:14s\n",
      "epoch 64 | loss: 0.5128  | val_0_mse: 0.54641 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 0.54196\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5386... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77745</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">misty-sweep-37</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/vjdinjjc\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/vjdinjjc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045321-vjdinjjc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jvhhxdcp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.17821408562645472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/jvhhxdcp\" target=\"_blank\">pleasant-sweep-38</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.66627 | val_0_mse: 2.23241 |  0:00:00s\n",
      "epoch 1  | loss: 1.44705 | val_0_mse: 0.92842 |  0:00:00s\n",
      "epoch 2  | loss: 1.13321 | val_0_mse: 1.3709  |  0:00:00s\n",
      "epoch 3  | loss: 0.8291  | val_0_mse: 1.22397 |  0:00:00s\n",
      "epoch 4  | loss: 0.70011 | val_0_mse: 1.00548 |  0:00:00s\n",
      "epoch 5  | loss: 0.62486 | val_0_mse: 1.14978 |  0:00:01s\n",
      "epoch 6  | loss: 0.61592 | val_0_mse: 1.31594 |  0:00:01s\n",
      "epoch 7  | loss: 0.59531 | val_0_mse: 0.98546 |  0:00:01s\n",
      "epoch 8  | loss: 0.58011 | val_0_mse: 0.90716 |  0:00:01s\n",
      "epoch 9  | loss: 0.56865 | val_0_mse: 0.88358 |  0:00:01s\n",
      "epoch 10 | loss: 0.55858 | val_0_mse: 0.85871 |  0:00:02s\n",
      "epoch 11 | loss: 0.56073 | val_0_mse: 0.84557 |  0:00:02s\n",
      "epoch 12 | loss: 0.54328 | val_0_mse: 0.89603 |  0:00:02s\n",
      "epoch 13 | loss: 0.53463 | val_0_mse: 0.88433 |  0:00:02s\n",
      "epoch 14 | loss: 0.52775 | val_0_mse: 0.84011 |  0:00:02s\n",
      "epoch 15 | loss: 0.5746  | val_0_mse: 1.06548 |  0:00:03s\n",
      "epoch 16 | loss: 0.59218 | val_0_mse: 0.7262  |  0:00:03s\n",
      "epoch 17 | loss: 0.54455 | val_0_mse: 0.83161 |  0:00:03s\n",
      "epoch 18 | loss: 0.50663 | val_0_mse: 0.74385 |  0:00:03s\n",
      "epoch 19 | loss: 0.51199 | val_0_mse: 0.89925 |  0:00:03s\n",
      "epoch 20 | loss: 0.52097 | val_0_mse: 0.79075 |  0:00:04s\n",
      "epoch 21 | loss: 0.51328 | val_0_mse: 0.81804 |  0:00:04s\n",
      "epoch 22 | loss: 0.51801 | val_0_mse: 0.72341 |  0:00:04s\n",
      "epoch 23 | loss: 0.51093 | val_0_mse: 0.72218 |  0:00:04s\n",
      "epoch 24 | loss: 0.4986  | val_0_mse: 0.71042 |  0:00:05s\n",
      "epoch 25 | loss: 0.49807 | val_0_mse: 0.725   |  0:00:05s\n",
      "epoch 26 | loss: 0.49601 | val_0_mse: 0.71502 |  0:00:05s\n",
      "epoch 27 | loss: 0.49521 | val_0_mse: 0.773   |  0:00:05s\n",
      "epoch 28 | loss: 0.49138 | val_0_mse: 0.72689 |  0:00:05s\n",
      "epoch 29 | loss: 0.48414 | val_0_mse: 0.69292 |  0:00:06s\n",
      "epoch 30 | loss: 0.49585 | val_0_mse: 0.71712 |  0:00:06s\n",
      "epoch 31 | loss: 0.48905 | val_0_mse: 0.68741 |  0:00:06s\n",
      "epoch 32 | loss: 0.48553 | val_0_mse: 0.69702 |  0:00:06s\n",
      "epoch 33 | loss: 0.48585 | val_0_mse: 0.63753 |  0:00:06s\n",
      "epoch 34 | loss: 0.53324 | val_0_mse: 0.82408 |  0:00:07s\n",
      "epoch 35 | loss: 0.60109 | val_0_mse: 0.66133 |  0:00:07s\n",
      "epoch 36 | loss: 0.58013 | val_0_mse: 0.69891 |  0:00:07s\n",
      "epoch 37 | loss: 0.51719 | val_0_mse: 0.58813 |  0:00:07s\n",
      "epoch 38 | loss: 0.51325 | val_0_mse: 0.63342 |  0:00:07s\n",
      "epoch 39 | loss: 0.50185 | val_0_mse: 0.7578  |  0:00:08s\n",
      "epoch 40 | loss: 0.54726 | val_0_mse: 0.60065 |  0:00:08s\n",
      "epoch 41 | loss: 0.67957 | val_0_mse: 0.6086  |  0:00:08s\n",
      "epoch 42 | loss: 0.50835 | val_0_mse: 0.65434 |  0:00:08s\n",
      "epoch 43 | loss: 0.50224 | val_0_mse: 0.65013 |  0:00:08s\n",
      "epoch 44 | loss: 0.49118 | val_0_mse: 0.58854 |  0:00:09s\n",
      "epoch 45 | loss: 0.49003 | val_0_mse: 0.59093 |  0:00:09s\n",
      "epoch 46 | loss: 0.48681 | val_0_mse: 0.71014 |  0:00:09s\n",
      "epoch 47 | loss: 0.50988 | val_0_mse: 0.58061 |  0:00:09s\n",
      "epoch 48 | loss: 0.49609 | val_0_mse: 0.58464 |  0:00:09s\n",
      "epoch 49 | loss: 0.4856  | val_0_mse: 0.56146 |  0:00:10s\n",
      "epoch 50 | loss: 0.48554 | val_0_mse: 0.58761 |  0:00:10s\n",
      "epoch 51 | loss: 0.48839 | val_0_mse: 0.57722 |  0:00:10s\n",
      "epoch 52 | loss: 0.47949 | val_0_mse: 0.57856 |  0:00:10s\n",
      "epoch 53 | loss: 0.47878 | val_0_mse: 0.52994 |  0:00:10s\n",
      "epoch 54 | loss: 0.49225 | val_0_mse: 0.54196 |  0:00:11s\n",
      "epoch 55 | loss: 0.49706 | val_0_mse: 0.56321 |  0:00:11s\n",
      "epoch 56 | loss: 0.48033 | val_0_mse: 0.51546 |  0:00:11s\n",
      "epoch 57 | loss: 0.49765 | val_0_mse: 0.57915 |  0:00:11s\n",
      "epoch 58 | loss: 0.49534 | val_0_mse: 0.51989 |  0:00:11s\n",
      "epoch 59 | loss: 0.49198 | val_0_mse: 0.54777 |  0:00:12s\n",
      "epoch 60 | loss: 0.49444 | val_0_mse: 0.58238 |  0:00:12s\n",
      "epoch 61 | loss: 0.50858 | val_0_mse: 0.53083 |  0:00:12s\n",
      "epoch 62 | loss: 0.48824 | val_0_mse: 0.56822 |  0:00:12s\n",
      "epoch 63 | loss: 0.48925 | val_0_mse: 0.52165 |  0:00:12s\n",
      "epoch 64 | loss: 0.47716 | val_0_mse: 0.51632 |  0:00:13s\n",
      "epoch 65 | loss: 0.48052 | val_0_mse: 0.57797 |  0:00:13s\n",
      "epoch 66 | loss: 0.49467 | val_0_mse: 0.52459 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 0.51546\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5451... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78926</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">pleasant-sweep-38</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/jvhhxdcp\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/jvhhxdcp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045341-jvhhxdcp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 00prkxta with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.11708225142570676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/00prkxta\" target=\"_blank\">desert-sweep-39</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 13.5308 | val_0_mse: 5.63363 |  0:00:00s\n",
      "epoch 1  | loss: 2.11535 | val_0_mse: 1.81865 |  0:00:00s\n",
      "epoch 2  | loss: 1.04068 | val_0_mse: 1.46888 |  0:00:00s\n",
      "epoch 3  | loss: 0.76031 | val_0_mse: 0.98493 |  0:00:00s\n",
      "epoch 4  | loss: 0.65185 | val_0_mse: 1.19992 |  0:00:00s\n",
      "epoch 5  | loss: 0.56786 | val_0_mse: 1.07934 |  0:00:01s\n",
      "epoch 6  | loss: 0.55477 | val_0_mse: 1.00817 |  0:00:01s\n",
      "epoch 7  | loss: 0.53863 | val_0_mse: 1.07751 |  0:00:01s\n",
      "epoch 8  | loss: 0.54844 | val_0_mse: 0.91999 |  0:00:01s\n",
      "epoch 9  | loss: 0.54725 | val_0_mse: 1.08231 |  0:00:01s\n",
      "epoch 10 | loss: 0.55273 | val_0_mse: 0.95824 |  0:00:01s\n",
      "epoch 11 | loss: 0.55514 | val_0_mse: 0.89397 |  0:00:02s\n",
      "epoch 12 | loss: 0.52197 | val_0_mse: 0.85757 |  0:00:02s\n",
      "epoch 13 | loss: 0.53275 | val_0_mse: 0.88414 |  0:00:02s\n",
      "epoch 14 | loss: 0.51884 | val_0_mse: 0.85156 |  0:00:02s\n",
      "epoch 15 | loss: 0.50401 | val_0_mse: 0.89459 |  0:00:02s\n",
      "epoch 16 | loss: 0.49626 | val_0_mse: 0.86247 |  0:00:02s\n",
      "epoch 17 | loss: 0.49316 | val_0_mse: 0.76889 |  0:00:03s\n",
      "epoch 18 | loss: 0.49365 | val_0_mse: 0.88909 |  0:00:03s\n",
      "epoch 19 | loss: 0.49743 | val_0_mse: 0.80863 |  0:00:03s\n",
      "epoch 20 | loss: 0.48834 | val_0_mse: 0.76843 |  0:00:03s\n",
      "epoch 21 | loss: 0.4897  | val_0_mse: 0.72313 |  0:00:03s\n",
      "epoch 22 | loss: 0.49991 | val_0_mse: 0.8381  |  0:00:03s\n",
      "epoch 23 | loss: 0.49607 | val_0_mse: 0.74111 |  0:00:04s\n",
      "epoch 24 | loss: 0.48986 | val_0_mse: 0.75676 |  0:00:04s\n",
      "epoch 25 | loss: 0.48935 | val_0_mse: 0.70412 |  0:00:04s\n",
      "epoch 26 | loss: 0.50436 | val_0_mse: 0.76962 |  0:00:04s\n",
      "epoch 27 | loss: 0.49947 | val_0_mse: 0.723   |  0:00:04s\n",
      "epoch 28 | loss: 0.4995  | val_0_mse: 0.67083 |  0:00:04s\n",
      "epoch 29 | loss: 0.49849 | val_0_mse: 0.71249 |  0:00:05s\n",
      "epoch 30 | loss: 0.48368 | val_0_mse: 0.69961 |  0:00:05s\n",
      "epoch 31 | loss: 0.49887 | val_0_mse: 0.68122 |  0:00:05s\n",
      "epoch 32 | loss: 0.48012 | val_0_mse: 0.65718 |  0:00:05s\n",
      "epoch 33 | loss: 0.4839  | val_0_mse: 0.62897 |  0:00:06s\n",
      "epoch 34 | loss: 0.47844 | val_0_mse: 0.65136 |  0:00:06s\n",
      "epoch 35 | loss: 0.47419 | val_0_mse: 0.64625 |  0:00:06s\n",
      "epoch 36 | loss: 0.48537 | val_0_mse: 0.66759 |  0:00:06s\n",
      "epoch 37 | loss: 0.48436 | val_0_mse: 0.65886 |  0:00:06s\n",
      "epoch 38 | loss: 0.48031 | val_0_mse: 0.70405 |  0:00:06s\n",
      "epoch 39 | loss: 0.49906 | val_0_mse: 0.61034 |  0:00:07s\n",
      "epoch 40 | loss: 0.49514 | val_0_mse: 0.73359 |  0:00:07s\n",
      "epoch 41 | loss: 0.49619 | val_0_mse: 0.61949 |  0:00:07s\n",
      "epoch 42 | loss: 0.54025 | val_0_mse: 0.70922 |  0:00:07s\n",
      "epoch 43 | loss: 0.52826 | val_0_mse: 0.61567 |  0:00:07s\n",
      "epoch 44 | loss: 0.61316 | val_0_mse: 0.67327 |  0:00:07s\n",
      "epoch 45 | loss: 0.53524 | val_0_mse: 0.63151 |  0:00:08s\n",
      "epoch 46 | loss: 0.50073 | val_0_mse: 0.59969 |  0:00:08s\n",
      "epoch 47 | loss: 0.50122 | val_0_mse: 0.56939 |  0:00:08s\n",
      "epoch 48 | loss: 0.51879 | val_0_mse: 0.59188 |  0:00:08s\n",
      "epoch 49 | loss: 0.49257 | val_0_mse: 0.54563 |  0:00:08s\n",
      "epoch 50 | loss: 0.5308  | val_0_mse: 0.6366  |  0:00:09s\n",
      "epoch 51 | loss: 0.53777 | val_0_mse: 0.64114 |  0:00:09s\n",
      "epoch 52 | loss: 0.52947 | val_0_mse: 0.58593 |  0:00:09s\n",
      "epoch 53 | loss: 0.49382 | val_0_mse: 0.52652 |  0:00:09s\n",
      "epoch 54 | loss: 0.47814 | val_0_mse: 0.5784  |  0:00:09s\n",
      "epoch 55 | loss: 0.4846  | val_0_mse: 0.54766 |  0:00:09s\n",
      "epoch 56 | loss: 0.5148  | val_0_mse: 0.59265 |  0:00:10s\n",
      "epoch 57 | loss: 0.48254 | val_0_mse: 0.55827 |  0:00:10s\n",
      "epoch 58 | loss: 0.5233  | val_0_mse: 0.55415 |  0:00:10s\n",
      "epoch 59 | loss: 0.4802  | val_0_mse: 0.59159 |  0:00:10s\n",
      "epoch 60 | loss: 0.4704  | val_0_mse: 0.55431 |  0:00:10s\n",
      "epoch 61 | loss: 0.45854 | val_0_mse: 0.56225 |  0:00:10s\n",
      "epoch 62 | loss: 0.46985 | val_0_mse: 0.52921 |  0:00:11s\n",
      "epoch 63 | loss: 0.45773 | val_0_mse: 0.56261 |  0:00:11s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 0.52652\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5501... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78255</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">desert-sweep-39</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/00prkxta\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/00prkxta</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045401-00prkxta/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhl5in74 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.08698237479132005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/bhl5in74\" target=\"_blank\">flowing-sweep-40</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 7.37754 | val_0_mse: 1.94116 |  0:00:00s\n",
      "epoch 1  | loss: 2.34915 | val_0_mse: 1.2871  |  0:00:00s\n",
      "epoch 2  | loss: 1.25234 | val_0_mse: 1.1208  |  0:00:00s\n",
      "epoch 3  | loss: 0.91615 | val_0_mse: 1.1959  |  0:00:00s\n",
      "epoch 4  | loss: 0.82099 | val_0_mse: 1.02848 |  0:00:00s\n",
      "epoch 5  | loss: 0.7684  | val_0_mse: 1.17158 |  0:00:01s\n",
      "epoch 6  | loss: 0.64515 | val_0_mse: 1.03841 |  0:00:01s\n",
      "epoch 7  | loss: 0.67132 | val_0_mse: 1.04466 |  0:00:01s\n",
      "epoch 8  | loss: 0.61207 | val_0_mse: 0.94196 |  0:00:01s\n",
      "epoch 9  | loss: 0.61546 | val_0_mse: 0.97479 |  0:00:01s\n",
      "epoch 10 | loss: 0.6666  | val_0_mse: 1.2211  |  0:00:01s\n",
      "epoch 11 | loss: 0.584   | val_0_mse: 1.02232 |  0:00:02s\n",
      "epoch 12 | loss: 0.52956 | val_0_mse: 0.8985  |  0:00:02s\n",
      "epoch 13 | loss: 0.54042 | val_0_mse: 0.88314 |  0:00:02s\n",
      "epoch 14 | loss: 0.535   | val_0_mse: 0.86296 |  0:00:02s\n",
      "epoch 15 | loss: 0.5381  | val_0_mse: 0.95984 |  0:00:02s\n",
      "epoch 16 | loss: 0.54492 | val_0_mse: 0.81968 |  0:00:03s\n",
      "epoch 17 | loss: 0.52646 | val_0_mse: 0.83602 |  0:00:03s\n",
      "epoch 18 | loss: 0.53171 | val_0_mse: 0.8644  |  0:00:03s\n",
      "epoch 19 | loss: 0.56126 | val_0_mse: 0.74633 |  0:00:03s\n",
      "epoch 20 | loss: 0.56113 | val_0_mse: 0.8725  |  0:00:03s\n",
      "epoch 21 | loss: 0.53942 | val_0_mse: 0.7667  |  0:00:03s\n",
      "epoch 22 | loss: 0.52086 | val_0_mse: 0.72618 |  0:00:04s\n",
      "epoch 23 | loss: 0.5603  | val_0_mse: 0.74746 |  0:00:04s\n",
      "epoch 24 | loss: 0.54637 | val_0_mse: 0.97343 |  0:00:04s\n",
      "epoch 25 | loss: 0.54725 | val_0_mse: 0.75912 |  0:00:04s\n",
      "epoch 26 | loss: 0.5404  | val_0_mse: 0.66103 |  0:00:04s\n",
      "epoch 27 | loss: 0.59596 | val_0_mse: 0.92413 |  0:00:05s\n",
      "epoch 28 | loss: 0.57609 | val_0_mse: 0.63462 |  0:00:05s\n",
      "epoch 29 | loss: 0.59557 | val_0_mse: 0.85297 |  0:00:05s\n",
      "epoch 30 | loss: 0.59478 | val_0_mse: 0.62025 |  0:00:05s\n",
      "epoch 31 | loss: 0.62866 | val_0_mse: 0.82418 |  0:00:05s\n",
      "epoch 32 | loss: 0.77139 | val_0_mse: 0.67131 |  0:00:05s\n",
      "epoch 33 | loss: 0.60003 | val_0_mse: 0.81271 |  0:00:06s\n",
      "epoch 34 | loss: 0.57611 | val_0_mse: 0.68538 |  0:00:06s\n",
      "epoch 35 | loss: 0.52232 | val_0_mse: 0.64587 |  0:00:06s\n",
      "epoch 36 | loss: 0.51908 | val_0_mse: 0.60817 |  0:00:06s\n",
      "epoch 37 | loss: 0.52154 | val_0_mse: 0.62861 |  0:00:06s\n",
      "epoch 38 | loss: 0.50157 | val_0_mse: 0.62018 |  0:00:07s\n",
      "epoch 39 | loss: 0.49485 | val_0_mse: 0.57914 |  0:00:07s\n",
      "epoch 40 | loss: 0.50416 | val_0_mse: 0.60784 |  0:00:07s\n",
      "epoch 41 | loss: 0.49859 | val_0_mse: 0.64253 |  0:00:07s\n",
      "epoch 42 | loss: 0.50534 | val_0_mse: 0.65582 |  0:00:07s\n",
      "epoch 43 | loss: 0.51863 | val_0_mse: 0.59289 |  0:00:07s\n",
      "epoch 44 | loss: 0.50813 | val_0_mse: 0.61705 |  0:00:08s\n",
      "epoch 45 | loss: 0.48971 | val_0_mse: 0.56645 |  0:00:08s\n",
      "epoch 46 | loss: 0.48336 | val_0_mse: 0.59964 |  0:00:08s\n",
      "epoch 47 | loss: 0.49419 | val_0_mse: 0.55464 |  0:00:08s\n",
      "epoch 48 | loss: 0.50322 | val_0_mse: 0.65553 |  0:00:09s\n",
      "epoch 49 | loss: 0.49389 | val_0_mse: 0.55876 |  0:00:09s\n",
      "epoch 50 | loss: 0.48651 | val_0_mse: 0.56929 |  0:00:09s\n",
      "epoch 51 | loss: 0.4974  | val_0_mse: 0.59997 |  0:00:09s\n",
      "epoch 52 | loss: 0.50359 | val_0_mse: 0.56185 |  0:00:09s\n",
      "epoch 53 | loss: 0.49772 | val_0_mse: 0.56357 |  0:00:09s\n",
      "epoch 54 | loss: 0.49787 | val_0_mse: 0.58205 |  0:00:10s\n",
      "epoch 55 | loss: 0.48753 | val_0_mse: 0.60673 |  0:00:10s\n",
      "epoch 56 | loss: 0.52018 | val_0_mse: 0.54403 |  0:00:10s\n",
      "epoch 57 | loss: 0.5247  | val_0_mse: 0.67093 |  0:00:10s\n",
      "epoch 58 | loss: 0.58888 | val_0_mse: 0.54074 |  0:00:10s\n",
      "epoch 59 | loss: 0.48938 | val_0_mse: 0.581   |  0:00:11s\n",
      "epoch 60 | loss: 0.48693 | val_0_mse: 0.53628 |  0:00:11s\n",
      "epoch 61 | loss: 0.47743 | val_0_mse: 0.55679 |  0:00:11s\n",
      "epoch 62 | loss: 0.49302 | val_0_mse: 0.57546 |  0:00:11s\n",
      "epoch 63 | loss: 0.51324 | val_0_mse: 0.61745 |  0:00:11s\n",
      "epoch 64 | loss: 0.63579 | val_0_mse: 0.60289 |  0:00:11s\n",
      "epoch 65 | loss: 0.53912 | val_0_mse: 0.55829 |  0:00:12s\n",
      "epoch 66 | loss: 0.5212  | val_0_mse: 0.60754 |  0:00:12s\n",
      "epoch 67 | loss: 0.51926 | val_0_mse: 0.58719 |  0:00:12s\n",
      "epoch 68 | loss: 0.64961 | val_0_mse: 0.55997 |  0:00:12s\n",
      "epoch 69 | loss: 0.52517 | val_0_mse: 0.58965 |  0:00:12s\n",
      "epoch 70 | loss: 0.49411 | val_0_mse: 0.53526 |  0:00:13s\n",
      "epoch 71 | loss: 0.49546 | val_0_mse: 0.57492 |  0:00:13s\n",
      "epoch 72 | loss: 0.49087 | val_0_mse: 0.52261 |  0:00:13s\n",
      "epoch 73 | loss: 0.49129 | val_0_mse: 0.5236  |  0:00:13s\n",
      "epoch 74 | loss: 0.48272 | val_0_mse: 0.54146 |  0:00:13s\n",
      "epoch 75 | loss: 0.48098 | val_0_mse: 0.54467 |  0:00:13s\n",
      "epoch 76 | loss: 0.48415 | val_0_mse: 0.51969 |  0:00:14s\n",
      "epoch 77 | loss: 0.49921 | val_0_mse: 0.55519 |  0:00:14s\n",
      "epoch 78 | loss: 0.49044 | val_0_mse: 0.52249 |  0:00:14s\n",
      "epoch 79 | loss: 0.48444 | val_0_mse: 0.52216 |  0:00:14s\n",
      "epoch 80 | loss: 0.49081 | val_0_mse: 0.57608 |  0:00:14s\n",
      "epoch 81 | loss: 0.50839 | val_0_mse: 0.54873 |  0:00:15s\n",
      "epoch 82 | loss: 0.50838 | val_0_mse: 0.60422 |  0:00:15s\n",
      "epoch 83 | loss: 0.49394 | val_0_mse: 0.52929 |  0:00:15s\n",
      "epoch 84 | loss: 0.48295 | val_0_mse: 0.55759 |  0:00:15s\n",
      "epoch 85 | loss: 0.4899  | val_0_mse: 0.53874 |  0:00:15s\n",
      "epoch 86 | loss: 0.48302 | val_0_mse: 0.5381  |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.51969\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5544... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78147</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">flowing-sweep-40</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/bhl5in74\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/bhl5in74</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045417-bhl5in74/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y0wgjcp7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2309628803482911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/y0wgjcp7\" target=\"_blank\">giddy-sweep-41</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 12.78371| val_0_mse: 3.38492 |  0:00:00s\n",
      "epoch 1  | loss: 2.58214 | val_0_mse: 2.10202 |  0:00:00s\n",
      "epoch 2  | loss: 1.63803 | val_0_mse: 1.15021 |  0:00:00s\n",
      "epoch 3  | loss: 1.17818 | val_0_mse: 1.32692 |  0:00:00s\n",
      "epoch 4  | loss: 0.93997 | val_0_mse: 1.22788 |  0:00:00s\n",
      "epoch 5  | loss: 0.81114 | val_0_mse: 1.16763 |  0:00:01s\n",
      "epoch 6  | loss: 0.71203 | val_0_mse: 1.24379 |  0:00:01s\n",
      "epoch 7  | loss: 0.68399 | val_0_mse: 1.05559 |  0:00:01s\n",
      "epoch 8  | loss: 0.64878 | val_0_mse: 1.19019 |  0:00:01s\n",
      "epoch 9  | loss: 0.67678 | val_0_mse: 0.95379 |  0:00:01s\n",
      "epoch 10 | loss: 0.70702 | val_0_mse: 0.91286 |  0:00:02s\n",
      "epoch 11 | loss: 0.78514 | val_0_mse: 1.0475  |  0:00:02s\n",
      "epoch 12 | loss: 0.70324 | val_0_mse: 0.96165 |  0:00:02s\n",
      "epoch 13 | loss: 0.63591 | val_0_mse: 0.88939 |  0:00:02s\n",
      "epoch 14 | loss: 0.71805 | val_0_mse: 0.86274 |  0:00:02s\n",
      "epoch 15 | loss: 0.65898 | val_0_mse: 0.82441 |  0:00:02s\n",
      "epoch 16 | loss: 0.65371 | val_0_mse: 0.93148 |  0:00:03s\n",
      "epoch 17 | loss: 0.60446 | val_0_mse: 0.81166 |  0:00:03s\n",
      "epoch 18 | loss: 0.59042 | val_0_mse: 0.75703 |  0:00:03s\n",
      "epoch 19 | loss: 0.56502 | val_0_mse: 0.89346 |  0:00:03s\n",
      "epoch 20 | loss: 0.62773 | val_0_mse: 0.76395 |  0:00:03s\n",
      "epoch 21 | loss: 0.63268 | val_0_mse: 0.94681 |  0:00:04s\n",
      "epoch 22 | loss: 0.58417 | val_0_mse: 0.73934 |  0:00:04s\n",
      "epoch 23 | loss: 0.63237 | val_0_mse: 0.83425 |  0:00:04s\n",
      "epoch 24 | loss: 0.55349 | val_0_mse: 0.76768 |  0:00:04s\n",
      "epoch 25 | loss: 0.56531 | val_0_mse: 0.90985 |  0:00:04s\n",
      "epoch 26 | loss: 0.57103 | val_0_mse: 0.7506  |  0:00:04s\n",
      "epoch 27 | loss: 0.55367 | val_0_mse: 0.81754 |  0:00:05s\n",
      "epoch 28 | loss: 0.53684 | val_0_mse: 0.79615 |  0:00:05s\n",
      "epoch 29 | loss: 0.51365 | val_0_mse: 0.74911 |  0:00:05s\n",
      "epoch 30 | loss: 0.50733 | val_0_mse: 0.71483 |  0:00:05s\n",
      "epoch 31 | loss: 0.52288 | val_0_mse: 0.69635 |  0:00:05s\n",
      "epoch 32 | loss: 0.52341 | val_0_mse: 0.72902 |  0:00:06s\n",
      "epoch 33 | loss: 0.52479 | val_0_mse: 0.65429 |  0:00:06s\n",
      "epoch 34 | loss: 0.53134 | val_0_mse: 0.69265 |  0:00:06s\n",
      "epoch 35 | loss: 0.5496  | val_0_mse: 0.64399 |  0:00:06s\n",
      "epoch 36 | loss: 0.52646 | val_0_mse: 0.70625 |  0:00:06s\n",
      "epoch 37 | loss: 0.50891 | val_0_mse: 0.64099 |  0:00:07s\n",
      "epoch 38 | loss: 0.50831 | val_0_mse: 0.68283 |  0:00:07s\n",
      "epoch 39 | loss: 0.52346 | val_0_mse: 0.66255 |  0:00:07s\n",
      "epoch 40 | loss: 0.51514 | val_0_mse: 0.69558 |  0:00:07s\n",
      "epoch 41 | loss: 0.53104 | val_0_mse: 0.62494 |  0:00:07s\n",
      "epoch 42 | loss: 0.51987 | val_0_mse: 0.70515 |  0:00:08s\n",
      "epoch 43 | loss: 0.54949 | val_0_mse: 0.6721  |  0:00:08s\n",
      "epoch 44 | loss: 0.54708 | val_0_mse: 0.69631 |  0:00:08s\n",
      "epoch 45 | loss: 0.52328 | val_0_mse: 0.63671 |  0:00:08s\n",
      "epoch 46 | loss: 0.50839 | val_0_mse: 0.60448 |  0:00:08s\n",
      "epoch 47 | loss: 0.52055 | val_0_mse: 0.61003 |  0:00:08s\n",
      "epoch 48 | loss: 0.50928 | val_0_mse: 0.59522 |  0:00:09s\n",
      "epoch 49 | loss: 0.51107 | val_0_mse: 0.57238 |  0:00:09s\n",
      "epoch 50 | loss: 0.50186 | val_0_mse: 0.58497 |  0:00:09s\n",
      "epoch 51 | loss: 0.50994 | val_0_mse: 0.57235 |  0:00:09s\n",
      "epoch 52 | loss: 0.50335 | val_0_mse: 0.70821 |  0:00:09s\n",
      "epoch 53 | loss: 0.59217 | val_0_mse: 0.57402 |  0:00:10s\n",
      "epoch 54 | loss: 0.55344 | val_0_mse: 0.60007 |  0:00:10s\n",
      "epoch 55 | loss: 0.53    | val_0_mse: 0.60018 |  0:00:10s\n",
      "epoch 56 | loss: 0.50988 | val_0_mse: 0.54266 |  0:00:10s\n",
      "epoch 57 | loss: 0.49814 | val_0_mse: 0.55112 |  0:00:10s\n",
      "epoch 58 | loss: 0.4975  | val_0_mse: 0.58526 |  0:00:11s\n",
      "epoch 59 | loss: 0.49676 | val_0_mse: 0.57792 |  0:00:11s\n",
      "epoch 60 | loss: 0.5045  | val_0_mse: 0.55814 |  0:00:11s\n",
      "epoch 61 | loss: 0.50323 | val_0_mse: 0.61154 |  0:00:11s\n",
      "epoch 62 | loss: 0.51519 | val_0_mse: 0.57127 |  0:00:11s\n",
      "epoch 63 | loss: 0.50248 | val_0_mse: 0.57555 |  0:00:11s\n",
      "epoch 64 | loss: 0.52336 | val_0_mse: 0.61237 |  0:00:12s\n",
      "epoch 65 | loss: 0.50401 | val_0_mse: 0.5525  |  0:00:12s\n",
      "epoch 66 | loss: 0.50503 | val_0_mse: 0.54564 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 0.54266\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5597... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77054</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">giddy-sweep-41</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/y0wgjcp7\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/y0wgjcp7</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045440-y0wgjcp7/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vka59a9i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.07801433964993502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/vka59a9i\" target=\"_blank\">smooth-sweep-42</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 24.7485 | val_0_mse: 2.90255 |  0:00:00s\n",
      "epoch 1  | loss: 5.42432 | val_0_mse: 2.89321 |  0:00:00s\n",
      "epoch 2  | loss: 3.04344 | val_0_mse: 2.07294 |  0:00:00s\n",
      "epoch 3  | loss: 1.47217 | val_0_mse: 1.2852  |  0:00:00s\n",
      "epoch 4  | loss: 1.07367 | val_0_mse: 1.57385 |  0:00:01s\n",
      "epoch 5  | loss: 0.87509 | val_0_mse: 1.72727 |  0:00:01s\n",
      "epoch 6  | loss: 0.82205 | val_0_mse: 1.13624 |  0:00:01s\n",
      "epoch 7  | loss: 0.7548  | val_0_mse: 1.17382 |  0:00:01s\n",
      "epoch 8  | loss: 0.67923 | val_0_mse: 1.11041 |  0:00:02s\n",
      "epoch 9  | loss: 0.64967 | val_0_mse: 0.92689 |  0:00:02s\n",
      "epoch 10 | loss: 0.59947 | val_0_mse: 0.87896 |  0:00:02s\n",
      "epoch 11 | loss: 0.62659 | val_0_mse: 1.10523 |  0:00:02s\n",
      "epoch 12 | loss: 0.65436 | val_0_mse: 0.91004 |  0:00:02s\n",
      "epoch 13 | loss: 0.63978 | val_0_mse: 0.84911 |  0:00:03s\n",
      "epoch 14 | loss: 0.58974 | val_0_mse: 0.86179 |  0:00:03s\n",
      "epoch 15 | loss: 0.58948 | val_0_mse: 0.92444 |  0:00:03s\n",
      "epoch 16 | loss: 0.62855 | val_0_mse: 1.00782 |  0:00:03s\n",
      "epoch 17 | loss: 0.63558 | val_0_mse: 0.82646 |  0:00:04s\n",
      "epoch 18 | loss: 0.63671 | val_0_mse: 0.8472  |  0:00:04s\n",
      "epoch 19 | loss: 0.56599 | val_0_mse: 0.73272 |  0:00:04s\n",
      "epoch 20 | loss: 0.57744 | val_0_mse: 0.73609 |  0:00:04s\n",
      "epoch 21 | loss: 0.55145 | val_0_mse: 0.74708 |  0:00:04s\n",
      "epoch 22 | loss: 0.55929 | val_0_mse: 0.69119 |  0:00:05s\n",
      "epoch 23 | loss: 0.58429 | val_0_mse: 0.8203  |  0:00:05s\n",
      "epoch 24 | loss: 0.56961 | val_0_mse: 0.76335 |  0:00:05s\n",
      "epoch 25 | loss: 0.59153 | val_0_mse: 0.77553 |  0:00:05s\n",
      "epoch 26 | loss: 0.56463 | val_0_mse: 0.65436 |  0:00:06s\n",
      "epoch 27 | loss: 0.55971 | val_0_mse: 0.63881 |  0:00:06s\n",
      "epoch 28 | loss: 0.63769 | val_0_mse: 0.70447 |  0:00:06s\n",
      "epoch 29 | loss: 0.56135 | val_0_mse: 0.64555 |  0:00:06s\n",
      "epoch 30 | loss: 0.58453 | val_0_mse: 0.75124 |  0:00:07s\n",
      "epoch 31 | loss: 0.56354 | val_0_mse: 0.62589 |  0:00:07s\n",
      "epoch 32 | loss: 0.55245 | val_0_mse: 0.61455 |  0:00:07s\n",
      "epoch 33 | loss: 0.53517 | val_0_mse: 0.66017 |  0:00:07s\n",
      "epoch 34 | loss: 0.59154 | val_0_mse: 0.58199 |  0:00:07s\n",
      "epoch 35 | loss: 0.53921 | val_0_mse: 0.64798 |  0:00:08s\n",
      "epoch 36 | loss: 0.54952 | val_0_mse: 0.6176  |  0:00:08s\n",
      "epoch 37 | loss: 0.54777 | val_0_mse: 0.65742 |  0:00:08s\n",
      "epoch 38 | loss: 0.53362 | val_0_mse: 0.60627 |  0:00:08s\n",
      "epoch 39 | loss: 0.51251 | val_0_mse: 0.57955 |  0:00:09s\n",
      "epoch 40 | loss: 0.52736 | val_0_mse: 0.61952 |  0:00:09s\n",
      "epoch 41 | loss: 0.52525 | val_0_mse: 0.58721 |  0:00:09s\n",
      "epoch 42 | loss: 0.49958 | val_0_mse: 0.56844 |  0:00:09s\n",
      "epoch 43 | loss: 0.5137  | val_0_mse: 0.63935 |  0:00:09s\n",
      "epoch 44 | loss: 0.53881 | val_0_mse: 0.576   |  0:00:10s\n",
      "epoch 45 | loss: 0.50318 | val_0_mse: 0.59805 |  0:00:10s\n",
      "epoch 46 | loss: 0.51809 | val_0_mse: 0.61411 |  0:00:10s\n",
      "epoch 47 | loss: 0.51786 | val_0_mse: 0.56976 |  0:00:11s\n",
      "epoch 48 | loss: 0.55327 | val_0_mse: 0.64554 |  0:00:11s\n",
      "epoch 49 | loss: 0.55353 | val_0_mse: 0.5667  |  0:00:11s\n",
      "epoch 50 | loss: 0.50155 | val_0_mse: 0.6778  |  0:00:11s\n",
      "epoch 51 | loss: 0.61924 | val_0_mse: 0.5931  |  0:00:11s\n",
      "epoch 52 | loss: 0.52991 | val_0_mse: 0.64933 |  0:00:12s\n",
      "epoch 53 | loss: 0.50921 | val_0_mse: 0.54784 |  0:00:12s\n",
      "epoch 54 | loss: 0.52109 | val_0_mse: 0.57386 |  0:00:12s\n",
      "epoch 55 | loss: 0.49394 | val_0_mse: 0.61664 |  0:00:12s\n",
      "epoch 56 | loss: 0.49859 | val_0_mse: 0.57829 |  0:00:13s\n",
      "epoch 57 | loss: 0.5188  | val_0_mse: 0.54069 |  0:00:13s\n",
      "epoch 58 | loss: 0.50216 | val_0_mse: 0.59458 |  0:00:13s\n",
      "epoch 59 | loss: 0.49808 | val_0_mse: 0.5383  |  0:00:13s\n",
      "epoch 60 | loss: 0.48289 | val_0_mse: 0.54867 |  0:00:14s\n",
      "epoch 61 | loss: 0.48957 | val_0_mse: 0.55232 |  0:00:14s\n",
      "epoch 62 | loss: 0.48615 | val_0_mse: 0.55296 |  0:00:14s\n",
      "epoch 63 | loss: 0.48789 | val_0_mse: 0.58782 |  0:00:14s\n",
      "epoch 64 | loss: 0.50365 | val_0_mse: 0.55171 |  0:00:14s\n",
      "epoch 65 | loss: 0.50233 | val_0_mse: 0.5625  |  0:00:15s\n",
      "epoch 66 | loss: 0.48672 | val_0_mse: 0.52902 |  0:00:15s\n",
      "epoch 67 | loss: 0.4846  | val_0_mse: 0.53846 |  0:00:15s\n",
      "epoch 68 | loss: 0.48469 | val_0_mse: 0.53842 |  0:00:15s\n",
      "epoch 69 | loss: 0.49168 | val_0_mse: 0.53238 |  0:00:16s\n",
      "epoch 70 | loss: 0.48189 | val_0_mse: 0.52927 |  0:00:16s\n",
      "epoch 71 | loss: 0.48873 | val_0_mse: 0.52919 |  0:00:16s\n",
      "epoch 72 | loss: 0.49218 | val_0_mse: 0.54047 |  0:00:16s\n",
      "epoch 73 | loss: 0.49994 | val_0_mse: 0.56077 |  0:00:16s\n",
      "epoch 74 | loss: 0.50542 | val_0_mse: 0.57183 |  0:00:17s\n",
      "epoch 75 | loss: 0.57321 | val_0_mse: 0.53435 |  0:00:17s\n",
      "epoch 76 | loss: 0.50551 | val_0_mse: 0.54006 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.52902\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5673... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77813</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">smooth-sweep-42</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/vka59a9i\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/vka59a9i</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045458-vka59a9i/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u7gijz8b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.012914979822361476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/u7gijz8b\" target=\"_blank\">decent-sweep-43</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.21905 | val_0_mse: 4.16156 |  0:00:00s\n",
      "epoch 1  | loss: 2.38009 | val_0_mse: 4.68364 |  0:00:00s\n",
      "epoch 2  | loss: 1.39324 | val_0_mse: 2.91313 |  0:00:00s\n",
      "epoch 3  | loss: 1.01911 | val_0_mse: 1.96376 |  0:00:00s\n",
      "epoch 4  | loss: 1.00169 | val_0_mse: 2.14287 |  0:00:01s\n",
      "epoch 5  | loss: 0.97593 | val_0_mse: 1.37501 |  0:00:01s\n",
      "epoch 6  | loss: 0.71851 | val_0_mse: 1.20111 |  0:00:01s\n",
      "epoch 7  | loss: 0.84966 | val_0_mse: 1.34476 |  0:00:01s\n",
      "epoch 8  | loss: 0.73224 | val_0_mse: 0.99678 |  0:00:02s\n",
      "epoch 9  | loss: 0.85511 | val_0_mse: 1.14589 |  0:00:02s\n",
      "epoch 10 | loss: 0.70524 | val_0_mse: 1.07512 |  0:00:02s\n",
      "epoch 11 | loss: 0.70419 | val_0_mse: 0.98316 |  0:00:02s\n",
      "epoch 12 | loss: 0.63715 | val_0_mse: 0.92139 |  0:00:02s\n",
      "epoch 13 | loss: 0.61292 | val_0_mse: 1.02527 |  0:00:03s\n",
      "epoch 14 | loss: 0.64178 | val_0_mse: 0.86467 |  0:00:03s\n",
      "epoch 15 | loss: 0.61148 | val_0_mse: 1.01791 |  0:00:03s\n",
      "epoch 16 | loss: 0.78967 | val_0_mse: 0.86865 |  0:00:03s\n",
      "epoch 17 | loss: 0.95664 | val_0_mse: 0.95641 |  0:00:04s\n",
      "epoch 18 | loss: 0.63101 | val_0_mse: 0.93691 |  0:00:04s\n",
      "epoch 19 | loss: 0.60453 | val_0_mse: 0.94409 |  0:00:04s\n",
      "epoch 20 | loss: 0.55134 | val_0_mse: 0.99324 |  0:00:04s\n",
      "epoch 21 | loss: 0.55816 | val_0_mse: 0.88522 |  0:00:04s\n",
      "epoch 22 | loss: 0.54013 | val_0_mse: 0.78486 |  0:00:05s\n",
      "epoch 23 | loss: 0.53105 | val_0_mse: 0.7412  |  0:00:05s\n",
      "epoch 24 | loss: 0.53633 | val_0_mse: 0.69041 |  0:00:05s\n",
      "epoch 25 | loss: 0.54481 | val_0_mse: 0.72207 |  0:00:05s\n",
      "epoch 26 | loss: 0.5223  | val_0_mse: 0.76218 |  0:00:06s\n",
      "epoch 27 | loss: 0.53518 | val_0_mse: 0.66356 |  0:00:06s\n",
      "epoch 28 | loss: 0.50948 | val_0_mse: 0.70127 |  0:00:06s\n",
      "epoch 29 | loss: 0.50207 | val_0_mse: 0.74833 |  0:00:06s\n",
      "epoch 30 | loss: 0.50853 | val_0_mse: 0.69217 |  0:00:07s\n",
      "epoch 31 | loss: 0.50995 | val_0_mse: 0.67548 |  0:00:07s\n",
      "epoch 32 | loss: 0.52985 | val_0_mse: 0.7471  |  0:00:07s\n",
      "epoch 33 | loss: 0.54455 | val_0_mse: 0.69118 |  0:00:07s\n",
      "epoch 34 | loss: 0.52906 | val_0_mse: 0.72491 |  0:00:07s\n",
      "epoch 35 | loss: 0.52097 | val_0_mse: 0.62038 |  0:00:08s\n",
      "epoch 36 | loss: 0.53109 | val_0_mse: 0.73443 |  0:00:08s\n",
      "epoch 37 | loss: 0.53545 | val_0_mse: 0.65942 |  0:00:08s\n",
      "epoch 38 | loss: 0.60063 | val_0_mse: 0.78867 |  0:00:08s\n",
      "epoch 39 | loss: 0.58782 | val_0_mse: 0.65129 |  0:00:09s\n",
      "epoch 40 | loss: 0.83563 | val_0_mse: 0.61257 |  0:00:09s\n",
      "epoch 41 | loss: 0.57687 | val_0_mse: 0.94513 |  0:00:09s\n",
      "epoch 42 | loss: 0.65163 | val_0_mse: 0.58282 |  0:00:09s\n",
      "epoch 43 | loss: 0.60549 | val_0_mse: 0.69997 |  0:00:10s\n",
      "epoch 44 | loss: 0.56821 | val_0_mse: 0.60702 |  0:00:10s\n",
      "epoch 45 | loss: 0.50815 | val_0_mse: 0.62499 |  0:00:10s\n",
      "epoch 46 | loss: 0.51023 | val_0_mse: 0.64368 |  0:00:10s\n",
      "epoch 47 | loss: 0.55249 | val_0_mse: 0.60223 |  0:00:11s\n",
      "epoch 48 | loss: 0.54151 | val_0_mse: 0.69679 |  0:00:11s\n",
      "epoch 49 | loss: 0.61469 | val_0_mse: 0.60976 |  0:00:11s\n",
      "epoch 50 | loss: 0.52056 | val_0_mse: 0.59582 |  0:00:11s\n",
      "epoch 51 | loss: 0.50317 | val_0_mse: 0.55067 |  0:00:12s\n",
      "epoch 52 | loss: 0.49973 | val_0_mse: 0.54439 |  0:00:12s\n",
      "epoch 53 | loss: 0.50616 | val_0_mse: 0.60055 |  0:00:12s\n",
      "epoch 54 | loss: 0.50349 | val_0_mse: 0.55571 |  0:00:12s\n",
      "epoch 55 | loss: 0.49234 | val_0_mse: 0.59163 |  0:00:12s\n",
      "epoch 56 | loss: 0.50614 | val_0_mse: 0.57236 |  0:00:13s\n",
      "epoch 57 | loss: 0.50331 | val_0_mse: 0.55005 |  0:00:13s\n",
      "epoch 58 | loss: 0.49565 | val_0_mse: 0.55692 |  0:00:13s\n",
      "epoch 59 | loss: 0.493   | val_0_mse: 0.5464  |  0:00:13s\n",
      "epoch 60 | loss: 0.48624 | val_0_mse: 0.56963 |  0:00:14s\n",
      "epoch 61 | loss: 0.49473 | val_0_mse: 0.53319 |  0:00:14s\n",
      "epoch 62 | loss: 0.49933 | val_0_mse: 0.59854 |  0:00:14s\n",
      "epoch 63 | loss: 0.50097 | val_0_mse: 0.54276 |  0:00:14s\n",
      "epoch 64 | loss: 0.4885  | val_0_mse: 0.55096 |  0:00:15s\n",
      "epoch 65 | loss: 0.47541 | val_0_mse: 0.52532 |  0:00:15s\n",
      "epoch 66 | loss: 0.50684 | val_0_mse: 0.61281 |  0:00:15s\n",
      "epoch 67 | loss: 0.52191 | val_0_mse: 0.53607 |  0:00:15s\n",
      "epoch 68 | loss: 0.48739 | val_0_mse: 0.59004 |  0:00:15s\n",
      "epoch 69 | loss: 0.51183 | val_0_mse: 0.52897 |  0:00:16s\n",
      "epoch 70 | loss: 0.49259 | val_0_mse: 0.55846 |  0:00:16s\n",
      "epoch 71 | loss: 0.49151 | val_0_mse: 0.53003 |  0:00:16s\n",
      "epoch 72 | loss: 0.49822 | val_0_mse: 0.54872 |  0:00:16s\n",
      "epoch 73 | loss: 0.49617 | val_0_mse: 0.54613 |  0:00:17s\n",
      "epoch 74 | loss: 0.48168 | val_0_mse: 0.52726 |  0:00:17s\n",
      "epoch 75 | loss: 0.4809  | val_0_mse: 0.53971 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 0.52532\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5725... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78301</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">decent-sweep-43</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/u7gijz8b\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/u7gijz8b</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045521-u7gijz8b/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1tw24cyy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.026358942067821738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1tw24cyy\" target=\"_blank\">scarlet-sweep-44</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 17.46753| val_0_mse: 5.11145 |  0:00:00s\n",
      "epoch 1  | loss: 3.41777 | val_0_mse: 2.49107 |  0:00:00s\n",
      "epoch 2  | loss: 2.73151 | val_0_mse: 2.01795 |  0:00:00s\n",
      "epoch 3  | loss: 1.59382 | val_0_mse: 2.74735 |  0:00:01s\n",
      "epoch 4  | loss: 1.36331 | val_0_mse: 1.89061 |  0:00:01s\n",
      "epoch 5  | loss: 1.07823 | val_0_mse: 1.45387 |  0:00:01s\n",
      "epoch 6  | loss: 0.92235 | val_0_mse: 1.49742 |  0:00:01s\n",
      "epoch 7  | loss: 0.80517 | val_0_mse: 1.05157 |  0:00:01s\n",
      "epoch 8  | loss: 0.76237 | val_0_mse: 1.16042 |  0:00:02s\n",
      "epoch 9  | loss: 0.68693 | val_0_mse: 1.00229 |  0:00:02s\n",
      "epoch 10 | loss: 0.63975 | val_0_mse: 1.05743 |  0:00:02s\n",
      "epoch 11 | loss: 0.60389 | val_0_mse: 1.02459 |  0:00:02s\n",
      "epoch 12 | loss: 0.58371 | val_0_mse: 0.89526 |  0:00:03s\n",
      "epoch 13 | loss: 0.60282 | val_0_mse: 0.85097 |  0:00:03s\n",
      "epoch 14 | loss: 0.60012 | val_0_mse: 1.06039 |  0:00:03s\n",
      "epoch 15 | loss: 0.60904 | val_0_mse: 0.8817  |  0:00:04s\n",
      "epoch 16 | loss: 0.62745 | val_0_mse: 1.06951 |  0:00:04s\n",
      "epoch 17 | loss: 0.57432 | val_0_mse: 0.83836 |  0:00:04s\n",
      "epoch 18 | loss: 0.56952 | val_0_mse: 1.05978 |  0:00:04s\n",
      "epoch 19 | loss: 0.73218 | val_0_mse: 0.8211  |  0:00:05s\n",
      "epoch 20 | loss: 0.55938 | val_0_mse: 0.82776 |  0:00:05s\n",
      "epoch 21 | loss: 0.55252 | val_0_mse: 0.78064 |  0:00:05s\n",
      "epoch 22 | loss: 0.57195 | val_0_mse: 0.85284 |  0:00:05s\n",
      "epoch 23 | loss: 0.56052 | val_0_mse: 0.77665 |  0:00:06s\n",
      "epoch 24 | loss: 0.55473 | val_0_mse: 0.69411 |  0:00:06s\n",
      "epoch 25 | loss: 0.55982 | val_0_mse: 0.76892 |  0:00:06s\n",
      "epoch 26 | loss: 0.5441  | val_0_mse: 0.69131 |  0:00:06s\n",
      "epoch 27 | loss: 0.52774 | val_0_mse: 0.6688  |  0:00:07s\n",
      "epoch 28 | loss: 0.54274 | val_0_mse: 0.7281  |  0:00:07s\n",
      "epoch 29 | loss: 0.55902 | val_0_mse: 0.63565 |  0:00:07s\n",
      "epoch 30 | loss: 0.71031 | val_0_mse: 0.66046 |  0:00:07s\n",
      "epoch 31 | loss: 0.56451 | val_0_mse: 0.68777 |  0:00:08s\n",
      "epoch 32 | loss: 0.52757 | val_0_mse: 0.65485 |  0:00:08s\n",
      "epoch 33 | loss: 0.51798 | val_0_mse: 0.74516 |  0:00:08s\n",
      "epoch 34 | loss: 0.52282 | val_0_mse: 0.68183 |  0:00:08s\n",
      "epoch 35 | loss: 0.52646 | val_0_mse: 0.63942 |  0:00:09s\n",
      "epoch 36 | loss: 0.52502 | val_0_mse: 0.6197  |  0:00:09s\n",
      "epoch 37 | loss: 0.54197 | val_0_mse: 0.67891 |  0:00:09s\n",
      "epoch 38 | loss: 0.53979 | val_0_mse: 0.59389 |  0:00:09s\n",
      "epoch 39 | loss: 0.54471 | val_0_mse: 0.65514 |  0:00:10s\n",
      "epoch 40 | loss: 0.52954 | val_0_mse: 0.59498 |  0:00:10s\n",
      "epoch 41 | loss: 0.51342 | val_0_mse: 0.5994  |  0:00:10s\n",
      "epoch 42 | loss: 0.50753 | val_0_mse: 0.63134 |  0:00:10s\n",
      "epoch 43 | loss: 0.50423 | val_0_mse: 0.61307 |  0:00:11s\n",
      "epoch 44 | loss: 0.50307 | val_0_mse: 0.5938  |  0:00:11s\n",
      "epoch 45 | loss: 0.51104 | val_0_mse: 0.60263 |  0:00:11s\n",
      "epoch 46 | loss: 0.49999 | val_0_mse: 0.59698 |  0:00:11s\n",
      "epoch 47 | loss: 0.50441 | val_0_mse: 0.5761  |  0:00:12s\n",
      "epoch 48 | loss: 0.50965 | val_0_mse: 0.58162 |  0:00:12s\n",
      "epoch 49 | loss: 0.49373 | val_0_mse: 0.55637 |  0:00:12s\n",
      "epoch 50 | loss: 0.50219 | val_0_mse: 0.59276 |  0:00:13s\n",
      "epoch 51 | loss: 0.50844 | val_0_mse: 0.55798 |  0:00:13s\n",
      "epoch 52 | loss: 0.498   | val_0_mse: 0.56792 |  0:00:13s\n",
      "epoch 53 | loss: 0.49995 | val_0_mse: 0.54399 |  0:00:13s\n",
      "epoch 54 | loss: 0.50464 | val_0_mse: 0.56727 |  0:00:14s\n",
      "epoch 55 | loss: 0.49864 | val_0_mse: 0.54426 |  0:00:14s\n",
      "epoch 56 | loss: 0.4918  | val_0_mse: 0.53187 |  0:00:14s\n",
      "epoch 57 | loss: 0.49491 | val_0_mse: 0.56382 |  0:00:14s\n",
      "epoch 58 | loss: 0.49591 | val_0_mse: 0.54518 |  0:00:15s\n",
      "epoch 59 | loss: 0.4945  | val_0_mse: 0.55282 |  0:00:15s\n",
      "epoch 60 | loss: 0.50025 | val_0_mse: 0.52046 |  0:00:15s\n",
      "epoch 61 | loss: 0.50271 | val_0_mse: 0.51369 |  0:00:15s\n",
      "epoch 62 | loss: 0.48788 | val_0_mse: 0.52807 |  0:00:16s\n",
      "epoch 63 | loss: 0.49003 | val_0_mse: 0.53285 |  0:00:16s\n",
      "epoch 64 | loss: 0.48688 | val_0_mse: 0.52785 |  0:00:16s\n",
      "epoch 65 | loss: 0.49139 | val_0_mse: 0.54535 |  0:00:16s\n",
      "epoch 66 | loss: 0.49288 | val_0_mse: 0.54991 |  0:00:17s\n",
      "epoch 67 | loss: 0.52359 | val_0_mse: 0.55042 |  0:00:17s\n",
      "epoch 68 | loss: 0.5314  | val_0_mse: 0.56659 |  0:00:17s\n",
      "epoch 69 | loss: 0.63878 | val_0_mse: 0.57627 |  0:00:17s\n",
      "epoch 70 | loss: 0.54449 | val_0_mse: 0.57474 |  0:00:18s\n",
      "epoch 71 | loss: 0.52184 | val_0_mse: 0.58558 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.51369\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5775... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78821</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">scarlet-sweep-44</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/1tw24cyy\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/1tw24cyy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045545-1tw24cyy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: torwnw96 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.036049725130567326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/torwnw96\" target=\"_blank\">ethereal-sweep-45</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 7.44484 | val_0_mse: 5.00386 |  0:00:00s\n",
      "epoch 1  | loss: 1.95991 | val_0_mse: 2.71951 |  0:00:00s\n",
      "epoch 2  | loss: 1.37009 | val_0_mse: 2.13268 |  0:00:00s\n",
      "epoch 3  | loss: 1.20666 | val_0_mse: 1.46427 |  0:00:00s\n",
      "epoch 4  | loss: 1.00846 | val_0_mse: 1.20424 |  0:00:01s\n",
      "epoch 5  | loss: 0.88905 | val_0_mse: 1.67467 |  0:00:01s\n",
      "epoch 6  | loss: 0.79102 | val_0_mse: 1.111   |  0:00:01s\n",
      "epoch 7  | loss: 0.77288 | val_0_mse: 0.88887 |  0:00:01s\n",
      "epoch 8  | loss: 0.71093 | val_0_mse: 1.10075 |  0:00:01s\n",
      "epoch 9  | loss: 0.81245 | val_0_mse: 0.76502 |  0:00:02s\n",
      "epoch 10 | loss: 0.79058 | val_0_mse: 1.12744 |  0:00:02s\n",
      "epoch 11 | loss: 0.69692 | val_0_mse: 0.78165 |  0:00:02s\n",
      "epoch 12 | loss: 0.78241 | val_0_mse: 1.05685 |  0:00:02s\n",
      "epoch 13 | loss: 0.7264  | val_0_mse: 0.86911 |  0:00:02s\n",
      "epoch 14 | loss: 0.80742 | val_0_mse: 0.97027 |  0:00:02s\n",
      "epoch 15 | loss: 0.60614 | val_0_mse: 1.05309 |  0:00:03s\n",
      "epoch 16 | loss: 0.59292 | val_0_mse: 0.82806 |  0:00:03s\n",
      "epoch 17 | loss: 0.58255 | val_0_mse: 0.77089 |  0:00:03s\n",
      "epoch 18 | loss: 0.59012 | val_0_mse: 0.8344  |  0:00:03s\n",
      "epoch 19 | loss: 0.64195 | val_0_mse: 0.68093 |  0:00:03s\n",
      "epoch 20 | loss: 0.73023 | val_0_mse: 0.9554  |  0:00:04s\n",
      "epoch 21 | loss: 0.67375 | val_0_mse: 0.63879 |  0:00:04s\n",
      "epoch 22 | loss: 0.76974 | val_0_mse: 0.92565 |  0:00:04s\n",
      "epoch 23 | loss: 0.90399 | val_0_mse: 0.7589  |  0:00:04s\n",
      "epoch 24 | loss: 0.60762 | val_0_mse: 0.9029  |  0:00:04s\n",
      "epoch 25 | loss: 0.62135 | val_0_mse: 0.62431 |  0:00:05s\n",
      "epoch 26 | loss: 0.65659 | val_0_mse: 0.78241 |  0:00:05s\n",
      "epoch 27 | loss: 0.62985 | val_0_mse: 0.64388 |  0:00:05s\n",
      "epoch 28 | loss: 0.67714 | val_0_mse: 0.77447 |  0:00:05s\n",
      "epoch 29 | loss: 0.87207 | val_0_mse: 0.72448 |  0:00:05s\n",
      "epoch 30 | loss: 0.59681 | val_0_mse: 0.65769 |  0:00:06s\n",
      "epoch 31 | loss: 0.57974 | val_0_mse: 0.65971 |  0:00:06s\n",
      "epoch 32 | loss: 0.55832 | val_0_mse: 0.63498 |  0:00:06s\n",
      "epoch 33 | loss: 0.52606 | val_0_mse: 0.61256 |  0:00:06s\n",
      "epoch 34 | loss: 0.52282 | val_0_mse: 0.70802 |  0:00:06s\n",
      "epoch 35 | loss: 0.52997 | val_0_mse: 0.64244 |  0:00:07s\n",
      "epoch 36 | loss: 0.51451 | val_0_mse: 0.59499 |  0:00:07s\n",
      "epoch 37 | loss: 0.52244 | val_0_mse: 0.63128 |  0:00:07s\n",
      "epoch 38 | loss: 0.51113 | val_0_mse: 0.5956  |  0:00:07s\n",
      "epoch 39 | loss: 0.55971 | val_0_mse: 0.71204 |  0:00:07s\n",
      "epoch 40 | loss: 0.57322 | val_0_mse: 0.59512 |  0:00:08s\n",
      "epoch 41 | loss: 0.53657 | val_0_mse: 0.73531 |  0:00:08s\n",
      "epoch 42 | loss: 0.58815 | val_0_mse: 0.57765 |  0:00:08s\n",
      "epoch 43 | loss: 0.68195 | val_0_mse: 0.57635 |  0:00:08s\n",
      "epoch 44 | loss: 0.52907 | val_0_mse: 0.59526 |  0:00:09s\n",
      "epoch 45 | loss: 0.52141 | val_0_mse: 0.6259  |  0:00:09s\n",
      "epoch 46 | loss: 0.5028  | val_0_mse: 0.55822 |  0:00:09s\n",
      "epoch 47 | loss: 0.50899 | val_0_mse: 0.62771 |  0:00:09s\n",
      "epoch 48 | loss: 0.50496 | val_0_mse: 0.63197 |  0:00:09s\n",
      "epoch 49 | loss: 0.52902 | val_0_mse: 0.5497  |  0:00:10s\n",
      "epoch 50 | loss: 0.53355 | val_0_mse: 0.63373 |  0:00:10s\n",
      "epoch 51 | loss: 0.53836 | val_0_mse: 0.55744 |  0:00:10s\n",
      "epoch 52 | loss: 0.5623  | val_0_mse: 0.64617 |  0:00:10s\n",
      "epoch 53 | loss: 0.5736  | val_0_mse: 0.6069  |  0:00:11s\n",
      "epoch 54 | loss: 0.70316 | val_0_mse: 0.58727 |  0:00:11s\n",
      "epoch 55 | loss: 0.56533 | val_0_mse: 0.55788 |  0:00:11s\n",
      "epoch 56 | loss: 0.54498 | val_0_mse: 0.56309 |  0:00:11s\n",
      "epoch 57 | loss: 0.52556 | val_0_mse: 0.61579 |  0:00:11s\n",
      "epoch 58 | loss: 0.53853 | val_0_mse: 0.64198 |  0:00:12s\n",
      "epoch 59 | loss: 0.54798 | val_0_mse: 0.59061 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 0.5497\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5819... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77988</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-45</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/torwnw96\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/torwnw96</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045609-torwnw96/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 936pkrj3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.02797016495930984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/936pkrj3\" target=\"_blank\">deft-sweep-46</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.18062 | val_0_mse: 4.70168 |  0:00:00s\n",
      "epoch 1  | loss: 2.1571  | val_0_mse: 1.57156 |  0:00:00s\n",
      "epoch 2  | loss: 1.64002 | val_0_mse: 1.58479 |  0:00:00s\n",
      "epoch 3  | loss: 1.10893 | val_0_mse: 1.77184 |  0:00:01s\n",
      "epoch 4  | loss: 1.04368 | val_0_mse: 1.26227 |  0:00:01s\n",
      "epoch 5  | loss: 0.88034 | val_0_mse: 1.12881 |  0:00:01s\n",
      "epoch 6  | loss: 0.87602 | val_0_mse: 1.2915  |  0:00:02s\n",
      "epoch 7  | loss: 0.84645 | val_0_mse: 1.05871 |  0:00:02s\n",
      "epoch 8  | loss: 0.79179 | val_0_mse: 0.9084  |  0:00:02s\n",
      "epoch 9  | loss: 0.79431 | val_0_mse: 1.10412 |  0:00:02s\n",
      "epoch 10 | loss: 0.81077 | val_0_mse: 0.9582  |  0:00:03s\n",
      "epoch 11 | loss: 0.68699 | val_0_mse: 1.23275 |  0:00:03s\n",
      "epoch 12 | loss: 0.66055 | val_0_mse: 0.92812 |  0:00:03s\n",
      "epoch 13 | loss: 0.61119 | val_0_mse: 0.83741 |  0:00:04s\n",
      "epoch 14 | loss: 0.64273 | val_0_mse: 1.14526 |  0:00:04s\n",
      "epoch 15 | loss: 0.71273 | val_0_mse: 0.86016 |  0:00:04s\n",
      "epoch 16 | loss: 0.59811 | val_0_mse: 0.75826 |  0:00:05s\n",
      "epoch 17 | loss: 0.65912 | val_0_mse: 0.94518 |  0:00:05s\n",
      "epoch 18 | loss: 0.62894 | val_0_mse: 0.79292 |  0:00:05s\n",
      "epoch 19 | loss: 0.59992 | val_0_mse: 1.00971 |  0:00:05s\n",
      "epoch 20 | loss: 0.60471 | val_0_mse: 0.79259 |  0:00:06s\n",
      "epoch 21 | loss: 0.5418  | val_0_mse: 0.74458 |  0:00:06s\n",
      "epoch 22 | loss: 0.5796  | val_0_mse: 0.83729 |  0:00:06s\n",
      "epoch 23 | loss: 0.58848 | val_0_mse: 0.75471 |  0:00:07s\n",
      "epoch 24 | loss: 0.55278 | val_0_mse: 0.73314 |  0:00:07s\n",
      "epoch 25 | loss: 0.52914 | val_0_mse: 0.7069  |  0:00:07s\n",
      "epoch 26 | loss: 0.55091 | val_0_mse: 0.81918 |  0:00:08s\n",
      "epoch 27 | loss: 0.57798 | val_0_mse: 0.69762 |  0:00:08s\n",
      "epoch 28 | loss: 0.5604  | val_0_mse: 0.7379  |  0:00:08s\n",
      "epoch 29 | loss: 0.55222 | val_0_mse: 0.71061 |  0:00:08s\n",
      "epoch 30 | loss: 0.54885 | val_0_mse: 0.72307 |  0:00:09s\n",
      "epoch 31 | loss: 0.53516 | val_0_mse: 0.72174 |  0:00:09s\n",
      "epoch 32 | loss: 0.5415  | val_0_mse: 0.65214 |  0:00:09s\n",
      "epoch 33 | loss: 0.55527 | val_0_mse: 0.59602 |  0:00:10s\n",
      "epoch 34 | loss: 0.57987 | val_0_mse: 0.77131 |  0:00:10s\n",
      "epoch 35 | loss: 0.57821 | val_0_mse: 0.66359 |  0:00:10s\n",
      "epoch 36 | loss: 0.65408 | val_0_mse: 0.7798  |  0:00:11s\n",
      "epoch 37 | loss: 0.71796 | val_0_mse: 0.63027 |  0:00:11s\n",
      "epoch 38 | loss: 0.56233 | val_0_mse: 0.59728 |  0:00:11s\n",
      "epoch 39 | loss: 0.53414 | val_0_mse: 0.61719 |  0:00:11s\n",
      "epoch 40 | loss: 0.54026 | val_0_mse: 0.66365 |  0:00:12s\n",
      "epoch 41 | loss: 0.5574  | val_0_mse: 0.59708 |  0:00:12s\n",
      "epoch 42 | loss: 0.5353  | val_0_mse: 0.6003  |  0:00:12s\n",
      "epoch 43 | loss: 0.53638 | val_0_mse: 0.72248 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_mse = 0.59602\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5868... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76151</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deft-sweep-46</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/936pkrj3\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/936pkrj3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045628-936pkrj3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ge3ansjb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.07461980292779889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ge3ansjb\" target=\"_blank\">vital-sweep-47</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.13534 | val_0_mse: 3.37912 |  0:00:00s\n",
      "epoch 1  | loss: 1.69288 | val_0_mse: 1.42632 |  0:00:00s\n",
      "epoch 2  | loss: 1.15534 | val_0_mse: 1.18306 |  0:00:00s\n",
      "epoch 3  | loss: 0.88986 | val_0_mse: 1.10984 |  0:00:00s\n",
      "epoch 4  | loss: 0.7944  | val_0_mse: 1.0274  |  0:00:01s\n",
      "epoch 5  | loss: 0.7359  | val_0_mse: 0.77883 |  0:00:01s\n",
      "epoch 6  | loss: 0.66735 | val_0_mse: 1.01354 |  0:00:01s\n",
      "epoch 7  | loss: 0.65209 | val_0_mse: 0.83852 |  0:00:01s\n",
      "epoch 8  | loss: 0.66492 | val_0_mse: 0.90207 |  0:00:01s\n",
      "epoch 9  | loss: 0.59248 | val_0_mse: 0.8251  |  0:00:02s\n",
      "epoch 10 | loss: 0.5698  | val_0_mse: 0.93472 |  0:00:02s\n",
      "epoch 11 | loss: 0.53256 | val_0_mse: 0.84818 |  0:00:02s\n",
      "epoch 12 | loss: 0.53268 | val_0_mse: 0.83532 |  0:00:02s\n",
      "epoch 13 | loss: 0.54313 | val_0_mse: 0.86154 |  0:00:02s\n",
      "epoch 14 | loss: 0.55054 | val_0_mse: 0.79036 |  0:00:03s\n",
      "epoch 15 | loss: 0.53978 | val_0_mse: 0.7905  |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_mse = 0.77883\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5945... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.73045</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vital-sweep-47</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ge3ansjb\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/ge3ansjb</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045648-ge3ansjb/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: le0e36ph with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.022443210499543335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/le0e36ph\" target=\"_blank\">elated-sweep-48</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.21905 | val_0_mse: 4.12264 |  0:00:00s\n",
      "epoch 1  | loss: 2.38009 | val_0_mse: 4.34319 |  0:00:00s\n",
      "epoch 2  | loss: 1.39324 | val_0_mse: 2.30448 |  0:00:00s\n",
      "epoch 3  | loss: 1.01911 | val_0_mse: 1.48874 |  0:00:00s\n",
      "epoch 4  | loss: 1.00169 | val_0_mse: 1.73638 |  0:00:01s\n",
      "epoch 5  | loss: 0.97593 | val_0_mse: 1.2629  |  0:00:01s\n",
      "epoch 6  | loss: 0.71851 | val_0_mse: 1.07427 |  0:00:01s\n",
      "epoch 7  | loss: 0.84966 | val_0_mse: 1.21169 |  0:00:01s\n",
      "epoch 8  | loss: 0.73224 | val_0_mse: 0.92423 |  0:00:02s\n",
      "epoch 9  | loss: 0.85511 | val_0_mse: 1.06702 |  0:00:02s\n",
      "epoch 10 | loss: 0.70524 | val_0_mse: 1.03214 |  0:00:02s\n",
      "epoch 11 | loss: 0.70419 | val_0_mse: 0.99615 |  0:00:02s\n",
      "epoch 12 | loss: 0.63715 | val_0_mse: 0.90861 |  0:00:02s\n",
      "epoch 13 | loss: 0.61292 | val_0_mse: 1.00276 |  0:00:03s\n",
      "epoch 14 | loss: 0.64178 | val_0_mse: 0.86044 |  0:00:03s\n",
      "epoch 15 | loss: 0.61148 | val_0_mse: 1.01203 |  0:00:03s\n",
      "epoch 16 | loss: 0.78967 | val_0_mse: 0.90307 |  0:00:03s\n",
      "epoch 17 | loss: 0.95664 | val_0_mse: 0.96402 |  0:00:04s\n",
      "epoch 18 | loss: 0.63101 | val_0_mse: 0.94293 |  0:00:04s\n",
      "epoch 19 | loss: 0.60453 | val_0_mse: 0.94326 |  0:00:04s\n",
      "epoch 20 | loss: 0.55134 | val_0_mse: 0.97827 |  0:00:04s\n",
      "epoch 21 | loss: 0.55816 | val_0_mse: 0.87827 |  0:00:04s\n",
      "epoch 22 | loss: 0.54013 | val_0_mse: 0.77175 |  0:00:05s\n",
      "epoch 23 | loss: 0.53105 | val_0_mse: 0.72808 |  0:00:05s\n",
      "epoch 24 | loss: 0.53633 | val_0_mse: 0.68481 |  0:00:05s\n",
      "epoch 25 | loss: 0.54481 | val_0_mse: 0.72334 |  0:00:05s\n",
      "epoch 26 | loss: 0.5223  | val_0_mse: 0.76612 |  0:00:06s\n",
      "epoch 27 | loss: 0.53518 | val_0_mse: 0.67691 |  0:00:06s\n",
      "epoch 28 | loss: 0.50948 | val_0_mse: 0.71264 |  0:00:06s\n",
      "epoch 29 | loss: 0.50207 | val_0_mse: 0.75283 |  0:00:06s\n",
      "epoch 30 | loss: 0.50853 | val_0_mse: 0.6871  |  0:00:07s\n",
      "epoch 31 | loss: 0.50995 | val_0_mse: 0.66534 |  0:00:07s\n",
      "epoch 32 | loss: 0.52985 | val_0_mse: 0.72179 |  0:00:07s\n",
      "epoch 33 | loss: 0.54455 | val_0_mse: 0.68905 |  0:00:07s\n",
      "epoch 34 | loss: 0.52906 | val_0_mse: 0.72078 |  0:00:07s\n",
      "epoch 35 | loss: 0.52097 | val_0_mse: 0.62008 |  0:00:08s\n",
      "epoch 36 | loss: 0.53109 | val_0_mse: 0.7277  |  0:00:08s\n",
      "epoch 37 | loss: 0.53545 | val_0_mse: 0.65923 |  0:00:08s\n",
      "epoch 38 | loss: 0.60063 | val_0_mse: 0.77156 |  0:00:08s\n",
      "epoch 39 | loss: 0.58782 | val_0_mse: 0.65195 |  0:00:09s\n",
      "epoch 40 | loss: 0.83563 | val_0_mse: 0.61062 |  0:00:09s\n",
      "epoch 41 | loss: 0.57687 | val_0_mse: 0.93664 |  0:00:09s\n",
      "epoch 42 | loss: 0.65163 | val_0_mse: 0.58176 |  0:00:09s\n",
      "epoch 43 | loss: 0.60549 | val_0_mse: 0.69442 |  0:00:10s\n",
      "epoch 44 | loss: 0.56821 | val_0_mse: 0.60928 |  0:00:10s\n",
      "epoch 45 | loss: 0.50815 | val_0_mse: 0.62352 |  0:00:10s\n",
      "epoch 46 | loss: 0.51023 | val_0_mse: 0.64132 |  0:00:10s\n",
      "epoch 47 | loss: 0.55249 | val_0_mse: 0.60576 |  0:00:10s\n",
      "epoch 48 | loss: 0.54151 | val_0_mse: 0.69277 |  0:00:11s\n",
      "epoch 49 | loss: 0.61469 | val_0_mse: 0.60746 |  0:00:11s\n",
      "epoch 50 | loss: 0.52056 | val_0_mse: 0.59264 |  0:00:11s\n",
      "epoch 51 | loss: 0.50317 | val_0_mse: 0.54952 |  0:00:11s\n",
      "epoch 52 | loss: 0.49973 | val_0_mse: 0.54173 |  0:00:12s\n",
      "epoch 53 | loss: 0.50616 | val_0_mse: 0.60279 |  0:00:12s\n",
      "epoch 54 | loss: 0.50349 | val_0_mse: 0.55854 |  0:00:12s\n",
      "epoch 55 | loss: 0.49234 | val_0_mse: 0.58944 |  0:00:12s\n",
      "epoch 56 | loss: 0.50614 | val_0_mse: 0.57112 |  0:00:12s\n",
      "epoch 57 | loss: 0.50331 | val_0_mse: 0.55052 |  0:00:13s\n",
      "epoch 58 | loss: 0.49565 | val_0_mse: 0.55546 |  0:00:13s\n",
      "epoch 59 | loss: 0.493   | val_0_mse: 0.54374 |  0:00:13s\n",
      "epoch 60 | loss: 0.48624 | val_0_mse: 0.56881 |  0:00:13s\n",
      "epoch 61 | loss: 0.49473 | val_0_mse: 0.53248 |  0:00:14s\n",
      "epoch 62 | loss: 0.49933 | val_0_mse: 0.60574 |  0:00:14s\n",
      "epoch 63 | loss: 0.50097 | val_0_mse: 0.54191 |  0:00:14s\n",
      "epoch 64 | loss: 0.4885  | val_0_mse: 0.5505  |  0:00:14s\n",
      "epoch 65 | loss: 0.47541 | val_0_mse: 0.52693 |  0:00:15s\n",
      "epoch 66 | loss: 0.50684 | val_0_mse: 0.60747 |  0:00:15s\n",
      "epoch 67 | loss: 0.52191 | val_0_mse: 0.5382  |  0:00:15s\n",
      "epoch 68 | loss: 0.48739 | val_0_mse: 0.58549 |  0:00:15s\n",
      "epoch 69 | loss: 0.51183 | val_0_mse: 0.53123 |  0:00:15s\n",
      "epoch 70 | loss: 0.49259 | val_0_mse: 0.5582  |  0:00:16s\n",
      "epoch 71 | loss: 0.49151 | val_0_mse: 0.53074 |  0:00:16s\n",
      "epoch 72 | loss: 0.49822 | val_0_mse: 0.55119 |  0:00:16s\n",
      "epoch 73 | loss: 0.49617 | val_0_mse: 0.54493 |  0:00:16s\n",
      "epoch 74 | loss: 0.48168 | val_0_mse: 0.52346 |  0:00:17s\n",
      "epoch 75 | loss: 0.4809  | val_0_mse: 0.53836 |  0:00:17s\n",
      "epoch 76 | loss: 0.48041 | val_0_mse: 0.54125 |  0:00:17s\n",
      "epoch 77 | loss: 0.47708 | val_0_mse: 0.5468  |  0:00:17s\n",
      "epoch 78 | loss: 0.48519 | val_0_mse: 0.5327  |  0:00:17s\n",
      "epoch 79 | loss: 0.48588 | val_0_mse: 0.54101 |  0:00:18s\n",
      "epoch 80 | loss: 0.47213 | val_0_mse: 0.54623 |  0:00:18s\n",
      "epoch 81 | loss: 0.47822 | val_0_mse: 0.52243 |  0:00:18s\n",
      "epoch 82 | loss: 0.48471 | val_0_mse: 0.57684 |  0:00:19s\n",
      "epoch 83 | loss: 0.51552 | val_0_mse: 0.56818 |  0:00:19s\n",
      "epoch 84 | loss: 0.58913 | val_0_mse: 0.56559 |  0:00:19s\n",
      "epoch 85 | loss: 0.51776 | val_0_mse: 0.5347  |  0:00:19s\n",
      "epoch 86 | loss: 0.48578 | val_0_mse: 0.55887 |  0:00:19s\n",
      "epoch 87 | loss: 0.51724 | val_0_mse: 0.52937 |  0:00:20s\n",
      "epoch 88 | loss: 0.53521 | val_0_mse: 0.52574 |  0:00:20s\n",
      "epoch 89 | loss: 0.50614 | val_0_mse: 0.51064 |  0:00:20s\n",
      "epoch 90 | loss: 0.4821  | val_0_mse: 0.51713 |  0:00:20s\n",
      "epoch 91 | loss: 0.47601 | val_0_mse: 0.51393 |  0:00:21s\n",
      "epoch 92 | loss: 0.4766  | val_0_mse: 0.51633 |  0:00:21s\n",
      "epoch 93 | loss: 0.47934 | val_0_mse: 0.52659 |  0:00:21s\n",
      "epoch 94 | loss: 0.47409 | val_0_mse: 0.51258 |  0:00:21s\n",
      "epoch 95 | loss: 0.47895 | val_0_mse: 0.52119 |  0:00:21s\n",
      "epoch 96 | loss: 0.47652 | val_0_mse: 0.52586 |  0:00:22s\n",
      "epoch 97 | loss: 0.4716  | val_0_mse: 0.5169  |  0:00:22s\n",
      "epoch 98 | loss: 0.48055 | val_0_mse: 0.51704 |  0:00:22s\n",
      "epoch 99 | loss: 0.47802 | val_0_mse: 0.51544 |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_mse = 0.51064\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6039... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78437</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">elated-sweep-48</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/le0e36ph\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/le0e36ph</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045700-le0e36ph/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2vnpozp9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2416040601877383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/2vnpozp9\" target=\"_blank\">fast-sweep-49</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.22397 | val_0_mse: 2.01349 |  0:00:00s\n",
      "epoch 1  | loss: 1.5174  | val_0_mse: 1.33916 |  0:00:00s\n",
      "epoch 2  | loss: 1.08465 | val_0_mse: 1.05134 |  0:00:00s\n",
      "epoch 3  | loss: 1.03597 | val_0_mse: 1.29656 |  0:00:01s\n",
      "epoch 4  | loss: 0.95277 | val_0_mse: 0.93203 |  0:00:01s\n",
      "epoch 5  | loss: 0.89542 | val_0_mse: 1.15249 |  0:00:01s\n",
      "epoch 6  | loss: 0.75416 | val_0_mse: 1.13118 |  0:00:02s\n",
      "epoch 7  | loss: 0.71988 | val_0_mse: 1.00932 |  0:00:02s\n",
      "epoch 8  | loss: 0.61516 | val_0_mse: 0.90581 |  0:00:02s\n",
      "epoch 9  | loss: 0.65524 | val_0_mse: 1.05552 |  0:00:03s\n",
      "epoch 10 | loss: 0.5953  | val_0_mse: 0.9123  |  0:00:03s\n",
      "epoch 11 | loss: 0.64465 | val_0_mse: 0.84397 |  0:00:03s\n",
      "epoch 12 | loss: 0.64931 | val_0_mse: 0.72649 |  0:00:04s\n",
      "epoch 13 | loss: 0.66263 | val_0_mse: 0.90672 |  0:00:04s\n",
      "epoch 14 | loss: 0.60956 | val_0_mse: 0.84647 |  0:00:04s\n",
      "epoch 15 | loss: 0.60914 | val_0_mse: 0.84323 |  0:00:05s\n",
      "epoch 16 | loss: 0.55496 | val_0_mse: 0.86824 |  0:00:05s\n",
      "epoch 17 | loss: 0.53396 | val_0_mse: 0.78116 |  0:00:05s\n",
      "epoch 18 | loss: 0.53365 | val_0_mse: 0.75935 |  0:00:05s\n",
      "epoch 19 | loss: 0.54413 | val_0_mse: 0.80511 |  0:00:06s\n",
      "epoch 20 | loss: 0.54976 | val_0_mse: 0.70196 |  0:00:06s\n",
      "epoch 21 | loss: 0.52292 | val_0_mse: 0.75089 |  0:00:06s\n",
      "epoch 22 | loss: 0.50881 | val_0_mse: 0.77971 |  0:00:07s\n",
      "epoch 23 | loss: 0.54619 | val_0_mse: 0.69492 |  0:00:07s\n",
      "epoch 24 | loss: 0.56062 | val_0_mse: 0.86423 |  0:00:07s\n",
      "epoch 25 | loss: 0.56191 | val_0_mse: 0.67021 |  0:00:08s\n",
      "epoch 26 | loss: 0.57877 | val_0_mse: 0.7048  |  0:00:08s\n",
      "epoch 27 | loss: 0.56462 | val_0_mse: 0.68805 |  0:00:08s\n",
      "epoch 28 | loss: 0.54735 | val_0_mse: 0.72782 |  0:00:09s\n",
      "epoch 29 | loss: 0.52797 | val_0_mse: 0.69402 |  0:00:09s\n",
      "epoch 30 | loss: 0.52624 | val_0_mse: 0.66547 |  0:00:09s\n",
      "epoch 31 | loss: 0.51614 | val_0_mse: 0.71657 |  0:00:10s\n",
      "epoch 32 | loss: 0.51075 | val_0_mse: 0.70014 |  0:00:10s\n",
      "epoch 33 | loss: 0.50115 | val_0_mse: 0.66429 |  0:00:10s\n",
      "epoch 34 | loss: 0.53156 | val_0_mse: 0.78674 |  0:00:11s\n",
      "epoch 35 | loss: 0.5389  | val_0_mse: 0.67755 |  0:00:11s\n",
      "epoch 36 | loss: 0.61076 | val_0_mse: 0.70619 |  0:00:11s\n",
      "epoch 37 | loss: 0.5477  | val_0_mse: 0.6252  |  0:00:11s\n",
      "epoch 38 | loss: 0.52713 | val_0_mse: 0.69486 |  0:00:12s\n",
      "epoch 39 | loss: 0.51328 | val_0_mse: 0.62398 |  0:00:12s\n",
      "epoch 40 | loss: 0.51105 | val_0_mse: 0.57771 |  0:00:12s\n",
      "epoch 41 | loss: 0.56526 | val_0_mse: 0.68844 |  0:00:13s\n",
      "epoch 42 | loss: 0.52748 | val_0_mse: 0.60174 |  0:00:13s\n",
      "epoch 43 | loss: 0.50507 | val_0_mse: 0.77795 |  0:00:13s\n",
      "epoch 44 | loss: 0.57441 | val_0_mse: 0.59658 |  0:00:14s\n",
      "epoch 45 | loss: 0.57754 | val_0_mse: 0.65964 |  0:00:14s\n",
      "epoch 46 | loss: 0.53687 | val_0_mse: 0.58154 |  0:00:14s\n",
      "epoch 47 | loss: 0.51138 | val_0_mse: 0.61603 |  0:00:15s\n",
      "epoch 48 | loss: 0.51042 | val_0_mse: 0.65244 |  0:00:15s\n",
      "epoch 49 | loss: 0.59225 | val_0_mse: 0.6354  |  0:00:15s\n",
      "epoch 50 | loss: 0.55233 | val_0_mse: 0.6125  |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_mse = 0.57771\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6084... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77004</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fast-sweep-49</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/2vnpozp9\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/2vnpozp9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045730-2vnpozp9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7e4lc7di with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0717134736713868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/7e4lc7di\" target=\"_blank\">likely-sweep-50</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 12.78371| val_0_mse: 4.31901 |  0:00:00s\n",
      "epoch 1  | loss: 2.58214 | val_0_mse: 2.56622 |  0:00:00s\n",
      "epoch 2  | loss: 1.63803 | val_0_mse: 1.20146 |  0:00:00s\n",
      "epoch 3  | loss: 1.17818 | val_0_mse: 1.30717 |  0:00:00s\n",
      "epoch 4  | loss: 0.93997 | val_0_mse: 1.28538 |  0:00:01s\n",
      "epoch 5  | loss: 0.81114 | val_0_mse: 1.19231 |  0:00:01s\n",
      "epoch 6  | loss: 0.71203 | val_0_mse: 1.27327 |  0:00:01s\n",
      "epoch 7  | loss: 0.68399 | val_0_mse: 1.14823 |  0:00:01s\n",
      "epoch 8  | loss: 0.64878 | val_0_mse: 1.18748 |  0:00:01s\n",
      "epoch 9  | loss: 0.67678 | val_0_mse: 0.94595 |  0:00:01s\n",
      "epoch 10 | loss: 0.70702 | val_0_mse: 0.90606 |  0:00:02s\n",
      "epoch 11 | loss: 0.78514 | val_0_mse: 1.01456 |  0:00:02s\n",
      "epoch 12 | loss: 0.70324 | val_0_mse: 0.92923 |  0:00:02s\n",
      "epoch 13 | loss: 0.63591 | val_0_mse: 0.87842 |  0:00:02s\n",
      "epoch 14 | loss: 0.71805 | val_0_mse: 0.87089 |  0:00:02s\n",
      "epoch 15 | loss: 0.65898 | val_0_mse: 0.82666 |  0:00:03s\n",
      "epoch 16 | loss: 0.65371 | val_0_mse: 0.95752 |  0:00:03s\n",
      "epoch 17 | loss: 0.60446 | val_0_mse: 0.81027 |  0:00:03s\n",
      "epoch 18 | loss: 0.59042 | val_0_mse: 0.75449 |  0:00:03s\n",
      "epoch 19 | loss: 0.56502 | val_0_mse: 0.88043 |  0:00:03s\n",
      "epoch 20 | loss: 0.62773 | val_0_mse: 0.76315 |  0:00:03s\n",
      "epoch 21 | loss: 0.63268 | val_0_mse: 0.92222 |  0:00:04s\n",
      "epoch 22 | loss: 0.58417 | val_0_mse: 0.7627  |  0:00:04s\n",
      "epoch 23 | loss: 0.63237 | val_0_mse: 0.83352 |  0:00:04s\n",
      "epoch 24 | loss: 0.55349 | val_0_mse: 0.77839 |  0:00:04s\n",
      "epoch 25 | loss: 0.56531 | val_0_mse: 0.87835 |  0:00:04s\n",
      "epoch 26 | loss: 0.57103 | val_0_mse: 0.75853 |  0:00:05s\n",
      "epoch 27 | loss: 0.55367 | val_0_mse: 0.81508 |  0:00:05s\n",
      "epoch 28 | loss: 0.53684 | val_0_mse: 0.80121 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 0.75449\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6133... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.74104</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">likely-sweep-50</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/7e4lc7di\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/7e4lc7di</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045755-7e4lc7di/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o2e3u2v9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1197405493696104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/o2e3u2v9\" target=\"_blank\">robust-sweep-51</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 15.09386| val_0_mse: 6.57894 |  0:00:00s\n",
      "epoch 1  | loss: 4.66272 | val_0_mse: 3.60639 |  0:00:00s\n",
      "epoch 2  | loss: 2.93647 | val_0_mse: 2.23751 |  0:00:00s\n",
      "epoch 3  | loss: 1.63752 | val_0_mse: 1.75813 |  0:00:01s\n",
      "epoch 4  | loss: 1.24484 | val_0_mse: 1.3233  |  0:00:01s\n",
      "epoch 5  | loss: 0.90905 | val_0_mse: 1.13879 |  0:00:01s\n",
      "epoch 6  | loss: 0.77335 | val_0_mse: 0.83961 |  0:00:02s\n",
      "epoch 7  | loss: 0.7061  | val_0_mse: 0.95571 |  0:00:02s\n",
      "epoch 8  | loss: 0.64754 | val_0_mse: 1.09366 |  0:00:02s\n",
      "epoch 9  | loss: 0.67351 | val_0_mse: 0.75996 |  0:00:02s\n",
      "epoch 10 | loss: 0.71161 | val_0_mse: 1.1066  |  0:00:03s\n",
      "epoch 11 | loss: 0.65445 | val_0_mse: 0.77749 |  0:00:03s\n",
      "epoch 12 | loss: 0.71994 | val_0_mse: 0.99051 |  0:00:03s\n",
      "epoch 13 | loss: 0.66707 | val_0_mse: 0.9114  |  0:00:04s\n",
      "epoch 14 | loss: 0.60358 | val_0_mse: 0.83363 |  0:00:04s\n",
      "epoch 15 | loss: 0.58861 | val_0_mse: 0.80191 |  0:00:04s\n",
      "epoch 16 | loss: 0.61257 | val_0_mse: 0.76808 |  0:00:05s\n",
      "epoch 17 | loss: 0.57466 | val_0_mse: 0.77311 |  0:00:05s\n",
      "epoch 18 | loss: 0.63198 | val_0_mse: 0.82659 |  0:00:05s\n",
      "epoch 19 | loss: 0.64572 | val_0_mse: 0.76482 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_mse = 0.75996\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6180... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.74799</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">robust-sweep-51</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/o2e3u2v9\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/o2e3u2v9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045808-o2e3u2v9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jsk9ie2s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.14939863486834087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/jsk9ie2s\" target=\"_blank\">fresh-sweep-52</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 17.81528| val_0_mse: 5.10972 |  0:00:00s\n",
      "epoch 1  | loss: 3.55926 | val_0_mse: 2.17089 |  0:00:00s\n",
      "epoch 2  | loss: 1.54133 | val_0_mse: 1.18229 |  0:00:00s\n",
      "epoch 3  | loss: 0.98715 | val_0_mse: 0.96871 |  0:00:00s\n",
      "epoch 4  | loss: 0.85525 | val_0_mse: 0.93891 |  0:00:01s\n",
      "epoch 5  | loss: 0.74565 | val_0_mse: 1.04757 |  0:00:01s\n",
      "epoch 6  | loss: 0.73871 | val_0_mse: 0.919   |  0:00:01s\n",
      "epoch 7  | loss: 0.67075 | val_0_mse: 1.01799 |  0:00:01s\n",
      "epoch 8  | loss: 0.59624 | val_0_mse: 0.91493 |  0:00:02s\n",
      "epoch 9  | loss: 0.59525 | val_0_mse: 0.85671 |  0:00:02s\n",
      "epoch 10 | loss: 0.58484 | val_0_mse: 0.98201 |  0:00:02s\n",
      "epoch 11 | loss: 0.63626 | val_0_mse: 0.88397 |  0:00:02s\n",
      "epoch 12 | loss: 0.63605 | val_0_mse: 1.10207 |  0:00:02s\n",
      "epoch 13 | loss: 0.5887  | val_0_mse: 0.96682 |  0:00:03s\n",
      "epoch 14 | loss: 0.5842  | val_0_mse: 0.97539 |  0:00:03s\n",
      "epoch 15 | loss: 0.57876 | val_0_mse: 0.94681 |  0:00:03s\n",
      "epoch 16 | loss: 0.54846 | val_0_mse: 0.80642 |  0:00:03s\n",
      "epoch 17 | loss: 0.57714 | val_0_mse: 0.94599 |  0:00:04s\n",
      "epoch 18 | loss: 0.55306 | val_0_mse: 0.83585 |  0:00:04s\n",
      "epoch 19 | loss: 0.53735 | val_0_mse: 0.80108 |  0:00:04s\n",
      "epoch 20 | loss: 0.52391 | val_0_mse: 0.79789 |  0:00:04s\n",
      "epoch 21 | loss: 0.54099 | val_0_mse: 0.86962 |  0:00:05s\n",
      "epoch 22 | loss: 0.52881 | val_0_mse: 0.80994 |  0:00:05s\n",
      "epoch 23 | loss: 0.51956 | val_0_mse: 0.74802 |  0:00:05s\n",
      "epoch 24 | loss: 0.52198 | val_0_mse: 0.76552 |  0:00:05s\n",
      "epoch 25 | loss: 0.50542 | val_0_mse: 0.75481 |  0:00:05s\n",
      "epoch 26 | loss: 0.51096 | val_0_mse: 0.74987 |  0:00:06s\n",
      "epoch 27 | loss: 0.52871 | val_0_mse: 0.78571 |  0:00:06s\n",
      "epoch 28 | loss: 0.53981 | val_0_mse: 0.77019 |  0:00:06s\n",
      "epoch 29 | loss: 0.5208  | val_0_mse: 0.76887 |  0:00:07s\n",
      "epoch 30 | loss: 0.53105 | val_0_mse: 0.77159 |  0:00:07s\n",
      "epoch 31 | loss: 0.53854 | val_0_mse: 0.66825 |  0:00:07s\n",
      "epoch 32 | loss: 0.53704 | val_0_mse: 0.77623 |  0:00:07s\n",
      "epoch 33 | loss: 0.53194 | val_0_mse: 0.63044 |  0:00:07s\n",
      "epoch 34 | loss: 0.52198 | val_0_mse: 0.64104 |  0:00:08s\n",
      "epoch 35 | loss: 0.51771 | val_0_mse: 0.69016 |  0:00:08s\n",
      "epoch 36 | loss: 0.51449 | val_0_mse: 0.70421 |  0:00:08s\n",
      "epoch 37 | loss: 0.51307 | val_0_mse: 0.64208 |  0:00:08s\n",
      "epoch 38 | loss: 0.49677 | val_0_mse: 0.73221 |  0:00:09s\n",
      "epoch 39 | loss: 0.57167 | val_0_mse: 0.62013 |  0:00:09s\n",
      "epoch 40 | loss: 0.63801 | val_0_mse: 0.63468 |  0:00:09s\n",
      "epoch 41 | loss: 0.51771 | val_0_mse: 0.62084 |  0:00:09s\n",
      "epoch 42 | loss: 0.51368 | val_0_mse: 0.63994 |  0:00:10s\n",
      "epoch 43 | loss: 0.50831 | val_0_mse: 0.61509 |  0:00:10s\n",
      "epoch 44 | loss: 0.52547 | val_0_mse: 0.65481 |  0:00:10s\n",
      "epoch 45 | loss: 0.52156 | val_0_mse: 0.60234 |  0:00:10s\n",
      "epoch 46 | loss: 0.5011  | val_0_mse: 0.60105 |  0:00:10s\n",
      "epoch 47 | loss: 0.51701 | val_0_mse: 0.58539 |  0:00:11s\n",
      "epoch 48 | loss: 0.51315 | val_0_mse: 0.56965 |  0:00:11s\n",
      "epoch 49 | loss: 0.53035 | val_0_mse: 0.78437 |  0:00:11s\n",
      "epoch 50 | loss: 0.64726 | val_0_mse: 0.61042 |  0:00:11s\n",
      "epoch 51 | loss: 0.53044 | val_0_mse: 0.57395 |  0:00:12s\n",
      "epoch 52 | loss: 0.50099 | val_0_mse: 0.55547 |  0:00:12s\n",
      "epoch 53 | loss: 0.49721 | val_0_mse: 0.55635 |  0:00:12s\n",
      "epoch 54 | loss: 0.50215 | val_0_mse: 0.58435 |  0:00:12s\n",
      "epoch 55 | loss: 0.50627 | val_0_mse: 0.56993 |  0:00:13s\n",
      "epoch 56 | loss: 0.49477 | val_0_mse: 0.56062 |  0:00:13s\n",
      "epoch 57 | loss: 0.5033  | val_0_mse: 0.55134 |  0:00:13s\n",
      "epoch 58 | loss: 0.50338 | val_0_mse: 0.63793 |  0:00:13s\n",
      "epoch 59 | loss: 0.5273  | val_0_mse: 0.57099 |  0:00:13s\n",
      "epoch 60 | loss: 0.50166 | val_0_mse: 0.59422 |  0:00:14s\n",
      "epoch 61 | loss: 0.49934 | val_0_mse: 0.56582 |  0:00:14s\n",
      "epoch 62 | loss: 0.5041  | val_0_mse: 0.5868  |  0:00:14s\n",
      "epoch 63 | loss: 0.51259 | val_0_mse: 0.60804 |  0:00:14s\n",
      "epoch 64 | loss: 0.52393 | val_0_mse: 0.56224 |  0:00:15s\n",
      "epoch 65 | loss: 0.51332 | val_0_mse: 0.59028 |  0:00:15s\n",
      "epoch 66 | loss: 0.57584 | val_0_mse: 0.57421 |  0:00:15s\n",
      "epoch 67 | loss: 0.52205 | val_0_mse: 0.55889 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 0.55134\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6240... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77519</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fresh-sweep-52</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/jsk9ie2s\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/jsk9ie2s</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045822-jsk9ie2s/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x21r0b9q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.10949583530827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/x21r0b9q\" target=\"_blank\">dauntless-sweep-53</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.72459 | val_0_mse: 1.97291 |  0:00:00s\n",
      "epoch 1  | loss: 2.24704 | val_0_mse: 1.2272  |  0:00:00s\n",
      "epoch 2  | loss: 1.51628 | val_0_mse: 1.33406 |  0:00:00s\n",
      "epoch 3  | loss: 1.1332  | val_0_mse: 1.28839 |  0:00:01s\n",
      "epoch 4  | loss: 1.05051 | val_0_mse: 1.05649 |  0:00:01s\n",
      "epoch 5  | loss: 0.77894 | val_0_mse: 0.97413 |  0:00:01s\n",
      "epoch 6  | loss: 0.80941 | val_0_mse: 1.00744 |  0:00:01s\n",
      "epoch 7  | loss: 0.82465 | val_0_mse: 0.92705 |  0:00:02s\n",
      "epoch 8  | loss: 0.7728  | val_0_mse: 1.07949 |  0:00:02s\n",
      "epoch 9  | loss: 0.6702  | val_0_mse: 0.97753 |  0:00:02s\n",
      "epoch 10 | loss: 0.65155 | val_0_mse: 0.8814  |  0:00:02s\n",
      "epoch 11 | loss: 0.63017 | val_0_mse: 0.80064 |  0:00:03s\n",
      "epoch 12 | loss: 0.62423 | val_0_mse: 0.82935 |  0:00:03s\n",
      "epoch 13 | loss: 0.66667 | val_0_mse: 0.80963 |  0:00:03s\n",
      "epoch 14 | loss: 0.59041 | val_0_mse: 0.96971 |  0:00:04s\n",
      "epoch 15 | loss: 0.62017 | val_0_mse: 0.82109 |  0:00:04s\n",
      "epoch 16 | loss: 0.62158 | val_0_mse: 0.87763 |  0:00:04s\n",
      "epoch 17 | loss: 0.57107 | val_0_mse: 0.93076 |  0:00:04s\n",
      "epoch 18 | loss: 0.62986 | val_0_mse: 0.7934  |  0:00:05s\n",
      "epoch 19 | loss: 0.56442 | val_0_mse: 0.73453 |  0:00:05s\n",
      "epoch 20 | loss: 0.56285 | val_0_mse: 0.85683 |  0:00:05s\n",
      "epoch 21 | loss: 0.54544 | val_0_mse: 0.90924 |  0:00:05s\n",
      "epoch 22 | loss: 0.59505 | val_0_mse: 0.74604 |  0:00:06s\n",
      "epoch 23 | loss: 0.55727 | val_0_mse: 0.69407 |  0:00:06s\n",
      "epoch 24 | loss: 0.5612  | val_0_mse: 0.78562 |  0:00:06s\n",
      "epoch 25 | loss: 0.58465 | val_0_mse: 0.73184 |  0:00:07s\n",
      "epoch 26 | loss: 0.58324 | val_0_mse: 0.7205  |  0:00:07s\n",
      "epoch 27 | loss: 0.60795 | val_0_mse: 0.70387 |  0:00:07s\n",
      "epoch 28 | loss: 0.53987 | val_0_mse: 0.79104 |  0:00:07s\n",
      "epoch 29 | loss: 0.64858 | val_0_mse: 0.65562 |  0:00:08s\n",
      "epoch 30 | loss: 0.73167 | val_0_mse: 0.66177 |  0:00:08s\n",
      "epoch 31 | loss: 0.58968 | val_0_mse: 0.6781  |  0:00:08s\n",
      "epoch 32 | loss: 0.53236 | val_0_mse: 0.74301 |  0:00:09s\n",
      "epoch 33 | loss: 0.53393 | val_0_mse: 0.65403 |  0:00:09s\n",
      "epoch 34 | loss: 0.52841 | val_0_mse: 0.63214 |  0:00:09s\n",
      "epoch 35 | loss: 0.51814 | val_0_mse: 0.67823 |  0:00:09s\n",
      "epoch 36 | loss: 0.51843 | val_0_mse: 0.64246 |  0:00:10s\n",
      "epoch 37 | loss: 0.51435 | val_0_mse: 0.60954 |  0:00:10s\n",
      "epoch 38 | loss: 0.50449 | val_0_mse: 0.65053 |  0:00:10s\n",
      "epoch 39 | loss: 0.49952 | val_0_mse: 0.63499 |  0:00:11s\n",
      "epoch 40 | loss: 0.50756 | val_0_mse: 0.61095 |  0:00:11s\n",
      "epoch 41 | loss: 0.50215 | val_0_mse: 0.6098  |  0:00:11s\n",
      "epoch 42 | loss: 0.50163 | val_0_mse: 0.70149 |  0:00:11s\n",
      "epoch 43 | loss: 0.54871 | val_0_mse: 0.60477 |  0:00:12s\n",
      "epoch 44 | loss: 0.6337  | val_0_mse: 0.66678 |  0:00:12s\n",
      "epoch 45 | loss: 0.5229  | val_0_mse: 0.58579 |  0:00:12s\n",
      "epoch 46 | loss: 0.51237 | val_0_mse: 0.59286 |  0:00:13s\n",
      "epoch 47 | loss: 0.51152 | val_0_mse: 0.57959 |  0:00:13s\n",
      "epoch 48 | loss: 0.51491 | val_0_mse: 0.73481 |  0:00:13s\n",
      "epoch 49 | loss: 0.60517 | val_0_mse: 0.58132 |  0:00:13s\n",
      "epoch 50 | loss: 0.50883 | val_0_mse: 0.60459 |  0:00:14s\n",
      "epoch 51 | loss: 0.48684 | val_0_mse: 0.56215 |  0:00:14s\n",
      "epoch 52 | loss: 0.48801 | val_0_mse: 0.55183 |  0:00:14s\n",
      "epoch 53 | loss: 0.48869 | val_0_mse: 0.5899  |  0:00:14s\n",
      "epoch 54 | loss: 0.4911  | val_0_mse: 0.55389 |  0:00:15s\n",
      "epoch 55 | loss: 0.50241 | val_0_mse: 0.56728 |  0:00:15s\n",
      "epoch 56 | loss: 0.50367 | val_0_mse: 0.55084 |  0:00:15s\n",
      "epoch 57 | loss: 0.49465 | val_0_mse: 0.57338 |  0:00:16s\n",
      "epoch 58 | loss: 0.50494 | val_0_mse: 0.58692 |  0:00:16s\n",
      "epoch 59 | loss: 0.51434 | val_0_mse: 0.52466 |  0:00:16s\n",
      "epoch 60 | loss: 0.5082  | val_0_mse: 0.53187 |  0:00:16s\n",
      "epoch 61 | loss: 0.48537 | val_0_mse: 0.56063 |  0:00:17s\n",
      "epoch 62 | loss: 0.49421 | val_0_mse: 0.53074 |  0:00:17s\n",
      "epoch 63 | loss: 0.506   | val_0_mse: 0.57444 |  0:00:17s\n",
      "epoch 64 | loss: 0.51952 | val_0_mse: 0.52509 |  0:00:17s\n",
      "epoch 65 | loss: 0.5189  | val_0_mse: 0.55849 |  0:00:18s\n",
      "epoch 66 | loss: 0.51754 | val_0_mse: 0.51852 |  0:00:18s\n",
      "epoch 67 | loss: 0.49861 | val_0_mse: 0.52646 |  0:00:18s\n",
      "epoch 68 | loss: 0.53217 | val_0_mse: 0.56351 |  0:00:19s\n",
      "epoch 69 | loss: 0.52289 | val_0_mse: 0.53423 |  0:00:19s\n",
      "epoch 70 | loss: 0.51684 | val_0_mse: 0.58125 |  0:00:19s\n",
      "epoch 71 | loss: 0.53456 | val_0_mse: 0.52189 |  0:00:19s\n",
      "epoch 72 | loss: 0.50985 | val_0_mse: 0.54628 |  0:00:20s\n",
      "epoch 73 | loss: 0.49479 | val_0_mse: 0.55864 |  0:00:20s\n",
      "epoch 74 | loss: 0.51898 | val_0_mse: 0.59174 |  0:00:20s\n",
      "epoch 75 | loss: 0.5181  | val_0_mse: 0.55024 |  0:00:20s\n",
      "epoch 76 | loss: 0.49557 | val_0_mse: 0.53547 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.51852\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6308... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78384</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dauntless-sweep-53</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/x21r0b9q\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/x21r0b9q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045846-x21r0b9q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lykvr0wr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.19761138852016372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/lykvr0wr\" target=\"_blank\">dainty-sweep-54</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 13.5308 | val_0_mse: 5.41194 |  0:00:00s\n",
      "epoch 1  | loss: 2.11535 | val_0_mse: 1.7154  |  0:00:00s\n",
      "epoch 2  | loss: 1.04068 | val_0_mse: 1.45645 |  0:00:00s\n",
      "epoch 3  | loss: 0.76031 | val_0_mse: 0.93968 |  0:00:00s\n",
      "epoch 4  | loss: 0.65185 | val_0_mse: 1.21271 |  0:00:00s\n",
      "epoch 5  | loss: 0.56786 | val_0_mse: 1.05487 |  0:00:01s\n",
      "epoch 6  | loss: 0.55477 | val_0_mse: 0.99984 |  0:00:01s\n",
      "epoch 7  | loss: 0.53863 | val_0_mse: 1.06437 |  0:00:01s\n",
      "epoch 8  | loss: 0.54844 | val_0_mse: 0.89462 |  0:00:01s\n",
      "epoch 9  | loss: 0.54725 | val_0_mse: 1.0719  |  0:00:01s\n",
      "epoch 10 | loss: 0.55273 | val_0_mse: 0.95415 |  0:00:01s\n",
      "epoch 11 | loss: 0.55514 | val_0_mse: 0.87901 |  0:00:02s\n",
      "epoch 12 | loss: 0.52197 | val_0_mse: 0.86248 |  0:00:02s\n",
      "epoch 13 | loss: 0.53275 | val_0_mse: 0.88055 |  0:00:02s\n",
      "epoch 14 | loss: 0.51884 | val_0_mse: 0.84326 |  0:00:02s\n",
      "epoch 15 | loss: 0.50401 | val_0_mse: 0.89815 |  0:00:02s\n",
      "epoch 16 | loss: 0.49626 | val_0_mse: 0.86487 |  0:00:02s\n",
      "epoch 17 | loss: 0.49316 | val_0_mse: 0.77253 |  0:00:03s\n",
      "epoch 18 | loss: 0.49365 | val_0_mse: 0.89281 |  0:00:03s\n",
      "epoch 19 | loss: 0.49743 | val_0_mse: 0.80256 |  0:00:03s\n",
      "epoch 20 | loss: 0.48834 | val_0_mse: 0.77397 |  0:00:03s\n",
      "epoch 21 | loss: 0.4897  | val_0_mse: 0.71594 |  0:00:03s\n",
      "epoch 22 | loss: 0.49991 | val_0_mse: 0.85782 |  0:00:03s\n",
      "epoch 23 | loss: 0.49607 | val_0_mse: 0.7427  |  0:00:04s\n",
      "epoch 24 | loss: 0.48986 | val_0_mse: 0.74585 |  0:00:04s\n",
      "epoch 25 | loss: 0.48935 | val_0_mse: 0.70644 |  0:00:04s\n",
      "epoch 26 | loss: 0.50436 | val_0_mse: 0.77507 |  0:00:04s\n",
      "epoch 27 | loss: 0.49947 | val_0_mse: 0.72006 |  0:00:04s\n",
      "epoch 28 | loss: 0.4995  | val_0_mse: 0.67705 |  0:00:04s\n",
      "epoch 29 | loss: 0.49849 | val_0_mse: 0.71848 |  0:00:05s\n",
      "epoch 30 | loss: 0.48368 | val_0_mse: 0.69399 |  0:00:05s\n",
      "epoch 31 | loss: 0.49887 | val_0_mse: 0.69422 |  0:00:05s\n",
      "epoch 32 | loss: 0.48012 | val_0_mse: 0.66241 |  0:00:05s\n",
      "epoch 33 | loss: 0.4839  | val_0_mse: 0.62396 |  0:00:05s\n",
      "epoch 34 | loss: 0.47844 | val_0_mse: 0.65329 |  0:00:06s\n",
      "epoch 35 | loss: 0.47419 | val_0_mse: 0.64428 |  0:00:06s\n",
      "epoch 36 | loss: 0.48537 | val_0_mse: 0.67482 |  0:00:06s\n",
      "epoch 37 | loss: 0.48436 | val_0_mse: 0.66601 |  0:00:06s\n",
      "epoch 38 | loss: 0.48031 | val_0_mse: 0.71743 |  0:00:06s\n",
      "epoch 39 | loss: 0.49906 | val_0_mse: 0.61313 |  0:00:06s\n",
      "epoch 40 | loss: 0.49514 | val_0_mse: 0.73564 |  0:00:07s\n",
      "epoch 41 | loss: 0.49619 | val_0_mse: 0.61929 |  0:00:07s\n",
      "epoch 42 | loss: 0.54025 | val_0_mse: 0.71212 |  0:00:07s\n",
      "epoch 43 | loss: 0.52826 | val_0_mse: 0.6143  |  0:00:07s\n",
      "epoch 44 | loss: 0.61316 | val_0_mse: 0.67666 |  0:00:07s\n",
      "epoch 45 | loss: 0.53524 | val_0_mse: 0.63946 |  0:00:08s\n",
      "epoch 46 | loss: 0.50073 | val_0_mse: 0.6013  |  0:00:08s\n",
      "epoch 47 | loss: 0.50122 | val_0_mse: 0.57037 |  0:00:08s\n",
      "epoch 48 | loss: 0.51879 | val_0_mse: 0.58994 |  0:00:08s\n",
      "epoch 49 | loss: 0.49257 | val_0_mse: 0.54793 |  0:00:08s\n",
      "epoch 50 | loss: 0.5308  | val_0_mse: 0.64474 |  0:00:08s\n",
      "epoch 51 | loss: 0.53777 | val_0_mse: 0.64804 |  0:00:09s\n",
      "epoch 52 | loss: 0.52947 | val_0_mse: 0.58955 |  0:00:09s\n",
      "epoch 53 | loss: 0.49382 | val_0_mse: 0.52694 |  0:00:09s\n",
      "epoch 54 | loss: 0.47814 | val_0_mse: 0.58231 |  0:00:09s\n",
      "epoch 55 | loss: 0.4846  | val_0_mse: 0.54917 |  0:00:09s\n",
      "epoch 56 | loss: 0.5148  | val_0_mse: 0.59899 |  0:00:09s\n",
      "epoch 57 | loss: 0.48254 | val_0_mse: 0.55699 |  0:00:10s\n",
      "epoch 58 | loss: 0.5233  | val_0_mse: 0.55764 |  0:00:10s\n",
      "epoch 59 | loss: 0.4802  | val_0_mse: 0.58935 |  0:00:10s\n",
      "epoch 60 | loss: 0.4704  | val_0_mse: 0.55182 |  0:00:10s\n",
      "epoch 61 | loss: 0.45854 | val_0_mse: 0.56142 |  0:00:10s\n",
      "epoch 62 | loss: 0.46985 | val_0_mse: 0.52648 |  0:00:10s\n",
      "epoch 63 | loss: 0.45773 | val_0_mse: 0.56498 |  0:00:11s\n",
      "epoch 64 | loss: 0.48294 | val_0_mse: 0.52121 |  0:00:11s\n",
      "epoch 65 | loss: 0.46597 | val_0_mse: 0.55485 |  0:00:11s\n",
      "epoch 66 | loss: 0.46584 | val_0_mse: 0.53209 |  0:00:11s\n",
      "epoch 67 | loss: 0.46403 | val_0_mse: 0.53435 |  0:00:11s\n",
      "epoch 68 | loss: 0.47844 | val_0_mse: 0.52656 |  0:00:12s\n",
      "epoch 69 | loss: 0.46903 | val_0_mse: 0.53275 |  0:00:12s\n",
      "epoch 70 | loss: 0.46588 | val_0_mse: 0.51605 |  0:00:12s\n",
      "epoch 71 | loss: 0.47533 | val_0_mse: 0.525   |  0:00:12s\n",
      "epoch 72 | loss: 0.47066 | val_0_mse: 0.58616 |  0:00:12s\n",
      "epoch 73 | loss: 0.49831 | val_0_mse: 0.52063 |  0:00:12s\n",
      "epoch 74 | loss: 0.47753 | val_0_mse: 0.53374 |  0:00:13s\n",
      "epoch 75 | loss: 0.48663 | val_0_mse: 0.51538 |  0:00:13s\n",
      "epoch 76 | loss: 0.47141 | val_0_mse: 0.52728 |  0:00:13s\n",
      "epoch 77 | loss: 0.46493 | val_0_mse: 0.49335 |  0:00:13s\n",
      "epoch 78 | loss: 0.46908 | val_0_mse: 0.51061 |  0:00:13s\n",
      "epoch 79 | loss: 0.46912 | val_0_mse: 0.52072 |  0:00:13s\n",
      "epoch 80 | loss: 0.48055 | val_0_mse: 0.5298  |  0:00:14s\n",
      "epoch 81 | loss: 0.4652  | val_0_mse: 0.53031 |  0:00:14s\n",
      "epoch 82 | loss: 0.47027 | val_0_mse: 0.52202 |  0:00:14s\n",
      "epoch 83 | loss: 0.47158 | val_0_mse: 0.53588 |  0:00:14s\n",
      "epoch 84 | loss: 0.48287 | val_0_mse: 0.53519 |  0:00:14s\n",
      "epoch 85 | loss: 0.47838 | val_0_mse: 0.54735 |  0:00:14s\n",
      "epoch 86 | loss: 0.47317 | val_0_mse: 0.52326 |  0:00:15s\n",
      "epoch 87 | loss: 0.47315 | val_0_mse: 0.53228 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.49335\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6513... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.79358</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dainty-sweep-54</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/lykvr0wr\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/lykvr0wr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045914-lykvr0wr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 38aamlik with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.22670926326100171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/38aamlik\" target=\"_blank\">distinctive-sweep-55</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.05195 | val_0_mse: 1.86975 |  0:00:00s\n",
      "epoch 1  | loss: 1.54053 | val_0_mse: 1.07959 |  0:00:00s\n",
      "epoch 2  | loss: 1.00934 | val_0_mse: 0.72643 |  0:00:00s\n",
      "epoch 3  | loss: 0.76185 | val_0_mse: 0.71088 |  0:00:00s\n",
      "epoch 4  | loss: 0.70871 | val_0_mse: 0.8111  |  0:00:01s\n",
      "epoch 5  | loss: 0.63781 | val_0_mse: 0.70159 |  0:00:01s\n",
      "epoch 6  | loss: 0.63418 | val_0_mse: 0.89819 |  0:00:01s\n",
      "epoch 7  | loss: 0.61431 | val_0_mse: 0.77308 |  0:00:01s\n",
      "epoch 8  | loss: 0.57221 | val_0_mse: 0.83126 |  0:00:02s\n",
      "epoch 9  | loss: 0.55064 | val_0_mse: 0.74655 |  0:00:02s\n",
      "epoch 10 | loss: 0.54007 | val_0_mse: 0.84761 |  0:00:02s\n",
      "epoch 11 | loss: 0.56375 | val_0_mse: 0.87323 |  0:00:02s\n",
      "epoch 12 | loss: 0.58483 | val_0_mse: 0.77083 |  0:00:03s\n",
      "epoch 13 | loss: 0.65888 | val_0_mse: 0.82524 |  0:00:03s\n",
      "epoch 14 | loss: 0.54049 | val_0_mse: 0.8821  |  0:00:03s\n",
      "epoch 15 | loss: 0.53076 | val_0_mse: 0.83283 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_mse = 0.70159\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6564... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.74896</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">distinctive-sweep-55</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/38aamlik\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/38aamlik</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045936-38aamlik/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: os0mfllu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.17538465272386383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/os0mfllu\" target=\"_blank\">northern-sweep-56</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.87281 | val_0_mse: 3.82924 |  0:00:00s\n",
      "epoch 1  | loss: 1.79634 | val_0_mse: 1.58643 |  0:00:00s\n",
      "epoch 2  | loss: 1.23848 | val_0_mse: 1.32013 |  0:00:00s\n",
      "epoch 3  | loss: 1.03859 | val_0_mse: 1.08882 |  0:00:00s\n",
      "epoch 4  | loss: 0.88461 | val_0_mse: 1.17988 |  0:00:00s\n",
      "epoch 5  | loss: 0.83211 | val_0_mse: 1.08954 |  0:00:00s\n",
      "epoch 6  | loss: 0.75394 | val_0_mse: 1.24673 |  0:00:01s\n",
      "epoch 7  | loss: 0.87624 | val_0_mse: 0.94051 |  0:00:01s\n",
      "epoch 8  | loss: 1.11421 | val_0_mse: 1.06448 |  0:00:01s\n",
      "epoch 9  | loss: 0.74875 | val_0_mse: 1.00775 |  0:00:01s\n",
      "epoch 10 | loss: 0.70239 | val_0_mse: 1.05407 |  0:00:01s\n",
      "epoch 11 | loss: 0.67628 | val_0_mse: 0.98269 |  0:00:01s\n",
      "epoch 12 | loss: 0.64665 | val_0_mse: 1.03312 |  0:00:02s\n",
      "epoch 13 | loss: 0.66039 | val_0_mse: 0.98644 |  0:00:02s\n",
      "epoch 14 | loss: 0.64777 | val_0_mse: 0.835   |  0:00:02s\n",
      "epoch 15 | loss: 0.61108 | val_0_mse: 0.86924 |  0:00:02s\n",
      "epoch 16 | loss: 0.6055  | val_0_mse: 0.86252 |  0:00:02s\n",
      "epoch 17 | loss: 0.61919 | val_0_mse: 0.88228 |  0:00:02s\n",
      "epoch 18 | loss: 0.61819 | val_0_mse: 0.77139 |  0:00:02s\n",
      "epoch 19 | loss: 0.61954 | val_0_mse: 0.78238 |  0:00:03s\n",
      "epoch 20 | loss: 0.61896 | val_0_mse: 0.77866 |  0:00:03s\n",
      "epoch 21 | loss: 0.61679 | val_0_mse: 0.86882 |  0:00:03s\n",
      "epoch 22 | loss: 0.60024 | val_0_mse: 0.63561 |  0:00:03s\n",
      "epoch 23 | loss: 0.62572 | val_0_mse: 0.75459 |  0:00:03s\n",
      "epoch 24 | loss: 0.57968 | val_0_mse: 0.66106 |  0:00:04s\n",
      "epoch 25 | loss: 0.54326 | val_0_mse: 0.71209 |  0:00:04s\n",
      "epoch 26 | loss: 0.54579 | val_0_mse: 0.69006 |  0:00:04s\n",
      "epoch 27 | loss: 0.53725 | val_0_mse: 0.65239 |  0:00:04s\n",
      "epoch 28 | loss: 0.55676 | val_0_mse: 0.67742 |  0:00:04s\n",
      "epoch 29 | loss: 0.55137 | val_0_mse: 0.64244 |  0:00:04s\n",
      "epoch 30 | loss: 0.5571  | val_0_mse: 0.72115 |  0:00:05s\n",
      "epoch 31 | loss: 0.56132 | val_0_mse: 0.73883 |  0:00:05s\n",
      "epoch 32 | loss: 0.56444 | val_0_mse: 0.65171 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 0.63561\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6645... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.75747</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">northern-sweep-56</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/os0mfllu\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/os0mfllu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045946-os0mfllu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rpmubbmt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.3131903327988993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/rpmubbmt\" target=\"_blank\">magic-sweep-57</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 11.82991| val_0_mse: 1.88979 |  0:00:00s\n",
      "epoch 1  | loss: 2.50345 | val_0_mse: 1.21274 |  0:00:00s\n",
      "epoch 2  | loss: 1.4856  | val_0_mse: 0.91496 |  0:00:00s\n",
      "epoch 3  | loss: 1.06736 | val_0_mse: 1.29653 |  0:00:01s\n",
      "epoch 4  | loss: 0.8107  | val_0_mse: 1.03256 |  0:00:01s\n",
      "epoch 5  | loss: 0.79735 | val_0_mse: 1.00133 |  0:00:01s\n",
      "epoch 6  | loss: 0.70396 | val_0_mse: 0.82779 |  0:00:02s\n",
      "epoch 7  | loss: 0.66938 | val_0_mse: 0.89699 |  0:00:02s\n",
      "epoch 8  | loss: 0.62522 | val_0_mse: 1.03654 |  0:00:02s\n",
      "epoch 9  | loss: 0.60268 | val_0_mse: 0.84432 |  0:00:03s\n",
      "epoch 10 | loss: 0.60336 | val_0_mse: 0.81882 |  0:00:03s\n",
      "epoch 11 | loss: 0.60686 | val_0_mse: 1.04131 |  0:00:03s\n",
      "epoch 12 | loss: 0.64623 | val_0_mse: 0.78168 |  0:00:03s\n",
      "epoch 13 | loss: 0.60372 | val_0_mse: 0.79068 |  0:00:04s\n",
      "epoch 14 | loss: 0.58918 | val_0_mse: 0.85502 |  0:00:04s\n",
      "epoch 15 | loss: 0.56965 | val_0_mse: 0.85908 |  0:00:04s\n",
      "epoch 16 | loss: 0.59335 | val_0_mse: 0.80095 |  0:00:05s\n",
      "epoch 17 | loss: 0.56726 | val_0_mse: 0.82097 |  0:00:05s\n",
      "epoch 18 | loss: 0.5574  | val_0_mse: 0.85691 |  0:00:05s\n",
      "epoch 19 | loss: 0.6026  | val_0_mse: 0.73414 |  0:00:06s\n",
      "epoch 20 | loss: 0.54778 | val_0_mse: 0.81354 |  0:00:06s\n",
      "epoch 21 | loss: 0.55058 | val_0_mse: 0.84103 |  0:00:06s\n",
      "epoch 22 | loss: 0.55925 | val_0_mse: 0.82446 |  0:00:06s\n",
      "epoch 23 | loss: 0.54672 | val_0_mse: 0.73899 |  0:00:07s\n",
      "epoch 24 | loss: 0.5456  | val_0_mse: 0.75058 |  0:00:07s\n",
      "epoch 25 | loss: 0.54648 | val_0_mse: 0.67609 |  0:00:07s\n",
      "epoch 26 | loss: 0.54404 | val_0_mse: 0.70902 |  0:00:08s\n",
      "epoch 27 | loss: 0.55562 | val_0_mse: 0.65872 |  0:00:08s\n",
      "epoch 28 | loss: 0.55988 | val_0_mse: 0.68423 |  0:00:08s\n",
      "epoch 29 | loss: 0.54099 | val_0_mse: 0.72302 |  0:00:09s\n",
      "epoch 30 | loss: 0.60185 | val_0_mse: 0.6687  |  0:00:09s\n",
      "epoch 31 | loss: 0.53111 | val_0_mse: 0.67445 |  0:00:09s\n",
      "epoch 32 | loss: 0.52461 | val_0_mse: 0.6687  |  0:00:09s\n",
      "epoch 33 | loss: 0.51066 | val_0_mse: 0.69797 |  0:00:10s\n",
      "epoch 34 | loss: 0.51768 | val_0_mse: 0.69574 |  0:00:10s\n",
      "epoch 35 | loss: 0.53201 | val_0_mse: 0.62566 |  0:00:10s\n",
      "epoch 36 | loss: 0.52497 | val_0_mse: 0.64439 |  0:00:11s\n",
      "epoch 37 | loss: 0.53363 | val_0_mse: 0.74904 |  0:00:11s\n",
      "epoch 38 | loss: 0.60245 | val_0_mse: 0.71662 |  0:00:11s\n",
      "epoch 39 | loss: 0.70886 | val_0_mse: 0.6874  |  0:00:12s\n",
      "epoch 40 | loss: 0.57783 | val_0_mse: 0.72766 |  0:00:12s\n",
      "epoch 41 | loss: 0.54501 | val_0_mse: 0.72116 |  0:00:12s\n",
      "epoch 42 | loss: 0.64546 | val_0_mse: 0.58817 |  0:00:12s\n",
      "epoch 43 | loss: 0.56523 | val_0_mse: 0.65583 |  0:00:13s\n",
      "epoch 44 | loss: 0.53301 | val_0_mse: 0.67759 |  0:00:13s\n",
      "epoch 45 | loss: 0.53133 | val_0_mse: 0.66098 |  0:00:13s\n",
      "epoch 46 | loss: 0.61209 | val_0_mse: 0.67932 |  0:00:14s\n",
      "epoch 47 | loss: 0.60118 | val_0_mse: 0.586   |  0:00:14s\n",
      "epoch 48 | loss: 0.56306 | val_0_mse: 0.6504  |  0:00:14s\n",
      "epoch 49 | loss: 0.55979 | val_0_mse: 0.71575 |  0:00:15s\n",
      "epoch 50 | loss: 0.59963 | val_0_mse: 0.65075 |  0:00:15s\n",
      "epoch 51 | loss: 0.6142  | val_0_mse: 0.64385 |  0:00:15s\n",
      "epoch 52 | loss: 0.68144 | val_0_mse: 0.60983 |  0:00:15s\n",
      "epoch 53 | loss: 0.59306 | val_0_mse: 0.63324 |  0:00:16s\n",
      "epoch 54 | loss: 0.56302 | val_0_mse: 0.62319 |  0:00:16s\n",
      "epoch 55 | loss: 0.54702 | val_0_mse: 0.56125 |  0:00:16s\n",
      "epoch 56 | loss: 0.53617 | val_0_mse: 0.59852 |  0:00:17s\n",
      "epoch 57 | loss: 0.5178  | val_0_mse: 0.57906 |  0:00:17s\n",
      "epoch 58 | loss: 0.52175 | val_0_mse: 0.5863  |  0:00:17s\n",
      "epoch 59 | loss: 0.52508 | val_0_mse: 0.55103 |  0:00:18s\n",
      "epoch 60 | loss: 0.525   | val_0_mse: 0.56248 |  0:00:18s\n",
      "epoch 61 | loss: 0.52866 | val_0_mse: 0.56122 |  0:00:18s\n",
      "epoch 62 | loss: 0.52045 | val_0_mse: 0.56554 |  0:00:19s\n",
      "epoch 63 | loss: 0.53558 | val_0_mse: 0.56761 |  0:00:19s\n",
      "epoch 64 | loss: 0.53313 | val_0_mse: 0.5572  |  0:00:19s\n",
      "epoch 65 | loss: 0.52367 | val_0_mse: 0.61608 |  0:00:19s\n",
      "epoch 66 | loss: 0.54939 | val_0_mse: 0.56723 |  0:00:20s\n",
      "epoch 67 | loss: 0.54486 | val_0_mse: 0.5873  |  0:00:20s\n",
      "epoch 68 | loss: 0.53219 | val_0_mse: 0.57108 |  0:00:20s\n",
      "epoch 69 | loss: 0.53997 | val_0_mse: 0.589   |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 0.55103\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6686... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76814</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">magic-sweep-57</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/rpmubbmt\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/rpmubbmt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_045957-rpmubbmt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ffovfp9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.39824743920085537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/7ffovfp9\" target=\"_blank\">swept-sweep-58</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 16.77794| val_0_mse: 6.30339 |  0:00:00s\n",
      "epoch 1  | loss: 2.64032 | val_0_mse: 1.50036 |  0:00:00s\n",
      "epoch 2  | loss: 1.13558 | val_0_mse: 1.62663 |  0:00:00s\n",
      "epoch 3  | loss: 0.80803 | val_0_mse: 1.25791 |  0:00:00s\n",
      "epoch 4  | loss: 0.7213  | val_0_mse: 1.26326 |  0:00:00s\n",
      "epoch 5  | loss: 0.65806 | val_0_mse: 0.96019 |  0:00:00s\n",
      "epoch 6  | loss: 0.62658 | val_0_mse: 0.968   |  0:00:00s\n",
      "epoch 7  | loss: 0.58558 | val_0_mse: 0.93233 |  0:00:00s\n",
      "epoch 8  | loss: 0.57401 | val_0_mse: 1.09536 |  0:00:01s\n",
      "epoch 9  | loss: 0.60205 | val_0_mse: 0.96164 |  0:00:01s\n",
      "epoch 10 | loss: 0.60434 | val_0_mse: 1.00416 |  0:00:01s\n",
      "epoch 11 | loss: 0.63517 | val_0_mse: 0.9261  |  0:00:01s\n",
      "epoch 12 | loss: 0.54892 | val_0_mse: 0.86674 |  0:00:01s\n",
      "epoch 13 | loss: 0.54816 | val_0_mse: 0.88544 |  0:00:01s\n",
      "epoch 14 | loss: 0.53769 | val_0_mse: 0.76877 |  0:00:01s\n",
      "epoch 15 | loss: 0.5397  | val_0_mse: 0.83604 |  0:00:01s\n",
      "epoch 16 | loss: 0.53019 | val_0_mse: 0.77398 |  0:00:01s\n",
      "epoch 17 | loss: 0.53348 | val_0_mse: 0.78585 |  0:00:01s\n",
      "epoch 18 | loss: 0.50438 | val_0_mse: 0.78974 |  0:00:02s\n",
      "epoch 19 | loss: 0.50681 | val_0_mse: 0.77497 |  0:00:02s\n",
      "epoch 20 | loss: 0.50484 | val_0_mse: 0.80333 |  0:00:02s\n",
      "epoch 21 | loss: 0.52832 | val_0_mse: 0.70102 |  0:00:02s\n",
      "epoch 22 | loss: 0.49965 | val_0_mse: 0.77976 |  0:00:02s\n",
      "epoch 23 | loss: 0.4933  | val_0_mse: 0.70162 |  0:00:02s\n",
      "epoch 24 | loss: 0.48712 | val_0_mse: 0.84368 |  0:00:02s\n",
      "epoch 25 | loss: 0.50128 | val_0_mse: 0.72707 |  0:00:02s\n",
      "epoch 26 | loss: 0.49161 | val_0_mse: 0.76502 |  0:00:02s\n",
      "epoch 27 | loss: 0.48048 | val_0_mse: 0.63324 |  0:00:02s\n",
      "epoch 28 | loss: 0.48601 | val_0_mse: 0.69575 |  0:00:03s\n",
      "epoch 29 | loss: 0.50005 | val_0_mse: 0.63821 |  0:00:03s\n",
      "epoch 30 | loss: 0.48862 | val_0_mse: 0.69826 |  0:00:03s\n",
      "epoch 31 | loss: 0.50466 | val_0_mse: 0.77871 |  0:00:03s\n",
      "epoch 32 | loss: 0.5158  | val_0_mse: 0.7285  |  0:00:03s\n",
      "epoch 33 | loss: 0.51206 | val_0_mse: 0.71282 |  0:00:03s\n",
      "epoch 34 | loss: 0.51497 | val_0_mse: 0.72096 |  0:00:03s\n",
      "epoch 35 | loss: 0.50212 | val_0_mse: 0.79721 |  0:00:03s\n",
      "epoch 36 | loss: 0.52657 | val_0_mse: 0.6618  |  0:00:03s\n",
      "epoch 37 | loss: 0.49986 | val_0_mse: 0.62869 |  0:00:03s\n",
      "epoch 38 | loss: 0.50643 | val_0_mse: 0.62801 |  0:00:04s\n",
      "epoch 39 | loss: 0.51612 | val_0_mse: 0.76246 |  0:00:04s\n",
      "epoch 40 | loss: 0.54703 | val_0_mse: 0.61766 |  0:00:04s\n",
      "epoch 41 | loss: 0.50868 | val_0_mse: 0.68914 |  0:00:04s\n",
      "epoch 42 | loss: 0.5342  | val_0_mse: 0.57384 |  0:00:04s\n",
      "epoch 43 | loss: 0.53651 | val_0_mse: 0.59065 |  0:00:04s\n",
      "epoch 44 | loss: 0.50437 | val_0_mse: 0.61078 |  0:00:04s\n",
      "epoch 45 | loss: 0.49414 | val_0_mse: 0.61636 |  0:00:04s\n",
      "epoch 46 | loss: 0.4864  | val_0_mse: 0.62466 |  0:00:04s\n",
      "epoch 47 | loss: 0.488   | val_0_mse: 0.59014 |  0:00:04s\n",
      "epoch 48 | loss: 0.5014  | val_0_mse: 0.54202 |  0:00:05s\n",
      "epoch 49 | loss: 0.49887 | val_0_mse: 0.57282 |  0:00:05s\n",
      "epoch 50 | loss: 0.50357 | val_0_mse: 0.57727 |  0:00:05s\n",
      "epoch 51 | loss: 0.49207 | val_0_mse: 0.59785 |  0:00:05s\n",
      "epoch 52 | loss: 0.48671 | val_0_mse: 0.57574 |  0:00:05s\n",
      "epoch 53 | loss: 0.49103 | val_0_mse: 0.54258 |  0:00:05s\n",
      "epoch 54 | loss: 0.49992 | val_0_mse: 0.60103 |  0:00:05s\n",
      "epoch 55 | loss: 0.5006  | val_0_mse: 0.59867 |  0:00:05s\n",
      "epoch 56 | loss: 0.49222 | val_0_mse: 0.53567 |  0:00:05s\n",
      "epoch 57 | loss: 0.49426 | val_0_mse: 0.53437 |  0:00:05s\n",
      "epoch 58 | loss: 0.49086 | val_0_mse: 0.58029 |  0:00:06s\n",
      "epoch 59 | loss: 0.51269 | val_0_mse: 0.55038 |  0:00:06s\n",
      "epoch 60 | loss: 0.51147 | val_0_mse: 0.56114 |  0:00:06s\n",
      "epoch 61 | loss: 0.5068  | val_0_mse: 0.55363 |  0:00:06s\n",
      "epoch 62 | loss: 0.498   | val_0_mse: 0.58758 |  0:00:06s\n",
      "epoch 63 | loss: 0.49791 | val_0_mse: 0.54069 |  0:00:06s\n",
      "epoch 64 | loss: 0.49906 | val_0_mse: 0.53957 |  0:00:06s\n",
      "epoch 65 | loss: 0.50168 | val_0_mse: 0.52717 |  0:00:06s\n",
      "epoch 66 | loss: 0.5058  | val_0_mse: 0.57978 |  0:00:06s\n",
      "epoch 67 | loss: 0.49354 | val_0_mse: 0.58807 |  0:00:06s\n",
      "epoch 68 | loss: 0.49912 | val_0_mse: 0.55451 |  0:00:07s\n",
      "epoch 69 | loss: 0.49611 | val_0_mse: 0.55902 |  0:00:07s\n",
      "epoch 70 | loss: 0.54881 | val_0_mse: 0.54764 |  0:00:07s\n",
      "epoch 71 | loss: 0.48283 | val_0_mse: 0.55135 |  0:00:07s\n",
      "epoch 72 | loss: 0.50398 | val_0_mse: 0.55505 |  0:00:07s\n",
      "epoch 73 | loss: 0.48202 | val_0_mse: 0.53762 |  0:00:07s\n",
      "epoch 74 | loss: 0.48542 | val_0_mse: 0.51425 |  0:00:07s\n",
      "epoch 75 | loss: 0.50593 | val_0_mse: 0.55112 |  0:00:07s\n",
      "epoch 76 | loss: 0.48674 | val_0_mse: 0.53392 |  0:00:07s\n",
      "epoch 77 | loss: 0.48462 | val_0_mse: 0.55045 |  0:00:07s\n",
      "epoch 78 | loss: 0.48297 | val_0_mse: 0.55242 |  0:00:08s\n",
      "epoch 79 | loss: 0.48988 | val_0_mse: 0.54141 |  0:00:08s\n",
      "epoch 80 | loss: 0.50981 | val_0_mse: 0.52828 |  0:00:08s\n",
      "epoch 81 | loss: 0.48629 | val_0_mse: 0.529   |  0:00:08s\n",
      "epoch 82 | loss: 0.48407 | val_0_mse: 0.51099 |  0:00:08s\n",
      "epoch 83 | loss: 0.47839 | val_0_mse: 0.54658 |  0:00:08s\n",
      "epoch 84 | loss: 0.48284 | val_0_mse: 0.51871 |  0:00:08s\n",
      "epoch 85 | loss: 0.48208 | val_0_mse: 0.51755 |  0:00:08s\n",
      "epoch 86 | loss: 0.49095 | val_0_mse: 0.52309 |  0:00:08s\n",
      "epoch 87 | loss: 0.47941 | val_0_mse: 0.52223 |  0:00:08s\n",
      "epoch 88 | loss: 0.4884  | val_0_mse: 0.52716 |  0:00:09s\n",
      "epoch 89 | loss: 0.49096 | val_0_mse: 0.50551 |  0:00:09s\n",
      "epoch 90 | loss: 0.48913 | val_0_mse: 0.50983 |  0:00:09s\n",
      "epoch 91 | loss: 0.51004 | val_0_mse: 0.50717 |  0:00:09s\n",
      "epoch 92 | loss: 0.49558 | val_0_mse: 0.50844 |  0:00:09s\n",
      "epoch 93 | loss: 0.48529 | val_0_mse: 0.49466 |  0:00:09s\n",
      "epoch 94 | loss: 0.48886 | val_0_mse: 0.50088 |  0:00:09s\n",
      "epoch 95 | loss: 0.47519 | val_0_mse: 0.50965 |  0:00:09s\n",
      "epoch 96 | loss: 0.48367 | val_0_mse: 0.51882 |  0:00:09s\n",
      "epoch 97 | loss: 0.49108 | val_0_mse: 0.51475 |  0:00:09s\n",
      "epoch 98 | loss: 0.48688 | val_0_mse: 0.52457 |  0:00:10s\n",
      "epoch 99 | loss: 0.50015 | val_0_mse: 0.53737 |  0:00:10s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_mse = 0.49466\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6730... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.79219</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">swept-sweep-58</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/7ffovfp9\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/7ffovfp9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050025-7ffovfp9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i802kydd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.02692973194021571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/i802kydd\" target=\"_blank\">eager-sweep-59</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 12.11009| val_0_mse: 4.0031  |  0:00:00s\n",
      "epoch 1  | loss: 3.31891 | val_0_mse: 2.33968 |  0:00:00s\n",
      "epoch 2  | loss: 1.60484 | val_0_mse: 1.98184 |  0:00:01s\n",
      "epoch 3  | loss: 1.19211 | val_0_mse: 1.5017  |  0:00:01s\n",
      "epoch 4  | loss: 0.9554  | val_0_mse: 1.43052 |  0:00:01s\n",
      "epoch 5  | loss: 0.80941 | val_0_mse: 1.30826 |  0:00:02s\n",
      "epoch 6  | loss: 0.7267  | val_0_mse: 0.96667 |  0:00:02s\n",
      "epoch 7  | loss: 0.70161 | val_0_mse: 0.88609 |  0:00:02s\n",
      "epoch 8  | loss: 0.71444 | val_0_mse: 0.83159 |  0:00:03s\n",
      "epoch 9  | loss: 0.63    | val_0_mse: 0.94928 |  0:00:03s\n",
      "epoch 10 | loss: 0.61761 | val_0_mse: 0.94911 |  0:00:03s\n",
      "epoch 11 | loss: 0.58925 | val_0_mse: 0.8579  |  0:00:04s\n",
      "epoch 12 | loss: 0.63652 | val_0_mse: 1.10147 |  0:00:04s\n",
      "epoch 13 | loss: 0.65699 | val_0_mse: 0.87827 |  0:00:04s\n",
      "epoch 14 | loss: 0.60963 | val_0_mse: 0.98783 |  0:00:05s\n",
      "epoch 15 | loss: 0.57177 | val_0_mse: 0.85387 |  0:00:05s\n",
      "epoch 16 | loss: 0.57497 | val_0_mse: 0.99447 |  0:00:05s\n",
      "epoch 17 | loss: 0.54781 | val_0_mse: 0.93829 |  0:00:06s\n",
      "epoch 18 | loss: 0.53515 | val_0_mse: 0.76669 |  0:00:06s\n",
      "epoch 19 | loss: 0.57516 | val_0_mse: 0.8047  |  0:00:06s\n",
      "epoch 20 | loss: 0.55755 | val_0_mse: 0.73781 |  0:00:07s\n",
      "epoch 21 | loss: 0.55388 | val_0_mse: 0.8325  |  0:00:07s\n",
      "epoch 22 | loss: 0.54131 | val_0_mse: 0.74505 |  0:00:07s\n",
      "epoch 23 | loss: 0.55276 | val_0_mse: 0.74133 |  0:00:08s\n",
      "epoch 24 | loss: 0.51909 | val_0_mse: 0.77518 |  0:00:08s\n",
      "epoch 25 | loss: 0.52628 | val_0_mse: 0.70912 |  0:00:08s\n",
      "epoch 26 | loss: 0.52597 | val_0_mse: 0.74432 |  0:00:09s\n",
      "epoch 27 | loss: 0.51988 | val_0_mse: 0.714   |  0:00:09s\n",
      "epoch 28 | loss: 0.52292 | val_0_mse: 0.73694 |  0:00:09s\n",
      "epoch 29 | loss: 0.51684 | val_0_mse: 0.69131 |  0:00:10s\n",
      "epoch 30 | loss: 0.50675 | val_0_mse: 0.74989 |  0:00:10s\n",
      "epoch 31 | loss: 0.5075  | val_0_mse: 0.68223 |  0:00:10s\n",
      "epoch 32 | loss: 0.50938 | val_0_mse: 0.76586 |  0:00:11s\n",
      "epoch 33 | loss: 0.50229 | val_0_mse: 0.6556  |  0:00:11s\n",
      "epoch 34 | loss: 0.50694 | val_0_mse: 0.69228 |  0:00:11s\n",
      "epoch 35 | loss: 0.50097 | val_0_mse: 0.67543 |  0:00:12s\n",
      "epoch 36 | loss: 0.49645 | val_0_mse: 0.72535 |  0:00:12s\n",
      "epoch 37 | loss: 0.49503 | val_0_mse: 0.65511 |  0:00:12s\n",
      "epoch 38 | loss: 0.51384 | val_0_mse: 0.74756 |  0:00:13s\n",
      "epoch 39 | loss: 0.49954 | val_0_mse: 0.60631 |  0:00:13s\n",
      "epoch 40 | loss: 0.50144 | val_0_mse: 0.62154 |  0:00:13s\n",
      "epoch 41 | loss: 0.49541 | val_0_mse: 0.6659  |  0:00:14s\n",
      "epoch 42 | loss: 0.51657 | val_0_mse: 0.62024 |  0:00:14s\n",
      "epoch 43 | loss: 0.4995  | val_0_mse: 0.59092 |  0:00:14s\n",
      "epoch 44 | loss: 0.50614 | val_0_mse: 0.61607 |  0:00:15s\n",
      "epoch 45 | loss: 0.5106  | val_0_mse: 0.61355 |  0:00:15s\n",
      "epoch 46 | loss: 0.50551 | val_0_mse: 0.59265 |  0:00:15s\n",
      "epoch 47 | loss: 0.48279 | val_0_mse: 0.61306 |  0:00:16s\n",
      "epoch 48 | loss: 0.49342 | val_0_mse: 0.60359 |  0:00:16s\n",
      "epoch 49 | loss: 0.50361 | val_0_mse: 0.61149 |  0:00:16s\n",
      "epoch 50 | loss: 0.50775 | val_0_mse: 0.60757 |  0:00:17s\n",
      "epoch 51 | loss: 0.49802 | val_0_mse: 0.61872 |  0:00:17s\n",
      "epoch 52 | loss: 0.48438 | val_0_mse: 0.56557 |  0:00:17s\n",
      "epoch 53 | loss: 0.48009 | val_0_mse: 0.56883 |  0:00:18s\n",
      "epoch 54 | loss: 0.49508 | val_0_mse: 0.60351 |  0:00:18s\n",
      "epoch 55 | loss: 0.52925 | val_0_mse: 0.56026 |  0:00:18s\n",
      "epoch 56 | loss: 0.51623 | val_0_mse: 0.69729 |  0:00:19s\n",
      "epoch 57 | loss: 0.75377 | val_0_mse: 0.66584 |  0:00:19s\n",
      "epoch 58 | loss: 0.57839 | val_0_mse: 0.55955 |  0:00:19s\n",
      "epoch 59 | loss: 0.53658 | val_0_mse: 0.7004  |  0:00:20s\n",
      "epoch 60 | loss: 0.55446 | val_0_mse: 0.55465 |  0:00:20s\n",
      "epoch 61 | loss: 0.51127 | val_0_mse: 0.58027 |  0:00:21s\n",
      "epoch 62 | loss: 0.50305 | val_0_mse: 0.53281 |  0:00:21s\n",
      "epoch 63 | loss: 0.48675 | val_0_mse: 0.55368 |  0:00:21s\n",
      "epoch 64 | loss: 0.47417 | val_0_mse: 0.5299  |  0:00:22s\n",
      "epoch 65 | loss: 0.48383 | val_0_mse: 0.58742 |  0:00:22s\n",
      "epoch 66 | loss: 0.50221 | val_0_mse: 0.5345  |  0:00:22s\n",
      "epoch 67 | loss: 0.50316 | val_0_mse: 0.53651 |  0:00:23s\n",
      "epoch 68 | loss: 0.49019 | val_0_mse: 0.53927 |  0:00:23s\n",
      "epoch 69 | loss: 0.49112 | val_0_mse: 0.51343 |  0:00:23s\n",
      "epoch 70 | loss: 0.49672 | val_0_mse: 0.51742 |  0:00:24s\n",
      "epoch 71 | loss: 0.48908 | val_0_mse: 0.53464 |  0:00:24s\n",
      "epoch 72 | loss: 0.48296 | val_0_mse: 0.52727 |  0:00:24s\n",
      "epoch 73 | loss: 0.49376 | val_0_mse: 0.52106 |  0:00:25s\n",
      "epoch 74 | loss: 0.49942 | val_0_mse: 0.5277  |  0:00:25s\n",
      "epoch 75 | loss: 0.49863 | val_0_mse: 0.511   |  0:00:25s\n",
      "epoch 76 | loss: 0.49556 | val_0_mse: 0.58866 |  0:00:26s\n",
      "epoch 77 | loss: 0.53072 | val_0_mse: 0.6075  |  0:00:26s\n",
      "epoch 78 | loss: 0.55339 | val_0_mse: 0.56343 |  0:00:26s\n",
      "epoch 79 | loss: 0.50831 | val_0_mse: 0.526   |  0:00:27s\n",
      "epoch 80 | loss: 0.51993 | val_0_mse: 0.57569 |  0:00:27s\n",
      "epoch 81 | loss: 0.49968 | val_0_mse: 0.52971 |  0:00:27s\n",
      "epoch 82 | loss: 0.50275 | val_0_mse: 0.58441 |  0:00:28s\n",
      "epoch 83 | loss: 0.49992 | val_0_mse: 0.52226 |  0:00:28s\n",
      "epoch 84 | loss: 0.49003 | val_0_mse: 0.52872 |  0:00:28s\n",
      "epoch 85 | loss: 0.48021 | val_0_mse: 0.51246 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_mse = 0.511\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6782... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78656</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">eager-sweep-59</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/i802kydd\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/i802kydd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050042-i802kydd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ntzrnv5q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.39664403048307567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ntzrnv5q\" target=\"_blank\">vague-sweep-60</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 6.0286  | val_0_mse: 2.16581 |  0:00:00s\n",
      "epoch 1  | loss: 1.5285  | val_0_mse: 1.99693 |  0:00:00s\n",
      "epoch 2  | loss: 0.91071 | val_0_mse: 1.45105 |  0:00:00s\n",
      "epoch 3  | loss: 0.72965 | val_0_mse: 1.27236 |  0:00:00s\n",
      "epoch 4  | loss: 0.63668 | val_0_mse: 0.99091 |  0:00:00s\n",
      "epoch 5  | loss: 0.63711 | val_0_mse: 1.06871 |  0:00:00s\n",
      "epoch 6  | loss: 0.59886 | val_0_mse: 0.91554 |  0:00:01s\n",
      "epoch 7  | loss: 0.6089  | val_0_mse: 1.00667 |  0:00:01s\n",
      "epoch 8  | loss: 0.5822  | val_0_mse: 1.02635 |  0:00:01s\n",
      "epoch 9  | loss: 0.58626 | val_0_mse: 0.99454 |  0:00:01s\n",
      "epoch 10 | loss: 0.57027 | val_0_mse: 0.91796 |  0:00:01s\n",
      "epoch 11 | loss: 0.55551 | val_0_mse: 0.93503 |  0:00:01s\n",
      "epoch 12 | loss: 0.56199 | val_0_mse: 0.99572 |  0:00:01s\n",
      "epoch 13 | loss: 0.58858 | val_0_mse: 0.82586 |  0:00:01s\n",
      "epoch 14 | loss: 0.61463 | val_0_mse: 0.97421 |  0:00:02s\n",
      "epoch 15 | loss: 0.58496 | val_0_mse: 0.81171 |  0:00:02s\n",
      "epoch 16 | loss: 0.54884 | val_0_mse: 0.78261 |  0:00:02s\n",
      "epoch 17 | loss: 0.5512  | val_0_mse: 0.85864 |  0:00:02s\n",
      "epoch 18 | loss: 0.57277 | val_0_mse: 0.74252 |  0:00:02s\n",
      "epoch 19 | loss: 0.56567 | val_0_mse: 0.7988  |  0:00:02s\n",
      "epoch 20 | loss: 0.55544 | val_0_mse: 0.8212  |  0:00:02s\n",
      "epoch 21 | loss: 0.5456  | val_0_mse: 0.78626 |  0:00:03s\n",
      "epoch 22 | loss: 0.57617 | val_0_mse: 0.91665 |  0:00:03s\n",
      "epoch 23 | loss: 0.63114 | val_0_mse: 0.82999 |  0:00:03s\n",
      "epoch 24 | loss: 0.54993 | val_0_mse: 0.75805 |  0:00:03s\n",
      "epoch 25 | loss: 0.54258 | val_0_mse: 0.86517 |  0:00:03s\n",
      "epoch 26 | loss: 0.53576 | val_0_mse: 0.77499 |  0:00:03s\n",
      "epoch 27 | loss: 0.5357  | val_0_mse: 0.79858 |  0:00:03s\n",
      "epoch 28 | loss: 0.53828 | val_0_mse: 0.79067 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 0.74252\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6836... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76109</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vague-sweep-60</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ntzrnv5q\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/ntzrnv5q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050118-ntzrnv5q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: klq9na2d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1558285912464298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/klq9na2d\" target=\"_blank\">drawn-sweep-61</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 15.31974| val_0_mse: 1.52343 |  0:00:00s\n",
      "epoch 1  | loss: 3.66572 | val_0_mse: 1.56107 |  0:00:00s\n",
      "epoch 2  | loss: 2.05441 | val_0_mse: 1.41905 |  0:00:00s\n",
      "epoch 3  | loss: 1.28888 | val_0_mse: 0.84584 |  0:00:00s\n",
      "epoch 4  | loss: 0.98457 | val_0_mse: 0.88369 |  0:00:00s\n",
      "epoch 5  | loss: 0.75133 | val_0_mse: 0.90368 |  0:00:01s\n",
      "epoch 6  | loss: 0.64545 | val_0_mse: 0.91939 |  0:00:01s\n",
      "epoch 7  | loss: 0.6125  | val_0_mse: 0.83669 |  0:00:01s\n",
      "epoch 8  | loss: 0.59041 | val_0_mse: 0.83644 |  0:00:01s\n",
      "epoch 9  | loss: 0.55383 | val_0_mse: 0.85012 |  0:00:01s\n",
      "epoch 10 | loss: 0.55014 | val_0_mse: 0.79757 |  0:00:01s\n",
      "epoch 11 | loss: 0.52711 | val_0_mse: 0.74896 |  0:00:02s\n",
      "epoch 12 | loss: 0.52946 | val_0_mse: 0.76145 |  0:00:02s\n",
      "epoch 13 | loss: 0.51628 | val_0_mse: 0.76985 |  0:00:02s\n",
      "epoch 14 | loss: 0.5181  | val_0_mse: 0.76162 |  0:00:02s\n",
      "epoch 15 | loss: 0.51979 | val_0_mse: 0.7127  |  0:00:02s\n",
      "epoch 16 | loss: 0.54188 | val_0_mse: 0.85712 |  0:00:02s\n",
      "epoch 17 | loss: 0.54462 | val_0_mse: 0.67479 |  0:00:03s\n",
      "epoch 18 | loss: 0.52764 | val_0_mse: 0.70685 |  0:00:03s\n",
      "epoch 19 | loss: 0.52202 | val_0_mse: 0.71011 |  0:00:03s\n",
      "epoch 20 | loss: 0.524   | val_0_mse: 0.69677 |  0:00:03s\n",
      "epoch 21 | loss: 0.51616 | val_0_mse: 0.70398 |  0:00:03s\n",
      "epoch 22 | loss: 0.50099 | val_0_mse: 0.67561 |  0:00:03s\n",
      "epoch 23 | loss: 0.50806 | val_0_mse: 0.66406 |  0:00:04s\n",
      "epoch 24 | loss: 0.51872 | val_0_mse: 0.66797 |  0:00:04s\n",
      "epoch 25 | loss: 0.5316  | val_0_mse: 0.75075 |  0:00:04s\n",
      "epoch 26 | loss: 0.51435 | val_0_mse: 0.71162 |  0:00:04s\n",
      "epoch 27 | loss: 0.51667 | val_0_mse: 0.77591 |  0:00:04s\n",
      "epoch 28 | loss: 0.52301 | val_0_mse: 0.68291 |  0:00:04s\n",
      "epoch 29 | loss: 0.52683 | val_0_mse: 0.74163 |  0:00:05s\n",
      "epoch 30 | loss: 0.52524 | val_0_mse: 0.64913 |  0:00:05s\n",
      "epoch 31 | loss: 0.51194 | val_0_mse: 0.67531 |  0:00:05s\n",
      "epoch 32 | loss: 0.50508 | val_0_mse: 0.65828 |  0:00:05s\n",
      "epoch 33 | loss: 0.49674 | val_0_mse: 0.62124 |  0:00:05s\n",
      "epoch 34 | loss: 0.48668 | val_0_mse: 0.61262 |  0:00:05s\n",
      "epoch 35 | loss: 0.5088  | val_0_mse: 0.60732 |  0:00:06s\n",
      "epoch 36 | loss: 0.51284 | val_0_mse: 0.63201 |  0:00:06s\n",
      "epoch 37 | loss: 0.51419 | val_0_mse: 0.6316  |  0:00:06s\n",
      "epoch 38 | loss: 0.51645 | val_0_mse: 0.63334 |  0:00:06s\n",
      "epoch 39 | loss: 0.51204 | val_0_mse: 0.63288 |  0:00:06s\n",
      "epoch 40 | loss: 0.51246 | val_0_mse: 0.64402 |  0:00:06s\n",
      "epoch 41 | loss: 0.50466 | val_0_mse: 0.62093 |  0:00:07s\n",
      "epoch 42 | loss: 0.50881 | val_0_mse: 0.63228 |  0:00:07s\n",
      "epoch 43 | loss: 0.50299 | val_0_mse: 0.61187 |  0:00:07s\n",
      "epoch 44 | loss: 0.49982 | val_0_mse: 0.61432 |  0:00:07s\n",
      "epoch 45 | loss: 0.49289 | val_0_mse: 0.59855 |  0:00:07s\n",
      "epoch 46 | loss: 0.49609 | val_0_mse: 0.58747 |  0:00:08s\n",
      "epoch 47 | loss: 0.48762 | val_0_mse: 0.5698  |  0:00:08s\n",
      "epoch 48 | loss: 0.49151 | val_0_mse: 0.59582 |  0:00:08s\n",
      "epoch 49 | loss: 0.50085 | val_0_mse: 0.5874  |  0:00:08s\n",
      "epoch 50 | loss: 0.49659 | val_0_mse: 0.62131 |  0:00:08s\n",
      "epoch 51 | loss: 0.50497 | val_0_mse: 0.58102 |  0:00:09s\n",
      "epoch 52 | loss: 0.49996 | val_0_mse: 0.62078 |  0:00:09s\n",
      "epoch 53 | loss: 0.49014 | val_0_mse: 0.55889 |  0:00:09s\n",
      "epoch 54 | loss: 0.48892 | val_0_mse: 0.6128  |  0:00:09s\n",
      "epoch 55 | loss: 0.51654 | val_0_mse: 0.54927 |  0:00:09s\n",
      "epoch 56 | loss: 0.50663 | val_0_mse: 0.58662 |  0:00:09s\n",
      "epoch 57 | loss: 0.48886 | val_0_mse: 0.57285 |  0:00:10s\n",
      "epoch 58 | loss: 0.50094 | val_0_mse: 0.56952 |  0:00:10s\n",
      "epoch 59 | loss: 0.5427  | val_0_mse: 0.63763 |  0:00:10s\n",
      "epoch 60 | loss: 0.55464 | val_0_mse: 0.57054 |  0:00:10s\n",
      "epoch 61 | loss: 0.51695 | val_0_mse: 0.55309 |  0:00:10s\n",
      "epoch 62 | loss: 0.49322 | val_0_mse: 0.56311 |  0:00:10s\n",
      "epoch 63 | loss: 0.49283 | val_0_mse: 0.58067 |  0:00:11s\n",
      "epoch 64 | loss: 0.4893  | val_0_mse: 0.54593 |  0:00:11s\n",
      "epoch 65 | loss: 0.49457 | val_0_mse: 0.55066 |  0:00:11s\n",
      "epoch 66 | loss: 0.48177 | val_0_mse: 0.5516  |  0:00:11s\n",
      "epoch 67 | loss: 0.49601 | val_0_mse: 0.57363 |  0:00:11s\n",
      "epoch 68 | loss: 0.4933  | val_0_mse: 0.56923 |  0:00:11s\n",
      "epoch 69 | loss: 0.50244 | val_0_mse: 0.58566 |  0:00:12s\n",
      "epoch 70 | loss: 0.4969  | val_0_mse: 0.55795 |  0:00:12s\n",
      "epoch 71 | loss: 0.50292 | val_0_mse: 0.58323 |  0:00:12s\n",
      "epoch 72 | loss: 0.50059 | val_0_mse: 0.54803 |  0:00:12s\n",
      "epoch 73 | loss: 0.49522 | val_0_mse: 0.54373 |  0:00:12s\n",
      "epoch 74 | loss: 0.48302 | val_0_mse: 0.52114 |  0:00:12s\n",
      "epoch 75 | loss: 0.48226 | val_0_mse: 0.54538 |  0:00:13s\n",
      "epoch 76 | loss: 0.48385 | val_0_mse: 0.52017 |  0:00:13s\n",
      "epoch 77 | loss: 0.48492 | val_0_mse: 0.53564 |  0:00:13s\n",
      "epoch 78 | loss: 0.51481 | val_0_mse: 0.54929 |  0:00:13s\n",
      "epoch 79 | loss: 0.50262 | val_0_mse: 0.53823 |  0:00:13s\n",
      "epoch 80 | loss: 0.4987  | val_0_mse: 0.55756 |  0:00:14s\n",
      "epoch 81 | loss: 0.53021 | val_0_mse: 0.54736 |  0:00:14s\n",
      "epoch 82 | loss: 0.54288 | val_0_mse: 0.52666 |  0:00:14s\n",
      "epoch 83 | loss: 0.49485 | val_0_mse: 0.53454 |  0:00:14s\n",
      "epoch 84 | loss: 0.49951 | val_0_mse: 0.57016 |  0:00:14s\n",
      "epoch 85 | loss: 0.51132 | val_0_mse: 0.55016 |  0:00:14s\n",
      "epoch 86 | loss: 0.51434 | val_0_mse: 0.5432  |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.52017\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6878... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78083</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">drawn-sweep-61</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/klq9na2d\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/klq9na2d</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050129-klq9na2d/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gbxbft3j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.14486611429798987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/gbxbft3j\" target=\"_blank\">frosty-sweep-62</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.65941 | val_0_mse: 2.50536 |  0:00:00s\n",
      "epoch 1  | loss: 2.66058 | val_0_mse: 2.0671  |  0:00:00s\n",
      "epoch 2  | loss: 1.42536 | val_0_mse: 1.17384 |  0:00:00s\n",
      "epoch 3  | loss: 0.92642 | val_0_mse: 1.465   |  0:00:01s\n",
      "epoch 4  | loss: 0.76557 | val_0_mse: 1.01089 |  0:00:01s\n",
      "epoch 5  | loss: 0.71474 | val_0_mse: 1.06636 |  0:00:01s\n",
      "epoch 6  | loss: 0.71629 | val_0_mse: 0.88842 |  0:00:01s\n",
      "epoch 7  | loss: 0.79516 | val_0_mse: 1.29621 |  0:00:02s\n",
      "epoch 8  | loss: 0.69097 | val_0_mse: 0.92009 |  0:00:02s\n",
      "epoch 9  | loss: 0.6179  | val_0_mse: 0.87869 |  0:00:02s\n",
      "epoch 10 | loss: 0.59405 | val_0_mse: 0.94348 |  0:00:03s\n",
      "epoch 11 | loss: 0.61179 | val_0_mse: 1.16931 |  0:00:03s\n",
      "epoch 12 | loss: 0.64831 | val_0_mse: 0.94348 |  0:00:03s\n",
      "epoch 13 | loss: 0.59304 | val_0_mse: 0.90716 |  0:00:03s\n",
      "epoch 14 | loss: 0.55922 | val_0_mse: 0.83975 |  0:00:04s\n",
      "epoch 15 | loss: 0.56133 | val_0_mse: 0.90837 |  0:00:04s\n",
      "epoch 16 | loss: 0.54823 | val_0_mse: 0.81262 |  0:00:04s\n",
      "epoch 17 | loss: 0.53621 | val_0_mse: 0.79639 |  0:00:04s\n",
      "epoch 18 | loss: 0.53142 | val_0_mse: 0.79078 |  0:00:05s\n",
      "epoch 19 | loss: 0.5067  | val_0_mse: 0.73913 |  0:00:05s\n",
      "epoch 20 | loss: 0.5255  | val_0_mse: 0.8606  |  0:00:05s\n",
      "epoch 21 | loss: 0.53429 | val_0_mse: 0.75457 |  0:00:06s\n",
      "epoch 22 | loss: 0.52066 | val_0_mse: 0.74117 |  0:00:06s\n",
      "epoch 23 | loss: 0.5079  | val_0_mse: 0.81709 |  0:00:06s\n",
      "epoch 24 | loss: 0.51836 | val_0_mse: 0.72388 |  0:00:06s\n",
      "epoch 25 | loss: 0.51667 | val_0_mse: 0.72991 |  0:00:07s\n",
      "epoch 26 | loss: 0.58357 | val_0_mse: 0.86812 |  0:00:07s\n",
      "epoch 27 | loss: 0.57144 | val_0_mse: 0.78774 |  0:00:07s\n",
      "epoch 28 | loss: 0.55256 | val_0_mse: 0.82396 |  0:00:07s\n",
      "epoch 29 | loss: 0.56895 | val_0_mse: 0.76673 |  0:00:08s\n",
      "epoch 30 | loss: 0.61491 | val_0_mse: 0.82641 |  0:00:08s\n",
      "epoch 31 | loss: 0.55695 | val_0_mse: 0.70304 |  0:00:08s\n",
      "epoch 32 | loss: 0.52474 | val_0_mse: 0.68894 |  0:00:09s\n",
      "epoch 33 | loss: 0.52017 | val_0_mse: 0.73655 |  0:00:09s\n",
      "epoch 34 | loss: 0.5293  | val_0_mse: 0.74812 |  0:00:09s\n",
      "epoch 35 | loss: 0.52612 | val_0_mse: 0.72954 |  0:00:09s\n",
      "epoch 36 | loss: 0.6358  | val_0_mse: 0.78031 |  0:00:10s\n",
      "epoch 37 | loss: 0.64362 | val_0_mse: 0.76446 |  0:00:10s\n",
      "epoch 38 | loss: 0.52    | val_0_mse: 0.71968 |  0:00:10s\n",
      "epoch 39 | loss: 0.51405 | val_0_mse: 0.69507 |  0:00:11s\n",
      "epoch 40 | loss: 0.51654 | val_0_mse: 0.69348 |  0:00:11s\n",
      "epoch 41 | loss: 0.52706 | val_0_mse: 0.56933 |  0:00:11s\n",
      "epoch 42 | loss: 0.54752 | val_0_mse: 0.62506 |  0:00:11s\n",
      "epoch 43 | loss: 0.5168  | val_0_mse: 0.53729 |  0:00:12s\n",
      "epoch 44 | loss: 0.49908 | val_0_mse: 0.57129 |  0:00:12s\n",
      "epoch 45 | loss: 0.49985 | val_0_mse: 0.6102  |  0:00:12s\n",
      "epoch 46 | loss: 0.50743 | val_0_mse: 0.54909 |  0:00:13s\n",
      "epoch 47 | loss: 0.52074 | val_0_mse: 0.70019 |  0:00:13s\n",
      "epoch 48 | loss: 0.63789 | val_0_mse: 0.6796  |  0:00:13s\n",
      "epoch 49 | loss: 0.53176 | val_0_mse: 0.57672 |  0:00:13s\n",
      "epoch 50 | loss: 0.50674 | val_0_mse: 0.56765 |  0:00:14s\n",
      "epoch 51 | loss: 0.48967 | val_0_mse: 0.5525  |  0:00:14s\n",
      "epoch 52 | loss: 0.49382 | val_0_mse: 0.5378  |  0:00:14s\n",
      "epoch 53 | loss: 0.49003 | val_0_mse: 0.55253 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_mse = 0.53729\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6966... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78015</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">frosty-sweep-62</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/gbxbft3j\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/gbxbft3j</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050152-gbxbft3j/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 878qgo8w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.18980648565673217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/878qgo8w\" target=\"_blank\">glorious-sweep-63</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.13534 | val_0_mse: 2.90818 |  0:00:00s\n",
      "epoch 1  | loss: 1.69288 | val_0_mse: 1.34774 |  0:00:00s\n",
      "epoch 2  | loss: 1.15534 | val_0_mse: 1.1711  |  0:00:00s\n",
      "epoch 3  | loss: 0.88986 | val_0_mse: 1.10623 |  0:00:00s\n",
      "epoch 4  | loss: 0.7944  | val_0_mse: 1.07661 |  0:00:00s\n",
      "epoch 5  | loss: 0.7359  | val_0_mse: 0.79185 |  0:00:01s\n",
      "epoch 6  | loss: 0.66735 | val_0_mse: 1.02921 |  0:00:01s\n",
      "epoch 7  | loss: 0.65209 | val_0_mse: 0.81703 |  0:00:01s\n",
      "epoch 8  | loss: 0.66492 | val_0_mse: 0.90362 |  0:00:01s\n",
      "epoch 9  | loss: 0.59248 | val_0_mse: 0.79953 |  0:00:01s\n",
      "epoch 10 | loss: 0.5698  | val_0_mse: 0.93461 |  0:00:02s\n",
      "epoch 11 | loss: 0.53256 | val_0_mse: 0.85645 |  0:00:02s\n",
      "epoch 12 | loss: 0.53268 | val_0_mse: 0.83683 |  0:00:02s\n",
      "epoch 13 | loss: 0.54313 | val_0_mse: 0.85853 |  0:00:02s\n",
      "epoch 14 | loss: 0.55054 | val_0_mse: 0.7807  |  0:00:02s\n",
      "epoch 15 | loss: 0.53978 | val_0_mse: 0.7865  |  0:00:03s\n",
      "epoch 16 | loss: 0.58113 | val_0_mse: 0.93281 |  0:00:03s\n",
      "epoch 17 | loss: 0.69647 | val_0_mse: 0.82924 |  0:00:03s\n",
      "epoch 18 | loss: 0.55903 | val_0_mse: 0.80903 |  0:00:03s\n",
      "epoch 19 | loss: 0.51337 | val_0_mse: 0.74489 |  0:00:03s\n",
      "epoch 20 | loss: 0.52036 | val_0_mse: 0.7743  |  0:00:04s\n",
      "epoch 21 | loss: 0.51002 | val_0_mse: 0.81816 |  0:00:04s\n",
      "epoch 22 | loss: 0.51979 | val_0_mse: 0.78721 |  0:00:04s\n",
      "epoch 23 | loss: 0.53623 | val_0_mse: 0.87725 |  0:00:04s\n",
      "epoch 24 | loss: 0.55482 | val_0_mse: 0.79066 |  0:00:04s\n",
      "epoch 25 | loss: 0.55833 | val_0_mse: 0.81124 |  0:00:05s\n",
      "epoch 26 | loss: 0.5216  | val_0_mse: 0.75437 |  0:00:05s\n",
      "epoch 27 | loss: 0.70344 | val_0_mse: 0.76855 |  0:00:05s\n",
      "epoch 28 | loss: 0.56872 | val_0_mse: 0.97404 |  0:00:05s\n",
      "epoch 29 | loss: 0.54421 | val_0_mse: 0.75926 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.74489\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7049... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.75479</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glorious-sweep-63</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/878qgo8w\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/878qgo8w</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050216-878qgo8w/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d520ldqg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.1413065134201494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/d520ldqg\" target=\"_blank\">crimson-sweep-64</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 10.5664 | val_0_mse: 3.49571 |  0:00:00s\n",
      "epoch 1  | loss: 3.27786 | val_0_mse: 1.47093 |  0:00:00s\n",
      "epoch 2  | loss: 1.19668 | val_0_mse: 1.49769 |  0:00:00s\n",
      "epoch 3  | loss: 0.80269 | val_0_mse: 1.13506 |  0:00:00s\n",
      "epoch 4  | loss: 0.67211 | val_0_mse: 0.94115 |  0:00:00s\n",
      "epoch 5  | loss: 0.61501 | val_0_mse: 0.99163 |  0:00:00s\n",
      "epoch 6  | loss: 0.58585 | val_0_mse: 0.95559 |  0:00:00s\n",
      "epoch 7  | loss: 0.57089 | val_0_mse: 1.03524 |  0:00:01s\n",
      "epoch 8  | loss: 0.56768 | val_0_mse: 0.90585 |  0:00:01s\n",
      "epoch 9  | loss: 0.55403 | val_0_mse: 0.91824 |  0:00:01s\n",
      "epoch 10 | loss: 0.53813 | val_0_mse: 0.85772 |  0:00:01s\n",
      "epoch 11 | loss: 0.52908 | val_0_mse: 0.93583 |  0:00:01s\n",
      "epoch 12 | loss: 0.53149 | val_0_mse: 0.8961  |  0:00:01s\n",
      "epoch 13 | loss: 0.50566 | val_0_mse: 0.80166 |  0:00:01s\n",
      "epoch 14 | loss: 0.51412 | val_0_mse: 0.93283 |  0:00:02s\n",
      "epoch 15 | loss: 0.50815 | val_0_mse: 0.87988 |  0:00:02s\n",
      "epoch 16 | loss: 0.49928 | val_0_mse: 0.83464 |  0:00:02s\n",
      "epoch 17 | loss: 0.50759 | val_0_mse: 0.85954 |  0:00:02s\n",
      "epoch 18 | loss: 0.49418 | val_0_mse: 0.74499 |  0:00:02s\n",
      "epoch 19 | loss: 0.50903 | val_0_mse: 0.81641 |  0:00:02s\n",
      "epoch 20 | loss: 0.49807 | val_0_mse: 0.74598 |  0:00:02s\n",
      "epoch 21 | loss: 0.50495 | val_0_mse: 0.81802 |  0:00:03s\n",
      "epoch 22 | loss: 0.50836 | val_0_mse: 0.73947 |  0:00:03s\n",
      "epoch 23 | loss: 0.49781 | val_0_mse: 0.73696 |  0:00:03s\n",
      "epoch 24 | loss: 0.49788 | val_0_mse: 0.79306 |  0:00:03s\n",
      "epoch 25 | loss: 0.50178 | val_0_mse: 0.80358 |  0:00:03s\n",
      "epoch 26 | loss: 0.49991 | val_0_mse: 0.72262 |  0:00:03s\n",
      "epoch 27 | loss: 0.49128 | val_0_mse: 0.71544 |  0:00:03s\n",
      "epoch 28 | loss: 0.49088 | val_0_mse: 0.78281 |  0:00:04s\n",
      "epoch 29 | loss: 0.5114  | val_0_mse: 0.64028 |  0:00:04s\n",
      "epoch 30 | loss: 0.5284  | val_0_mse: 0.88986 |  0:00:04s\n",
      "epoch 31 | loss: 0.63581 | val_0_mse: 0.78744 |  0:00:04s\n",
      "epoch 32 | loss: 0.53895 | val_0_mse: 0.71991 |  0:00:04s\n",
      "epoch 33 | loss: 0.48866 | val_0_mse: 0.63542 |  0:00:04s\n",
      "epoch 34 | loss: 0.48749 | val_0_mse: 0.68364 |  0:00:04s\n",
      "epoch 35 | loss: 0.49185 | val_0_mse: 0.6136  |  0:00:04s\n",
      "epoch 36 | loss: 0.49663 | val_0_mse: 0.72945 |  0:00:05s\n",
      "epoch 37 | loss: 0.50636 | val_0_mse: 0.61363 |  0:00:05s\n",
      "epoch 38 | loss: 0.49783 | val_0_mse: 0.62026 |  0:00:05s\n",
      "epoch 39 | loss: 0.49578 | val_0_mse: 0.77608 |  0:00:05s\n",
      "epoch 40 | loss: 0.596   | val_0_mse: 0.69738 |  0:00:05s\n",
      "epoch 41 | loss: 0.49677 | val_0_mse: 0.66839 |  0:00:05s\n",
      "epoch 42 | loss: 0.49085 | val_0_mse: 0.59541 |  0:00:05s\n",
      "epoch 43 | loss: 0.49185 | val_0_mse: 0.65161 |  0:00:06s\n",
      "epoch 44 | loss: 0.48733 | val_0_mse: 0.58794 |  0:00:06s\n",
      "epoch 45 | loss: 0.49452 | val_0_mse: 0.62257 |  0:00:06s\n",
      "epoch 46 | loss: 0.48843 | val_0_mse: 0.57193 |  0:00:06s\n",
      "epoch 47 | loss: 0.48215 | val_0_mse: 0.59441 |  0:00:06s\n",
      "epoch 48 | loss: 0.48113 | val_0_mse: 0.63509 |  0:00:06s\n",
      "epoch 49 | loss: 0.49396 | val_0_mse: 0.53955 |  0:00:07s\n",
      "epoch 50 | loss: 0.49069 | val_0_mse: 0.6212  |  0:00:07s\n",
      "epoch 51 | loss: 0.48967 | val_0_mse: 0.55847 |  0:00:07s\n",
      "epoch 52 | loss: 0.48248 | val_0_mse: 0.58974 |  0:00:07s\n",
      "epoch 53 | loss: 0.48171 | val_0_mse: 0.58213 |  0:00:07s\n",
      "epoch 54 | loss: 0.48649 | val_0_mse: 0.53846 |  0:00:07s\n",
      "epoch 55 | loss: 0.47924 | val_0_mse: 0.56198 |  0:00:07s\n",
      "epoch 56 | loss: 0.47552 | val_0_mse: 0.58392 |  0:00:08s\n",
      "epoch 57 | loss: 0.50305 | val_0_mse: 0.52728 |  0:00:08s\n",
      "epoch 58 | loss: 0.48376 | val_0_mse: 0.61825 |  0:00:08s\n",
      "epoch 59 | loss: 0.50539 | val_0_mse: 0.54115 |  0:00:08s\n",
      "epoch 60 | loss: 0.47705 | val_0_mse: 0.57221 |  0:00:08s\n",
      "epoch 61 | loss: 0.47763 | val_0_mse: 0.53015 |  0:00:08s\n",
      "epoch 62 | loss: 0.46553 | val_0_mse: 0.52241 |  0:00:08s\n",
      "epoch 63 | loss: 0.46944 | val_0_mse: 0.53181 |  0:00:09s\n",
      "epoch 64 | loss: 0.46788 | val_0_mse: 0.5299  |  0:00:09s\n",
      "epoch 65 | loss: 0.47493 | val_0_mse: 0.56754 |  0:00:09s\n",
      "epoch 66 | loss: 0.48553 | val_0_mse: 0.53942 |  0:00:09s\n",
      "epoch 67 | loss: 0.48857 | val_0_mse: 0.54125 |  0:00:09s\n",
      "epoch 68 | loss: 0.48663 | val_0_mse: 0.52108 |  0:00:09s\n",
      "epoch 69 | loss: 0.48297 | val_0_mse: 0.54594 |  0:00:09s\n",
      "epoch 70 | loss: 0.46874 | val_0_mse: 0.52624 |  0:00:10s\n",
      "epoch 71 | loss: 0.46613 | val_0_mse: 0.51416 |  0:00:10s\n",
      "epoch 72 | loss: 0.46992 | val_0_mse: 0.55034 |  0:00:10s\n",
      "epoch 73 | loss: 0.47437 | val_0_mse: 0.51927 |  0:00:10s\n",
      "epoch 74 | loss: 0.4861  | val_0_mse: 0.58551 |  0:00:10s\n",
      "epoch 75 | loss: 0.512   | val_0_mse: 0.51799 |  0:00:10s\n",
      "epoch 76 | loss: 0.54832 | val_0_mse: 0.5335  |  0:00:11s\n",
      "epoch 77 | loss: 0.49594 | val_0_mse: 0.50501 |  0:00:11s\n",
      "epoch 78 | loss: 0.48556 | val_0_mse: 0.5341  |  0:00:11s\n",
      "epoch 79 | loss: 0.47352 | val_0_mse: 0.52675 |  0:00:11s\n",
      "epoch 80 | loss: 0.48723 | val_0_mse: 0.53007 |  0:00:11s\n",
      "epoch 81 | loss: 0.4744  | val_0_mse: 0.53168 |  0:00:11s\n",
      "epoch 82 | loss: 0.47926 | val_0_mse: 0.49875 |  0:00:11s\n",
      "epoch 83 | loss: 0.46851 | val_0_mse: 0.50925 |  0:00:12s\n",
      "epoch 84 | loss: 0.463   | val_0_mse: 0.5045  |  0:00:12s\n",
      "epoch 85 | loss: 0.4712  | val_0_mse: 0.50706 |  0:00:12s\n",
      "epoch 86 | loss: 0.46703 | val_0_mse: 0.53138 |  0:00:12s\n",
      "epoch 87 | loss: 0.47533 | val_0_mse: 0.51396 |  0:00:12s\n",
      "epoch 88 | loss: 0.46762 | val_0_mse: 0.52487 |  0:00:12s\n",
      "epoch 89 | loss: 0.47326 | val_0_mse: 0.51754 |  0:00:12s\n",
      "epoch 90 | loss: 0.4752  | val_0_mse: 0.579   |  0:00:13s\n",
      "epoch 91 | loss: 0.50111 | val_0_mse: 0.55497 |  0:00:13s\n",
      "epoch 92 | loss: 0.50444 | val_0_mse: 0.553   |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 92 with best_epoch = 82 and best_val_0_mse = 0.49875\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7091... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.7899</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">crimson-sweep-64</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/d520ldqg\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/d520ldqg</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050228-d520ldqg/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uqix3lgx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.2271219626467975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/uqix3lgx\" target=\"_blank\">rural-sweep-65</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 17.07612| val_0_mse: 2.72081 |  0:00:00s\n",
      "epoch 1  | loss: 3.114   | val_0_mse: 0.95189 |  0:00:00s\n",
      "epoch 2  | loss: 1.30087 | val_0_mse: 1.26167 |  0:00:00s\n",
      "epoch 3  | loss: 0.93328 | val_0_mse: 1.05691 |  0:00:00s\n",
      "epoch 4  | loss: 0.84734 | val_0_mse: 1.10551 |  0:00:01s\n",
      "epoch 5  | loss: 0.70276 | val_0_mse: 1.00913 |  0:00:01s\n",
      "epoch 6  | loss: 0.63322 | val_0_mse: 0.84602 |  0:00:01s\n",
      "epoch 7  | loss: 0.60418 | val_0_mse: 1.00912 |  0:00:01s\n",
      "epoch 8  | loss: 0.5519  | val_0_mse: 0.87838 |  0:00:01s\n",
      "epoch 9  | loss: 0.56394 | val_0_mse: 1.07019 |  0:00:02s\n",
      "epoch 10 | loss: 0.5494  | val_0_mse: 0.8693  |  0:00:02s\n",
      "epoch 11 | loss: 0.54599 | val_0_mse: 0.94788 |  0:00:02s\n",
      "epoch 12 | loss: 0.53416 | val_0_mse: 0.89779 |  0:00:02s\n",
      "epoch 13 | loss: 0.55945 | val_0_mse: 0.99437 |  0:00:02s\n",
      "epoch 14 | loss: 0.54802 | val_0_mse: 0.87281 |  0:00:03s\n",
      "epoch 15 | loss: 0.59998 | val_0_mse: 0.9815  |  0:00:03s\n",
      "epoch 16 | loss: 0.66724 | val_0_mse: 0.87545 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_mse = 0.84602\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7135... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.74597</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">rural-sweep-65</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/uqix3lgx\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/uqix3lgx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050247-uqix3lgx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bfthufgh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.07118820236451769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/bfthufgh\" target=\"_blank\">lemon-sweep-66</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.69944 | val_0_mse: 3.71494 |  0:00:00s\n",
      "epoch 1  | loss: 1.53686 | val_0_mse: 1.69641 |  0:00:00s\n",
      "epoch 2  | loss: 1.16758 | val_0_mse: 1.49759 |  0:00:00s\n",
      "epoch 3  | loss: 1.06011 | val_0_mse: 1.50084 |  0:00:00s\n",
      "epoch 4  | loss: 0.81992 | val_0_mse: 1.21287 |  0:00:00s\n",
      "epoch 5  | loss: 0.76368 | val_0_mse: 0.89626 |  0:00:01s\n",
      "epoch 6  | loss: 0.69231 | val_0_mse: 0.99144 |  0:00:01s\n",
      "epoch 7  | loss: 0.63977 | val_0_mse: 0.79959 |  0:00:01s\n",
      "epoch 8  | loss: 0.62689 | val_0_mse: 0.82907 |  0:00:01s\n",
      "epoch 9  | loss: 0.65692 | val_0_mse: 0.82547 |  0:00:01s\n",
      "epoch 10 | loss: 0.58129 | val_0_mse: 0.8157  |  0:00:02s\n",
      "epoch 11 | loss: 0.56778 | val_0_mse: 0.87982 |  0:00:02s\n",
      "epoch 12 | loss: 0.62051 | val_0_mse: 0.8863  |  0:00:02s\n",
      "epoch 13 | loss: 0.58961 | val_0_mse: 0.82952 |  0:00:02s\n",
      "epoch 14 | loss: 0.5653  | val_0_mse: 0.77974 |  0:00:02s\n",
      "epoch 15 | loss: 0.59648 | val_0_mse: 0.91987 |  0:00:03s\n",
      "epoch 16 | loss: 0.56379 | val_0_mse: 0.886   |  0:00:03s\n",
      "epoch 17 | loss: 0.56579 | val_0_mse: 0.79962 |  0:00:03s\n",
      "epoch 18 | loss: 0.5669  | val_0_mse: 0.73126 |  0:00:03s\n",
      "epoch 19 | loss: 0.56705 | val_0_mse: 1.07327 |  0:00:03s\n",
      "epoch 20 | loss: 0.67546 | val_0_mse: 0.71282 |  0:00:04s\n",
      "epoch 21 | loss: 0.84265 | val_0_mse: 0.70097 |  0:00:04s\n",
      "epoch 22 | loss: 0.61503 | val_0_mse: 0.89097 |  0:00:04s\n",
      "epoch 23 | loss: 0.54876 | val_0_mse: 0.70904 |  0:00:04s\n",
      "epoch 24 | loss: 0.53801 | val_0_mse: 0.69995 |  0:00:04s\n",
      "epoch 25 | loss: 0.53462 | val_0_mse: 0.7239  |  0:00:05s\n",
      "epoch 26 | loss: 0.5229  | val_0_mse: 0.71605 |  0:00:05s\n",
      "epoch 27 | loss: 0.52488 | val_0_mse: 0.66477 |  0:00:05s\n",
      "epoch 28 | loss: 0.54307 | val_0_mse: 0.68864 |  0:00:05s\n",
      "epoch 29 | loss: 0.5211  | val_0_mse: 0.66569 |  0:00:05s\n",
      "epoch 30 | loss: 0.5154  | val_0_mse: 0.70169 |  0:00:06s\n",
      "epoch 31 | loss: 0.53696 | val_0_mse: 0.6456  |  0:00:06s\n",
      "epoch 32 | loss: 0.54354 | val_0_mse: 0.72766 |  0:00:06s\n",
      "epoch 33 | loss: 0.53543 | val_0_mse: 0.65867 |  0:00:06s\n",
      "epoch 34 | loss: 0.64605 | val_0_mse: 0.71049 |  0:00:06s\n",
      "epoch 35 | loss: 0.68174 | val_0_mse: 0.70291 |  0:00:07s\n",
      "epoch 36 | loss: 0.58404 | val_0_mse: 0.65413 |  0:00:07s\n",
      "epoch 37 | loss: 0.54717 | val_0_mse: 0.62757 |  0:00:07s\n",
      "epoch 38 | loss: 0.52051 | val_0_mse: 0.64222 |  0:00:07s\n",
      "epoch 39 | loss: 0.51253 | val_0_mse: 0.60034 |  0:00:07s\n",
      "epoch 40 | loss: 0.59638 | val_0_mse: 0.66495 |  0:00:08s\n",
      "epoch 41 | loss: 0.58275 | val_0_mse: 0.63179 |  0:00:08s\n",
      "epoch 42 | loss: 0.52023 | val_0_mse: 0.62775 |  0:00:08s\n",
      "epoch 43 | loss: 0.5093  | val_0_mse: 0.59949 |  0:00:08s\n",
      "epoch 44 | loss: 0.50233 | val_0_mse: 0.62459 |  0:00:09s\n",
      "epoch 45 | loss: 0.53072 | val_0_mse: 0.57275 |  0:00:09s\n",
      "epoch 46 | loss: 0.50562 | val_0_mse: 0.58636 |  0:00:09s\n",
      "epoch 47 | loss: 0.52121 | val_0_mse: 0.58057 |  0:00:09s\n",
      "epoch 48 | loss: 0.51564 | val_0_mse: 0.56104 |  0:00:09s\n",
      "epoch 49 | loss: 0.50452 | val_0_mse: 0.56721 |  0:00:10s\n",
      "epoch 50 | loss: 0.51382 | val_0_mse: 0.57805 |  0:00:10s\n",
      "epoch 51 | loss: 0.5033  | val_0_mse: 0.55126 |  0:00:10s\n",
      "epoch 52 | loss: 0.50319 | val_0_mse: 0.55442 |  0:00:10s\n",
      "epoch 53 | loss: 0.50637 | val_0_mse: 0.59858 |  0:00:10s\n",
      "epoch 54 | loss: 0.5045  | val_0_mse: 0.55947 |  0:00:11s\n",
      "epoch 55 | loss: 0.50112 | val_0_mse: 0.57237 |  0:00:11s\n",
      "epoch 56 | loss: 0.50885 | val_0_mse: 0.56441 |  0:00:11s\n",
      "epoch 57 | loss: 0.50097 | val_0_mse: 0.56932 |  0:00:11s\n",
      "epoch 58 | loss: 0.50585 | val_0_mse: 0.58049 |  0:00:11s\n",
      "epoch 59 | loss: 0.50489 | val_0_mse: 0.55342 |  0:00:12s\n",
      "epoch 60 | loss: 0.50874 | val_0_mse: 0.56918 |  0:00:12s\n",
      "epoch 61 | loss: 0.50387 | val_0_mse: 0.55404 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 0.55126\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7179... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77368</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">lemon-sweep-66</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/bfthufgh\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/bfthufgh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050257-bfthufgh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 30yxwokj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.3300867414749907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/30yxwokj\" target=\"_blank\">silver-sweep-67</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.27539 | val_0_mse: 1.45624 |  0:00:00s\n",
      "epoch 1  | loss: 1.38936 | val_0_mse: 1.07974 |  0:00:00s\n",
      "epoch 2  | loss: 0.76101 | val_0_mse: 0.97887 |  0:00:00s\n",
      "epoch 3  | loss: 0.63718 | val_0_mse: 1.04331 |  0:00:00s\n",
      "epoch 4  | loss: 0.5906  | val_0_mse: 1.00311 |  0:00:00s\n",
      "epoch 5  | loss: 0.57969 | val_0_mse: 0.9548  |  0:00:00s\n",
      "epoch 6  | loss: 0.58047 | val_0_mse: 1.06527 |  0:00:00s\n",
      "epoch 7  | loss: 0.58306 | val_0_mse: 0.98886 |  0:00:00s\n",
      "epoch 8  | loss: 0.59589 | val_0_mse: 1.09564 |  0:00:01s\n",
      "epoch 9  | loss: 0.5701  | val_0_mse: 0.80839 |  0:00:01s\n",
      "epoch 10 | loss: 0.55536 | val_0_mse: 1.17974 |  0:00:01s\n",
      "epoch 11 | loss: 0.56326 | val_0_mse: 0.85075 |  0:00:01s\n",
      "epoch 12 | loss: 0.52424 | val_0_mse: 0.90496 |  0:00:01s\n",
      "epoch 13 | loss: 0.5281  | val_0_mse: 0.85094 |  0:00:01s\n",
      "epoch 14 | loss: 0.52322 | val_0_mse: 0.88274 |  0:00:01s\n",
      "epoch 15 | loss: 0.50906 | val_0_mse: 0.85993 |  0:00:01s\n",
      "epoch 16 | loss: 0.51683 | val_0_mse: 0.75773 |  0:00:02s\n",
      "epoch 17 | loss: 0.51137 | val_0_mse: 0.89765 |  0:00:02s\n",
      "epoch 18 | loss: 0.50219 | val_0_mse: 0.80547 |  0:00:02s\n",
      "epoch 19 | loss: 0.50463 | val_0_mse: 0.85254 |  0:00:02s\n",
      "epoch 20 | loss: 0.50726 | val_0_mse: 0.90993 |  0:00:02s\n",
      "epoch 21 | loss: 0.48978 | val_0_mse: 0.89888 |  0:00:02s\n",
      "epoch 22 | loss: 0.48896 | val_0_mse: 0.73718 |  0:00:02s\n",
      "epoch 23 | loss: 0.50115 | val_0_mse: 0.77727 |  0:00:02s\n",
      "epoch 24 | loss: 0.49643 | val_0_mse: 0.84425 |  0:00:03s\n",
      "epoch 25 | loss: 0.51635 | val_0_mse: 0.72344 |  0:00:03s\n",
      "epoch 26 | loss: 0.48837 | val_0_mse: 0.82497 |  0:00:03s\n",
      "epoch 27 | loss: 0.48857 | val_0_mse: 0.73495 |  0:00:03s\n",
      "epoch 28 | loss: 0.49936 | val_0_mse: 0.82762 |  0:00:03s\n",
      "epoch 29 | loss: 0.48676 | val_0_mse: 0.70113 |  0:00:03s\n",
      "epoch 30 | loss: 0.48644 | val_0_mse: 0.87034 |  0:00:03s\n",
      "epoch 31 | loss: 0.48138 | val_0_mse: 0.74497 |  0:00:03s\n",
      "epoch 32 | loss: 0.48915 | val_0_mse: 0.81462 |  0:00:03s\n",
      "epoch 33 | loss: 0.48905 | val_0_mse: 0.65342 |  0:00:04s\n",
      "epoch 34 | loss: 0.47772 | val_0_mse: 0.73978 |  0:00:04s\n",
      "epoch 35 | loss: 0.48015 | val_0_mse: 0.66965 |  0:00:04s\n",
      "epoch 36 | loss: 0.46834 | val_0_mse: 0.67111 |  0:00:04s\n",
      "epoch 37 | loss: 0.47223 | val_0_mse: 0.70451 |  0:00:04s\n",
      "epoch 38 | loss: 0.47742 | val_0_mse: 0.68337 |  0:00:04s\n",
      "epoch 39 | loss: 0.47761 | val_0_mse: 0.62304 |  0:00:04s\n",
      "epoch 40 | loss: 0.46989 | val_0_mse: 0.68308 |  0:00:04s\n",
      "epoch 41 | loss: 0.47357 | val_0_mse: 0.64697 |  0:00:05s\n",
      "epoch 42 | loss: 0.48626 | val_0_mse: 0.61555 |  0:00:05s\n",
      "epoch 43 | loss: 0.48765 | val_0_mse: 0.65001 |  0:00:05s\n",
      "epoch 44 | loss: 0.48648 | val_0_mse: 0.62063 |  0:00:05s\n",
      "epoch 45 | loss: 0.47761 | val_0_mse: 0.60468 |  0:00:05s\n",
      "epoch 46 | loss: 0.48316 | val_0_mse: 0.57439 |  0:00:05s\n",
      "epoch 47 | loss: 0.4784  | val_0_mse: 0.59509 |  0:00:05s\n",
      "epoch 48 | loss: 0.47263 | val_0_mse: 0.59342 |  0:00:05s\n",
      "epoch 49 | loss: 0.484   | val_0_mse: 0.59875 |  0:00:06s\n",
      "epoch 50 | loss: 0.50173 | val_0_mse: 0.62293 |  0:00:06s\n",
      "epoch 51 | loss: 0.51342 | val_0_mse: 0.55531 |  0:00:06s\n",
      "epoch 52 | loss: 0.52273 | val_0_mse: 0.6779  |  0:00:06s\n",
      "epoch 53 | loss: 0.57007 | val_0_mse: 0.54421 |  0:00:06s\n",
      "epoch 54 | loss: 0.51718 | val_0_mse: 0.56405 |  0:00:06s\n",
      "epoch 55 | loss: 0.49203 | val_0_mse: 0.59841 |  0:00:06s\n",
      "epoch 56 | loss: 0.47593 | val_0_mse: 0.54667 |  0:00:07s\n",
      "epoch 57 | loss: 0.48107 | val_0_mse: 0.54907 |  0:00:07s\n",
      "epoch 58 | loss: 0.47557 | val_0_mse: 0.5237  |  0:00:07s\n",
      "epoch 59 | loss: 0.47834 | val_0_mse: 0.58551 |  0:00:07s\n",
      "epoch 60 | loss: 0.50003 | val_0_mse: 0.54616 |  0:00:07s\n",
      "epoch 61 | loss: 0.53787 | val_0_mse: 0.53734 |  0:00:07s\n",
      "epoch 62 | loss: 0.50332 | val_0_mse: 0.57895 |  0:00:07s\n",
      "epoch 63 | loss: 0.492   | val_0_mse: 0.557   |  0:00:07s\n",
      "epoch 64 | loss: 0.4881  | val_0_mse: 0.51907 |  0:00:08s\n",
      "epoch 65 | loss: 0.47181 | val_0_mse: 0.53006 |  0:00:08s\n",
      "epoch 66 | loss: 0.47303 | val_0_mse: 0.58928 |  0:00:08s\n",
      "epoch 67 | loss: 0.48597 | val_0_mse: 0.55301 |  0:00:08s\n",
      "epoch 68 | loss: 0.48266 | val_0_mse: 0.54611 |  0:00:08s\n",
      "epoch 69 | loss: 0.48703 | val_0_mse: 0.53134 |  0:00:08s\n",
      "epoch 70 | loss: 0.46965 | val_0_mse: 0.53152 |  0:00:08s\n",
      "epoch 71 | loss: 0.48316 | val_0_mse: 0.54052 |  0:00:08s\n",
      "epoch 72 | loss: 0.4791  | val_0_mse: 0.54876 |  0:00:09s\n",
      "epoch 73 | loss: 0.47461 | val_0_mse: 0.49716 |  0:00:09s\n",
      "epoch 74 | loss: 0.4773  | val_0_mse: 0.50822 |  0:00:09s\n",
      "epoch 75 | loss: 0.45768 | val_0_mse: 0.50628 |  0:00:09s\n",
      "epoch 76 | loss: 0.46707 | val_0_mse: 0.51414 |  0:00:09s\n",
      "epoch 77 | loss: 0.46588 | val_0_mse: 0.52805 |  0:00:09s\n",
      "epoch 78 | loss: 0.48131 | val_0_mse: 0.50276 |  0:00:09s\n",
      "epoch 79 | loss: 0.47316 | val_0_mse: 0.50956 |  0:00:09s\n",
      "epoch 80 | loss: 0.47883 | val_0_mse: 0.50757 |  0:00:10s\n",
      "epoch 81 | loss: 0.4791  | val_0_mse: 0.53701 |  0:00:10s\n",
      "epoch 82 | loss: 0.48312 | val_0_mse: 0.53664 |  0:00:10s\n",
      "epoch 83 | loss: 0.48732 | val_0_mse: 0.52529 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 0.49716\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7223... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.79088</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">silver-sweep-67</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/30yxwokj\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/30yxwokj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050315-30yxwokj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 04t6eu1r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.18988408161534287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/04t6eu1r\" target=\"_blank\">zesty-sweep-68</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.8409  | val_0_mse: 2.46665 |  0:00:00s\n",
      "epoch 1  | loss: 1.44773 | val_0_mse: 1.56447 |  0:00:00s\n",
      "epoch 2  | loss: 0.9971  | val_0_mse: 1.30819 |  0:00:00s\n",
      "epoch 3  | loss: 0.80319 | val_0_mse: 1.34476 |  0:00:00s\n",
      "epoch 4  | loss: 0.75113 | val_0_mse: 1.23763 |  0:00:00s\n",
      "epoch 5  | loss: 0.9338  | val_0_mse: 1.08215 |  0:00:01s\n",
      "epoch 6  | loss: 0.83986 | val_0_mse: 1.26367 |  0:00:01s\n",
      "epoch 7  | loss: 0.74153 | val_0_mse: 0.90475 |  0:00:01s\n",
      "epoch 8  | loss: 0.7882  | val_0_mse: 1.06366 |  0:00:01s\n",
      "epoch 9  | loss: 0.76096 | val_0_mse: 0.88181 |  0:00:01s\n",
      "epoch 10 | loss: 0.76475 | val_0_mse: 0.99753 |  0:00:02s\n",
      "epoch 11 | loss: 0.70804 | val_0_mse: 0.80205 |  0:00:02s\n",
      "epoch 12 | loss: 0.70485 | val_0_mse: 1.02558 |  0:00:02s\n",
      "epoch 13 | loss: 0.66375 | val_0_mse: 0.78733 |  0:00:02s\n",
      "epoch 14 | loss: 0.80072 | val_0_mse: 0.83632 |  0:00:02s\n",
      "epoch 15 | loss: 0.8657  | val_0_mse: 0.88901 |  0:00:03s\n",
      "epoch 16 | loss: 0.63935 | val_0_mse: 0.76043 |  0:00:03s\n",
      "epoch 17 | loss: 0.57039 | val_0_mse: 0.77773 |  0:00:03s\n",
      "epoch 18 | loss: 0.59873 | val_0_mse: 0.88822 |  0:00:03s\n",
      "epoch 19 | loss: 0.55344 | val_0_mse: 0.72515 |  0:00:03s\n",
      "epoch 20 | loss: 0.53727 | val_0_mse: 0.88223 |  0:00:04s\n",
      "epoch 21 | loss: 0.62877 | val_0_mse: 0.7757  |  0:00:04s\n",
      "epoch 22 | loss: 0.6117  | val_0_mse: 0.77617 |  0:00:04s\n",
      "epoch 23 | loss: 0.57099 | val_0_mse: 0.68742 |  0:00:04s\n",
      "epoch 24 | loss: 0.54784 | val_0_mse: 0.79555 |  0:00:04s\n",
      "epoch 25 | loss: 0.59733 | val_0_mse: 0.65527 |  0:00:05s\n",
      "epoch 26 | loss: 0.58299 | val_0_mse: 0.77771 |  0:00:05s\n",
      "epoch 27 | loss: 0.55348 | val_0_mse: 0.69741 |  0:00:05s\n",
      "epoch 28 | loss: 0.5225  | val_0_mse: 0.68203 |  0:00:05s\n",
      "epoch 29 | loss: 0.52765 | val_0_mse: 0.73907 |  0:00:05s\n",
      "epoch 30 | loss: 0.5211  | val_0_mse: 0.6891  |  0:00:06s\n",
      "epoch 31 | loss: 0.51811 | val_0_mse: 0.68359 |  0:00:06s\n",
      "epoch 32 | loss: 0.51802 | val_0_mse: 0.72012 |  0:00:06s\n",
      "epoch 33 | loss: 0.51405 | val_0_mse: 0.69183 |  0:00:06s\n",
      "epoch 34 | loss: 0.51654 | val_0_mse: 0.69008 |  0:00:06s\n",
      "epoch 35 | loss: 0.50627 | val_0_mse: 0.64601 |  0:00:07s\n",
      "epoch 36 | loss: 0.51352 | val_0_mse: 0.68771 |  0:00:07s\n",
      "epoch 37 | loss: 0.51978 | val_0_mse: 0.72045 |  0:00:07s\n",
      "epoch 38 | loss: 0.51336 | val_0_mse: 0.65429 |  0:00:07s\n",
      "epoch 39 | loss: 0.61621 | val_0_mse: 0.71495 |  0:00:07s\n",
      "epoch 40 | loss: 0.54648 | val_0_mse: 0.63331 |  0:00:08s\n",
      "epoch 41 | loss: 0.69739 | val_0_mse: 0.63784 |  0:00:08s\n",
      "epoch 42 | loss: 0.55473 | val_0_mse: 0.7033  |  0:00:08s\n",
      "epoch 43 | loss: 0.52228 | val_0_mse: 0.67008 |  0:00:08s\n",
      "epoch 44 | loss: 0.49993 | val_0_mse: 0.59008 |  0:00:08s\n",
      "epoch 45 | loss: 0.52498 | val_0_mse: 0.61169 |  0:00:09s\n",
      "epoch 46 | loss: 0.50045 | val_0_mse: 0.57258 |  0:00:09s\n",
      "epoch 47 | loss: 0.49238 | val_0_mse: 0.57761 |  0:00:09s\n",
      "epoch 48 | loss: 0.48923 | val_0_mse: 0.56623 |  0:00:09s\n",
      "epoch 49 | loss: 0.49651 | val_0_mse: 0.57588 |  0:00:10s\n",
      "epoch 50 | loss: 0.50089 | val_0_mse: 0.59227 |  0:00:10s\n",
      "epoch 51 | loss: 0.49574 | val_0_mse: 0.59267 |  0:00:10s\n",
      "epoch 52 | loss: 0.4964  | val_0_mse: 0.57981 |  0:00:10s\n",
      "epoch 53 | loss: 0.49843 | val_0_mse: 0.59189 |  0:00:10s\n",
      "epoch 54 | loss: 0.4973  | val_0_mse: 0.59387 |  0:00:11s\n",
      "epoch 55 | loss: 0.49951 | val_0_mse: 0.58152 |  0:00:11s\n",
      "epoch 56 | loss: 0.49794 | val_0_mse: 0.5698  |  0:00:11s\n",
      "epoch 57 | loss: 0.52667 | val_0_mse: 0.70053 |  0:00:11s\n",
      "epoch 58 | loss: 0.57901 | val_0_mse: 0.59839 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 0.56623\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7269... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76597</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">zesty-sweep-68</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/04t6eu1r\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/04t6eu1r</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050331-04t6eu1r/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: krk2hqp2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.3636958218554413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/krk2hqp2\" target=\"_blank\">neat-sweep-69</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 7.43931 | val_0_mse: 2.8407  |  0:00:00s\n",
      "epoch 1  | loss: 1.82067 | val_0_mse: 1.60316 |  0:00:00s\n",
      "epoch 2  | loss: 0.98213 | val_0_mse: 1.26323 |  0:00:00s\n",
      "epoch 3  | loss: 0.77273 | val_0_mse: 0.97851 |  0:00:00s\n",
      "epoch 4  | loss: 0.68355 | val_0_mse: 0.86812 |  0:00:00s\n",
      "epoch 5  | loss: 0.63511 | val_0_mse: 1.00639 |  0:00:00s\n",
      "epoch 6  | loss: 0.60383 | val_0_mse: 0.971   |  0:00:00s\n",
      "epoch 7  | loss: 0.58747 | val_0_mse: 0.86854 |  0:00:00s\n",
      "epoch 8  | loss: 0.56706 | val_0_mse: 1.06435 |  0:00:01s\n",
      "epoch 9  | loss: 0.5515  | val_0_mse: 0.89147 |  0:00:01s\n",
      "epoch 10 | loss: 0.54437 | val_0_mse: 0.87035 |  0:00:01s\n",
      "epoch 11 | loss: 0.54251 | val_0_mse: 0.91825 |  0:00:01s\n",
      "epoch 12 | loss: 0.53022 | val_0_mse: 0.82374 |  0:00:01s\n",
      "epoch 13 | loss: 0.52606 | val_0_mse: 0.96097 |  0:00:01s\n",
      "epoch 14 | loss: 0.53028 | val_0_mse: 0.87652 |  0:00:01s\n",
      "epoch 15 | loss: 0.52392 | val_0_mse: 0.90398 |  0:00:01s\n",
      "epoch 16 | loss: 0.5351  | val_0_mse: 0.84692 |  0:00:02s\n",
      "epoch 17 | loss: 0.51121 | val_0_mse: 0.9258  |  0:00:02s\n",
      "epoch 18 | loss: 0.51145 | val_0_mse: 0.80113 |  0:00:02s\n",
      "epoch 19 | loss: 0.59661 | val_0_mse: 0.87267 |  0:00:02s\n",
      "epoch 20 | loss: 0.52044 | val_0_mse: 0.87269 |  0:00:02s\n",
      "epoch 21 | loss: 0.50145 | val_0_mse: 0.93257 |  0:00:02s\n",
      "epoch 22 | loss: 0.51355 | val_0_mse: 0.81102 |  0:00:02s\n",
      "epoch 23 | loss: 0.51377 | val_0_mse: 0.97005 |  0:00:02s\n",
      "epoch 24 | loss: 0.50302 | val_0_mse: 0.80612 |  0:00:02s\n",
      "epoch 25 | loss: 0.49341 | val_0_mse: 0.86868 |  0:00:03s\n",
      "epoch 26 | loss: 0.50815 | val_0_mse: 0.74359 |  0:00:03s\n",
      "epoch 27 | loss: 0.52566 | val_0_mse: 0.79722 |  0:00:03s\n",
      "epoch 28 | loss: 0.5155  | val_0_mse: 0.76452 |  0:00:03s\n",
      "epoch 29 | loss: 0.50827 | val_0_mse: 0.74235 |  0:00:03s\n",
      "epoch 30 | loss: 0.50225 | val_0_mse: 0.69641 |  0:00:03s\n",
      "epoch 31 | loss: 0.5115  | val_0_mse: 0.66291 |  0:00:03s\n",
      "epoch 32 | loss: 0.48619 | val_0_mse: 0.74213 |  0:00:03s\n",
      "epoch 33 | loss: 0.48819 | val_0_mse: 0.69148 |  0:00:04s\n",
      "epoch 34 | loss: 0.48678 | val_0_mse: 0.6585  |  0:00:04s\n",
      "epoch 35 | loss: 0.49652 | val_0_mse: 0.644   |  0:00:04s\n",
      "epoch 36 | loss: 0.49248 | val_0_mse: 0.62113 |  0:00:04s\n",
      "epoch 37 | loss: 0.50052 | val_0_mse: 0.66008 |  0:00:04s\n",
      "epoch 38 | loss: 0.48282 | val_0_mse: 0.62623 |  0:00:04s\n",
      "epoch 39 | loss: 0.49485 | val_0_mse: 0.66317 |  0:00:04s\n",
      "epoch 40 | loss: 0.49359 | val_0_mse: 0.655   |  0:00:04s\n",
      "epoch 41 | loss: 0.50447 | val_0_mse: 0.59033 |  0:00:05s\n",
      "epoch 42 | loss: 0.50136 | val_0_mse: 0.71714 |  0:00:05s\n",
      "epoch 43 | loss: 0.55547 | val_0_mse: 0.5916  |  0:00:05s\n",
      "epoch 44 | loss: 0.52824 | val_0_mse: 0.65264 |  0:00:05s\n",
      "epoch 45 | loss: 0.48871 | val_0_mse: 0.62678 |  0:00:05s\n",
      "epoch 46 | loss: 0.48177 | val_0_mse: 0.59924 |  0:00:05s\n",
      "epoch 47 | loss: 0.48011 | val_0_mse: 0.65153 |  0:00:05s\n",
      "epoch 48 | loss: 0.47694 | val_0_mse: 0.58993 |  0:00:05s\n",
      "epoch 49 | loss: 0.48978 | val_0_mse: 0.62205 |  0:00:06s\n",
      "epoch 50 | loss: 0.48862 | val_0_mse: 0.5533  |  0:00:06s\n",
      "epoch 51 | loss: 0.49309 | val_0_mse: 0.67584 |  0:00:06s\n",
      "epoch 52 | loss: 0.52862 | val_0_mse: 0.56918 |  0:00:06s\n",
      "epoch 53 | loss: 0.52081 | val_0_mse: 0.58961 |  0:00:06s\n",
      "epoch 54 | loss: 0.50386 | val_0_mse: 0.59261 |  0:00:06s\n",
      "epoch 55 | loss: 0.51103 | val_0_mse: 0.62154 |  0:00:06s\n",
      "epoch 56 | loss: 0.50076 | val_0_mse: 0.5714  |  0:00:06s\n",
      "epoch 57 | loss: 0.5041  | val_0_mse: 0.59235 |  0:00:07s\n",
      "epoch 58 | loss: 0.49525 | val_0_mse: 0.57323 |  0:00:07s\n",
      "epoch 59 | loss: 0.4877  | val_0_mse: 0.58754 |  0:00:07s\n",
      "epoch 60 | loss: 0.48955 | val_0_mse: 0.54705 |  0:00:07s\n",
      "epoch 61 | loss: 0.48909 | val_0_mse: 0.55203 |  0:00:07s\n",
      "epoch 62 | loss: 0.4803  | val_0_mse: 0.53499 |  0:00:07s\n",
      "epoch 63 | loss: 0.48655 | val_0_mse: 0.55106 |  0:00:07s\n",
      "epoch 64 | loss: 0.49101 | val_0_mse: 0.56384 |  0:00:07s\n",
      "epoch 65 | loss: 0.47724 | val_0_mse: 0.53266 |  0:00:07s\n",
      "epoch 66 | loss: 0.48917 | val_0_mse: 0.56822 |  0:00:08s\n",
      "epoch 67 | loss: 0.50006 | val_0_mse: 0.5223  |  0:00:08s\n",
      "epoch 68 | loss: 0.50462 | val_0_mse: 0.55718 |  0:00:08s\n",
      "epoch 69 | loss: 0.50073 | val_0_mse: 0.54199 |  0:00:08s\n",
      "epoch 70 | loss: 0.48806 | val_0_mse: 0.54237 |  0:00:08s\n",
      "epoch 71 | loss: 0.51368 | val_0_mse: 0.52561 |  0:00:08s\n",
      "epoch 72 | loss: 0.53612 | val_0_mse: 0.55203 |  0:00:08s\n",
      "epoch 73 | loss: 0.51036 | val_0_mse: 0.53339 |  0:00:08s\n",
      "epoch 74 | loss: 0.50339 | val_0_mse: 0.56074 |  0:00:09s\n",
      "epoch 75 | loss: 0.48567 | val_0_mse: 0.54122 |  0:00:09s\n",
      "epoch 76 | loss: 0.48857 | val_0_mse: 0.53071 |  0:00:09s\n",
      "epoch 77 | loss: 0.49735 | val_0_mse: 0.5376  |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_mse = 0.5223\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7315... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78142</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">neat-sweep-69</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/krk2hqp2\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/krk2hqp2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050350-krk2hqp2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z56i4t7e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.17096689047790478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/z56i4t7e\" target=\"_blank\">smart-sweep-70</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.69944 | val_0_mse: 3.2733  |  0:00:00s\n",
      "epoch 1  | loss: 1.53686 | val_0_mse: 1.56802 |  0:00:00s\n",
      "epoch 2  | loss: 1.16758 | val_0_mse: 1.4557  |  0:00:00s\n",
      "epoch 3  | loss: 1.06011 | val_0_mse: 1.51977 |  0:00:00s\n",
      "epoch 4  | loss: 0.81992 | val_0_mse: 1.14466 |  0:00:00s\n",
      "epoch 5  | loss: 0.76368 | val_0_mse: 0.8819  |  0:00:01s\n",
      "epoch 6  | loss: 0.69231 | val_0_mse: 0.97256 |  0:00:01s\n",
      "epoch 7  | loss: 0.63977 | val_0_mse: 0.77946 |  0:00:01s\n",
      "epoch 8  | loss: 0.62689 | val_0_mse: 0.82551 |  0:00:01s\n",
      "epoch 9  | loss: 0.65692 | val_0_mse: 0.81191 |  0:00:01s\n",
      "epoch 10 | loss: 0.58129 | val_0_mse: 0.80731 |  0:00:02s\n",
      "epoch 11 | loss: 0.56778 | val_0_mse: 0.87766 |  0:00:02s\n",
      "epoch 12 | loss: 0.62051 | val_0_mse: 0.88417 |  0:00:02s\n",
      "epoch 13 | loss: 0.58961 | val_0_mse: 0.81742 |  0:00:02s\n",
      "epoch 14 | loss: 0.5653  | val_0_mse: 0.77692 |  0:00:03s\n",
      "epoch 15 | loss: 0.59648 | val_0_mse: 0.89601 |  0:00:03s\n",
      "epoch 16 | loss: 0.56379 | val_0_mse: 0.87921 |  0:00:03s\n",
      "epoch 17 | loss: 0.56579 | val_0_mse: 0.7937  |  0:00:03s\n",
      "epoch 18 | loss: 0.5669  | val_0_mse: 0.74019 |  0:00:03s\n",
      "epoch 19 | loss: 0.56705 | val_0_mse: 1.06619 |  0:00:04s\n",
      "epoch 20 | loss: 0.67546 | val_0_mse: 0.71497 |  0:00:04s\n",
      "epoch 21 | loss: 0.84265 | val_0_mse: 0.68626 |  0:00:04s\n",
      "epoch 22 | loss: 0.61503 | val_0_mse: 0.88779 |  0:00:04s\n",
      "epoch 23 | loss: 0.54876 | val_0_mse: 0.71161 |  0:00:04s\n",
      "epoch 24 | loss: 0.53801 | val_0_mse: 0.69965 |  0:00:05s\n",
      "epoch 25 | loss: 0.53462 | val_0_mse: 0.74799 |  0:00:05s\n",
      "epoch 26 | loss: 0.5229  | val_0_mse: 0.71734 |  0:00:05s\n",
      "epoch 27 | loss: 0.52488 | val_0_mse: 0.67818 |  0:00:05s\n",
      "epoch 28 | loss: 0.54307 | val_0_mse: 0.68761 |  0:00:05s\n",
      "epoch 29 | loss: 0.5211  | val_0_mse: 0.67183 |  0:00:06s\n",
      "epoch 30 | loss: 0.5154  | val_0_mse: 0.6899  |  0:00:06s\n",
      "epoch 31 | loss: 0.53696 | val_0_mse: 0.65478 |  0:00:06s\n",
      "epoch 32 | loss: 0.54354 | val_0_mse: 0.73911 |  0:00:06s\n",
      "epoch 33 | loss: 0.53543 | val_0_mse: 0.67835 |  0:00:06s\n",
      "epoch 34 | loss: 0.64605 | val_0_mse: 0.70905 |  0:00:07s\n",
      "epoch 35 | loss: 0.68174 | val_0_mse: 0.70565 |  0:00:07s\n",
      "epoch 36 | loss: 0.58404 | val_0_mse: 0.65427 |  0:00:07s\n",
      "epoch 37 | loss: 0.54717 | val_0_mse: 0.61606 |  0:00:07s\n",
      "epoch 38 | loss: 0.52051 | val_0_mse: 0.64283 |  0:00:07s\n",
      "epoch 39 | loss: 0.51253 | val_0_mse: 0.60497 |  0:00:08s\n",
      "epoch 40 | loss: 0.59638 | val_0_mse: 0.67212 |  0:00:08s\n",
      "epoch 41 | loss: 0.58275 | val_0_mse: 0.6471  |  0:00:08s\n",
      "epoch 42 | loss: 0.52023 | val_0_mse: 0.62633 |  0:00:08s\n",
      "epoch 43 | loss: 0.5093  | val_0_mse: 0.59924 |  0:00:08s\n",
      "epoch 44 | loss: 0.50233 | val_0_mse: 0.6219  |  0:00:09s\n",
      "epoch 45 | loss: 0.53072 | val_0_mse: 0.57242 |  0:00:09s\n",
      "epoch 46 | loss: 0.50562 | val_0_mse: 0.59114 |  0:00:09s\n",
      "epoch 47 | loss: 0.52121 | val_0_mse: 0.58174 |  0:00:09s\n",
      "epoch 48 | loss: 0.51564 | val_0_mse: 0.56402 |  0:00:10s\n",
      "epoch 49 | loss: 0.50452 | val_0_mse: 0.57019 |  0:00:10s\n",
      "epoch 50 | loss: 0.51382 | val_0_mse: 0.56915 |  0:00:10s\n",
      "epoch 51 | loss: 0.5033  | val_0_mse: 0.55193 |  0:00:10s\n",
      "epoch 52 | loss: 0.50319 | val_0_mse: 0.553   |  0:00:10s\n",
      "epoch 53 | loss: 0.50637 | val_0_mse: 0.61318 |  0:00:11s\n",
      "epoch 54 | loss: 0.5045  | val_0_mse: 0.56494 |  0:00:11s\n",
      "epoch 55 | loss: 0.50112 | val_0_mse: 0.56886 |  0:00:11s\n",
      "epoch 56 | loss: 0.50885 | val_0_mse: 0.57859 |  0:00:11s\n",
      "epoch 57 | loss: 0.50097 | val_0_mse: 0.57138 |  0:00:11s\n",
      "epoch 58 | loss: 0.50585 | val_0_mse: 0.57753 |  0:00:12s\n",
      "epoch 59 | loss: 0.50489 | val_0_mse: 0.54949 |  0:00:12s\n",
      "epoch 60 | loss: 0.50874 | val_0_mse: 0.56924 |  0:00:12s\n",
      "epoch 61 | loss: 0.50387 | val_0_mse: 0.55166 |  0:00:12s\n",
      "epoch 62 | loss: 0.50296 | val_0_mse: 0.61433 |  0:00:12s\n",
      "epoch 63 | loss: 0.53447 | val_0_mse: 0.59478 |  0:00:13s\n",
      "epoch 64 | loss: 0.59887 | val_0_mse: 0.58799 |  0:00:13s\n",
      "epoch 65 | loss: 0.54563 | val_0_mse: 0.54578 |  0:00:13s\n",
      "epoch 66 | loss: 0.52346 | val_0_mse: 0.58372 |  0:00:13s\n",
      "epoch 67 | loss: 0.56331 | val_0_mse: 0.54545 |  0:00:13s\n",
      "epoch 68 | loss: 0.49745 | val_0_mse: 0.54157 |  0:00:14s\n",
      "epoch 69 | loss: 0.49511 | val_0_mse: 0.54114 |  0:00:14s\n",
      "epoch 70 | loss: 0.49958 | val_0_mse: 0.54168 |  0:00:14s\n",
      "epoch 71 | loss: 0.49604 | val_0_mse: 0.54235 |  0:00:14s\n",
      "epoch 72 | loss: 0.49363 | val_0_mse: 0.52333 |  0:00:14s\n",
      "epoch 73 | loss: 0.4969  | val_0_mse: 0.5622  |  0:00:15s\n",
      "epoch 74 | loss: 0.49904 | val_0_mse: 0.54456 |  0:00:15s\n",
      "epoch 75 | loss: 0.50223 | val_0_mse: 0.53014 |  0:00:15s\n",
      "epoch 76 | loss: 0.49047 | val_0_mse: 0.5571  |  0:00:15s\n",
      "epoch 77 | loss: 0.48839 | val_0_mse: 0.52473 |  0:00:15s\n",
      "epoch 78 | loss: 0.48668 | val_0_mse: 0.528   |  0:00:16s\n",
      "epoch 79 | loss: 0.48658 | val_0_mse: 0.53043 |  0:00:16s\n",
      "epoch 80 | loss: 0.48697 | val_0_mse: 0.51618 |  0:00:16s\n",
      "epoch 81 | loss: 0.48105 | val_0_mse: 0.52906 |  0:00:16s\n",
      "epoch 82 | loss: 0.49148 | val_0_mse: 0.53555 |  0:00:16s\n",
      "epoch 83 | loss: 0.48265 | val_0_mse: 0.55348 |  0:00:17s\n",
      "epoch 84 | loss: 0.50011 | val_0_mse: 0.53114 |  0:00:17s\n",
      "epoch 85 | loss: 0.5376  | val_0_mse: 0.60572 |  0:00:17s\n",
      "epoch 86 | loss: 0.53605 | val_0_mse: 0.53693 |  0:00:17s\n",
      "epoch 87 | loss: 0.52535 | val_0_mse: 0.64745 |  0:00:17s\n",
      "epoch 88 | loss: 0.61577 | val_0_mse: 0.61556 |  0:00:18s\n",
      "epoch 89 | loss: 0.53801 | val_0_mse: 0.55624 |  0:00:18s\n",
      "epoch 90 | loss: 0.51674 | val_0_mse: 0.55286 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 0.51618\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7359... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78165</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">smart-sweep-70</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/z56i4t7e\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/z56i4t7e</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050405-z56i4t7e/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2a548kzf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.36357218374359096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/2a548kzf\" target=\"_blank\">apricot-sweep-71</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 7.72002 | val_0_mse: 2.87478 |  0:00:00s\n",
      "epoch 1  | loss: 1.86091 | val_0_mse: 1.64901 |  0:00:00s\n",
      "epoch 2  | loss: 0.82279 | val_0_mse: 1.20999 |  0:00:00s\n",
      "epoch 3  | loss: 0.69225 | val_0_mse: 0.97514 |  0:00:00s\n",
      "epoch 4  | loss: 0.65725 | val_0_mse: 0.95842 |  0:00:00s\n",
      "epoch 5  | loss: 0.60294 | val_0_mse: 0.98514 |  0:00:00s\n",
      "epoch 6  | loss: 0.556   | val_0_mse: 0.92134 |  0:00:01s\n",
      "epoch 7  | loss: 0.55857 | val_0_mse: 0.94839 |  0:00:01s\n",
      "epoch 8  | loss: 0.54093 | val_0_mse: 0.93575 |  0:00:01s\n",
      "epoch 9  | loss: 0.53758 | val_0_mse: 0.89337 |  0:00:01s\n",
      "epoch 10 | loss: 0.56058 | val_0_mse: 0.95961 |  0:00:01s\n",
      "epoch 11 | loss: 0.55555 | val_0_mse: 0.88956 |  0:00:01s\n",
      "epoch 12 | loss: 0.55478 | val_0_mse: 0.93667 |  0:00:01s\n",
      "epoch 13 | loss: 0.54729 | val_0_mse: 0.87777 |  0:00:01s\n",
      "epoch 14 | loss: 0.51677 | val_0_mse: 0.91636 |  0:00:01s\n",
      "epoch 15 | loss: 0.51372 | val_0_mse: 0.84856 |  0:00:02s\n",
      "epoch 16 | loss: 0.49833 | val_0_mse: 0.88204 |  0:00:02s\n",
      "epoch 17 | loss: 0.51921 | val_0_mse: 0.88122 |  0:00:02s\n",
      "epoch 18 | loss: 0.50816 | val_0_mse: 0.94046 |  0:00:02s\n",
      "epoch 19 | loss: 0.50354 | val_0_mse: 0.71917 |  0:00:02s\n",
      "epoch 20 | loss: 0.52002 | val_0_mse: 0.87575 |  0:00:02s\n",
      "epoch 21 | loss: 0.54198 | val_0_mse: 0.74098 |  0:00:02s\n",
      "epoch 22 | loss: 0.53019 | val_0_mse: 0.90726 |  0:00:02s\n",
      "epoch 23 | loss: 0.51326 | val_0_mse: 0.74038 |  0:00:03s\n",
      "epoch 24 | loss: 0.48934 | val_0_mse: 0.7525  |  0:00:03s\n",
      "epoch 25 | loss: 0.50938 | val_0_mse: 0.73672 |  0:00:03s\n",
      "epoch 26 | loss: 0.50076 | val_0_mse: 0.81364 |  0:00:03s\n",
      "epoch 27 | loss: 0.49423 | val_0_mse: 0.72049 |  0:00:03s\n",
      "epoch 28 | loss: 0.48635 | val_0_mse: 0.74528 |  0:00:03s\n",
      "epoch 29 | loss: 0.48669 | val_0_mse: 0.72234 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.71917\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7408... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76599</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">apricot-sweep-71</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/2a548kzf\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/2a548kzf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050429-2a548kzf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ab3p0aff with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.14646611624734646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ab3p0aff\" target=\"_blank\">breezy-sweep-72</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 5.69944 | val_0_mse: 3.31808 |  0:00:00s\n",
      "epoch 1  | loss: 1.53686 | val_0_mse: 1.57982 |  0:00:00s\n",
      "epoch 2  | loss: 1.16758 | val_0_mse: 1.46069 |  0:00:00s\n",
      "epoch 3  | loss: 1.06011 | val_0_mse: 1.51594 |  0:00:00s\n",
      "epoch 4  | loss: 0.81992 | val_0_mse: 1.15482 |  0:00:01s\n",
      "epoch 5  | loss: 0.76368 | val_0_mse: 0.88271 |  0:00:01s\n",
      "epoch 6  | loss: 0.69231 | val_0_mse: 0.97429 |  0:00:01s\n",
      "epoch 7  | loss: 0.63977 | val_0_mse: 0.78174 |  0:00:01s\n",
      "epoch 8  | loss: 0.62689 | val_0_mse: 0.82628 |  0:00:01s\n",
      "epoch 9  | loss: 0.65692 | val_0_mse: 0.81484 |  0:00:02s\n",
      "epoch 10 | loss: 0.58129 | val_0_mse: 0.80772 |  0:00:02s\n",
      "epoch 11 | loss: 0.56778 | val_0_mse: 0.87682 |  0:00:02s\n",
      "epoch 12 | loss: 0.62051 | val_0_mse: 0.88431 |  0:00:02s\n",
      "epoch 13 | loss: 0.58961 | val_0_mse: 0.81954 |  0:00:02s\n",
      "epoch 14 | loss: 0.5653  | val_0_mse: 0.77696 |  0:00:02s\n",
      "epoch 15 | loss: 0.59648 | val_0_mse: 0.90183 |  0:00:03s\n",
      "epoch 16 | loss: 0.56379 | val_0_mse: 0.87949 |  0:00:03s\n",
      "epoch 17 | loss: 0.56579 | val_0_mse: 0.79449 |  0:00:03s\n",
      "epoch 18 | loss: 0.5669  | val_0_mse: 0.73737 |  0:00:03s\n",
      "epoch 19 | loss: 0.56705 | val_0_mse: 1.06929 |  0:00:03s\n",
      "epoch 20 | loss: 0.67546 | val_0_mse: 0.71419 |  0:00:04s\n",
      "epoch 21 | loss: 0.84265 | val_0_mse: 0.68879 |  0:00:04s\n",
      "epoch 22 | loss: 0.61503 | val_0_mse: 0.8909  |  0:00:04s\n",
      "epoch 23 | loss: 0.54876 | val_0_mse: 0.71065 |  0:00:04s\n",
      "epoch 24 | loss: 0.53801 | val_0_mse: 0.69976 |  0:00:04s\n",
      "epoch 25 | loss: 0.53462 | val_0_mse: 0.7405  |  0:00:05s\n",
      "epoch 26 | loss: 0.5229  | val_0_mse: 0.71564 |  0:00:05s\n",
      "epoch 27 | loss: 0.52488 | val_0_mse: 0.67479 |  0:00:05s\n",
      "epoch 28 | loss: 0.54307 | val_0_mse: 0.68831 |  0:00:05s\n",
      "epoch 29 | loss: 0.5211  | val_0_mse: 0.67089 |  0:00:05s\n",
      "epoch 30 | loss: 0.5154  | val_0_mse: 0.6931  |  0:00:06s\n",
      "epoch 31 | loss: 0.53696 | val_0_mse: 0.65249 |  0:00:06s\n",
      "epoch 32 | loss: 0.54354 | val_0_mse: 0.73617 |  0:00:06s\n",
      "epoch 33 | loss: 0.53543 | val_0_mse: 0.67385 |  0:00:06s\n",
      "epoch 34 | loss: 0.64605 | val_0_mse: 0.70959 |  0:00:06s\n",
      "epoch 35 | loss: 0.68174 | val_0_mse: 0.70571 |  0:00:07s\n",
      "epoch 36 | loss: 0.58404 | val_0_mse: 0.65348 |  0:00:07s\n",
      "epoch 37 | loss: 0.54717 | val_0_mse: 0.61923 |  0:00:07s\n",
      "epoch 38 | loss: 0.52051 | val_0_mse: 0.64217 |  0:00:07s\n",
      "epoch 39 | loss: 0.51253 | val_0_mse: 0.6036  |  0:00:07s\n",
      "epoch 40 | loss: 0.59638 | val_0_mse: 0.66983 |  0:00:08s\n",
      "epoch 41 | loss: 0.58275 | val_0_mse: 0.64416 |  0:00:08s\n",
      "epoch 42 | loss: 0.52023 | val_0_mse: 0.62625 |  0:00:08s\n",
      "epoch 43 | loss: 0.5093  | val_0_mse: 0.59904 |  0:00:08s\n",
      "epoch 44 | loss: 0.50233 | val_0_mse: 0.62262 |  0:00:08s\n",
      "epoch 45 | loss: 0.53072 | val_0_mse: 0.57186 |  0:00:09s\n",
      "epoch 46 | loss: 0.50562 | val_0_mse: 0.59006 |  0:00:09s\n",
      "epoch 47 | loss: 0.52121 | val_0_mse: 0.58166 |  0:00:09s\n",
      "epoch 48 | loss: 0.51564 | val_0_mse: 0.5639  |  0:00:09s\n",
      "epoch 49 | loss: 0.50452 | val_0_mse: 0.56898 |  0:00:09s\n",
      "epoch 50 | loss: 0.51382 | val_0_mse: 0.57144 |  0:00:10s\n",
      "epoch 51 | loss: 0.5033  | val_0_mse: 0.55197 |  0:00:10s\n",
      "epoch 52 | loss: 0.50319 | val_0_mse: 0.55267 |  0:00:10s\n",
      "epoch 53 | loss: 0.50637 | val_0_mse: 0.61018 |  0:00:10s\n",
      "epoch 54 | loss: 0.5045  | val_0_mse: 0.564   |  0:00:10s\n",
      "epoch 55 | loss: 0.50112 | val_0_mse: 0.57016 |  0:00:11s\n",
      "epoch 56 | loss: 0.50885 | val_0_mse: 0.57469 |  0:00:11s\n",
      "epoch 57 | loss: 0.50097 | val_0_mse: 0.57124 |  0:00:11s\n",
      "epoch 58 | loss: 0.50585 | val_0_mse: 0.57799 |  0:00:11s\n",
      "epoch 59 | loss: 0.50489 | val_0_mse: 0.5502  |  0:00:11s\n",
      "epoch 60 | loss: 0.50874 | val_0_mse: 0.56966 |  0:00:12s\n",
      "epoch 61 | loss: 0.50387 | val_0_mse: 0.55161 |  0:00:12s\n",
      "epoch 62 | loss: 0.50296 | val_0_mse: 0.61461 |  0:00:12s\n",
      "epoch 63 | loss: 0.53447 | val_0_mse: 0.59188 |  0:00:12s\n",
      "epoch 64 | loss: 0.59887 | val_0_mse: 0.58791 |  0:00:12s\n",
      "epoch 65 | loss: 0.54563 | val_0_mse: 0.54548 |  0:00:13s\n",
      "epoch 66 | loss: 0.52346 | val_0_mse: 0.58287 |  0:00:13s\n",
      "epoch 67 | loss: 0.56331 | val_0_mse: 0.54605 |  0:00:13s\n",
      "epoch 68 | loss: 0.49745 | val_0_mse: 0.53896 |  0:00:13s\n",
      "epoch 69 | loss: 0.49511 | val_0_mse: 0.54042 |  0:00:14s\n",
      "epoch 70 | loss: 0.49958 | val_0_mse: 0.5416  |  0:00:14s\n",
      "epoch 71 | loss: 0.49604 | val_0_mse: 0.5414  |  0:00:14s\n",
      "epoch 72 | loss: 0.49363 | val_0_mse: 0.52359 |  0:00:14s\n",
      "epoch 73 | loss: 0.4969  | val_0_mse: 0.56118 |  0:00:14s\n",
      "epoch 74 | loss: 0.49904 | val_0_mse: 0.54388 |  0:00:15s\n",
      "epoch 75 | loss: 0.50223 | val_0_mse: 0.53074 |  0:00:15s\n",
      "epoch 76 | loss: 0.49047 | val_0_mse: 0.55669 |  0:00:15s\n",
      "epoch 77 | loss: 0.48839 | val_0_mse: 0.52395 |  0:00:15s\n",
      "epoch 78 | loss: 0.48668 | val_0_mse: 0.52722 |  0:00:15s\n",
      "epoch 79 | loss: 0.48658 | val_0_mse: 0.53099 |  0:00:16s\n",
      "epoch 80 | loss: 0.48697 | val_0_mse: 0.51643 |  0:00:16s\n",
      "epoch 81 | loss: 0.48105 | val_0_mse: 0.52816 |  0:00:16s\n",
      "epoch 82 | loss: 0.49148 | val_0_mse: 0.53543 |  0:00:16s\n",
      "epoch 83 | loss: 0.48265 | val_0_mse: 0.55318 |  0:00:16s\n",
      "epoch 84 | loss: 0.50011 | val_0_mse: 0.52988 |  0:00:17s\n",
      "epoch 85 | loss: 0.5376  | val_0_mse: 0.6055  |  0:00:17s\n",
      "epoch 86 | loss: 0.53605 | val_0_mse: 0.53601 |  0:00:17s\n",
      "epoch 87 | loss: 0.52535 | val_0_mse: 0.6473  |  0:00:17s\n",
      "epoch 88 | loss: 0.61577 | val_0_mse: 0.61771 |  0:00:17s\n",
      "epoch 89 | loss: 0.53801 | val_0_mse: 0.55701 |  0:00:18s\n",
      "epoch 90 | loss: 0.51674 | val_0_mse: 0.55204 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 0.51643\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7453... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78152</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">breezy-sweep-72</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ab3p0aff\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/ab3p0aff</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050439-ab3p0aff/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ryqe24qi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.29103836050482557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ryqe24qi\" target=\"_blank\">logical-sweep-73</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 16.5436 | val_0_mse: 4.87645 |  0:00:00s\n",
      "epoch 1  | loss: 2.45181 | val_0_mse: 1.00269 |  0:00:00s\n",
      "epoch 2  | loss: 1.00224 | val_0_mse: 1.45092 |  0:00:00s\n",
      "epoch 3  | loss: 0.68335 | val_0_mse: 1.02886 |  0:00:00s\n",
      "epoch 4  | loss: 0.63656 | val_0_mse: 1.03368 |  0:00:00s\n",
      "epoch 5  | loss: 0.61882 | val_0_mse: 1.05454 |  0:00:00s\n",
      "epoch 6  | loss: 0.5759  | val_0_mse: 0.95616 |  0:00:00s\n",
      "epoch 7  | loss: 0.53468 | val_0_mse: 0.92678 |  0:00:00s\n",
      "epoch 8  | loss: 0.54591 | val_0_mse: 0.93053 |  0:00:00s\n",
      "epoch 9  | loss: 0.54385 | val_0_mse: 0.79849 |  0:00:00s\n",
      "epoch 10 | loss: 0.54085 | val_0_mse: 1.02182 |  0:00:01s\n",
      "epoch 11 | loss: 0.53823 | val_0_mse: 0.88507 |  0:00:01s\n",
      "epoch 12 | loss: 0.52903 | val_0_mse: 0.87869 |  0:00:01s\n",
      "epoch 13 | loss: 0.51604 | val_0_mse: 0.82999 |  0:00:01s\n",
      "epoch 14 | loss: 0.5147  | val_0_mse: 0.92068 |  0:00:01s\n",
      "epoch 15 | loss: 0.5164  | val_0_mse: 0.86745 |  0:00:01s\n",
      "epoch 16 | loss: 0.53246 | val_0_mse: 0.9485  |  0:00:01s\n",
      "epoch 17 | loss: 0.5149  | val_0_mse: 0.77577 |  0:00:01s\n",
      "epoch 18 | loss: 0.5178  | val_0_mse: 0.92655 |  0:00:01s\n",
      "epoch 19 | loss: 0.5442  | val_0_mse: 0.80465 |  0:00:01s\n",
      "epoch 20 | loss: 0.52461 | val_0_mse: 0.76664 |  0:00:02s\n",
      "epoch 21 | loss: 0.55258 | val_0_mse: 0.77935 |  0:00:02s\n",
      "epoch 22 | loss: 0.56066 | val_0_mse: 0.83918 |  0:00:02s\n",
      "epoch 23 | loss: 0.51785 | val_0_mse: 0.73232 |  0:00:02s\n",
      "epoch 24 | loss: 0.50904 | val_0_mse: 0.83966 |  0:00:02s\n",
      "epoch 25 | loss: 0.50265 | val_0_mse: 0.78447 |  0:00:02s\n",
      "epoch 26 | loss: 0.48593 | val_0_mse: 0.78811 |  0:00:02s\n",
      "epoch 27 | loss: 0.47892 | val_0_mse: 0.70185 |  0:00:02s\n",
      "epoch 28 | loss: 0.47845 | val_0_mse: 0.74249 |  0:00:02s\n",
      "epoch 29 | loss: 0.48403 | val_0_mse: 0.65611 |  0:00:02s\n",
      "epoch 30 | loss: 0.48818 | val_0_mse: 0.71835 |  0:00:03s\n",
      "epoch 31 | loss: 0.48073 | val_0_mse: 0.67586 |  0:00:03s\n",
      "epoch 32 | loss: 0.49848 | val_0_mse: 0.69395 |  0:00:03s\n",
      "epoch 33 | loss: 0.49119 | val_0_mse: 0.64715 |  0:00:03s\n",
      "epoch 34 | loss: 0.50063 | val_0_mse: 0.62476 |  0:00:03s\n",
      "epoch 35 | loss: 0.48304 | val_0_mse: 0.66116 |  0:00:03s\n",
      "epoch 36 | loss: 0.49694 | val_0_mse: 0.66347 |  0:00:03s\n",
      "epoch 37 | loss: 0.47247 | val_0_mse: 0.63034 |  0:00:03s\n",
      "epoch 38 | loss: 0.48255 | val_0_mse: 0.56955 |  0:00:03s\n",
      "epoch 39 | loss: 0.51609 | val_0_mse: 0.64904 |  0:00:03s\n",
      "epoch 40 | loss: 0.55468 | val_0_mse: 0.63626 |  0:00:04s\n",
      "epoch 41 | loss: 0.50266 | val_0_mse: 0.66858 |  0:00:04s\n",
      "epoch 42 | loss: 0.49363 | val_0_mse: 0.61432 |  0:00:04s\n",
      "epoch 43 | loss: 0.48627 | val_0_mse: 0.58289 |  0:00:04s\n",
      "epoch 44 | loss: 0.47654 | val_0_mse: 0.62202 |  0:00:04s\n",
      "epoch 45 | loss: 0.48616 | val_0_mse: 0.60766 |  0:00:04s\n",
      "epoch 46 | loss: 0.47591 | val_0_mse: 0.6257  |  0:00:04s\n",
      "epoch 47 | loss: 0.47967 | val_0_mse: 0.55    |  0:00:04s\n",
      "epoch 48 | loss: 0.49301 | val_0_mse: 0.62923 |  0:00:04s\n",
      "epoch 49 | loss: 0.48276 | val_0_mse: 0.60088 |  0:00:04s\n",
      "epoch 50 | loss: 0.50997 | val_0_mse: 0.6255  |  0:00:05s\n",
      "epoch 51 | loss: 0.47482 | val_0_mse: 0.54692 |  0:00:05s\n",
      "epoch 52 | loss: 0.47022 | val_0_mse: 0.626   |  0:00:05s\n",
      "epoch 53 | loss: 0.49845 | val_0_mse: 0.52959 |  0:00:05s\n",
      "epoch 54 | loss: 0.4906  | val_0_mse: 0.53819 |  0:00:05s\n",
      "epoch 55 | loss: 0.47052 | val_0_mse: 0.55345 |  0:00:05s\n",
      "epoch 56 | loss: 0.47236 | val_0_mse: 0.56346 |  0:00:05s\n",
      "epoch 57 | loss: 0.47526 | val_0_mse: 0.53316 |  0:00:05s\n",
      "epoch 58 | loss: 0.48071 | val_0_mse: 0.62241 |  0:00:05s\n",
      "epoch 59 | loss: 0.49771 | val_0_mse: 0.53831 |  0:00:05s\n",
      "epoch 60 | loss: 0.48978 | val_0_mse: 0.61577 |  0:00:06s\n",
      "epoch 61 | loss: 0.50213 | val_0_mse: 0.55883 |  0:00:06s\n",
      "epoch 62 | loss: 0.49957 | val_0_mse: 0.57575 |  0:00:06s\n",
      "epoch 63 | loss: 0.48634 | val_0_mse: 0.53882 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 0.52959\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7550... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78629</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">logical-sweep-73</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/ryqe24qi\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/ryqe24qi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050503-ryqe24qi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: omzq12ko with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.33694055997730027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/omzq12ko\" target=\"_blank\">earnest-sweep-74</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 12.85375| val_0_mse: 3.43514 |  0:00:00s\n",
      "epoch 1  | loss: 2.98707 | val_0_mse: 2.09569 |  0:00:00s\n",
      "epoch 2  | loss: 1.11293 | val_0_mse: 1.11419 |  0:00:00s\n",
      "epoch 3  | loss: 0.81883 | val_0_mse: 1.04188 |  0:00:00s\n",
      "epoch 4  | loss: 0.75659 | val_0_mse: 0.95519 |  0:00:00s\n",
      "epoch 5  | loss: 0.67556 | val_0_mse: 0.86116 |  0:00:00s\n",
      "epoch 6  | loss: 0.66499 | val_0_mse: 0.85288 |  0:00:01s\n",
      "epoch 7  | loss: 0.63485 | val_0_mse: 0.93551 |  0:00:01s\n",
      "epoch 8  | loss: 0.59715 | val_0_mse: 0.96324 |  0:00:01s\n",
      "epoch 9  | loss: 0.60537 | val_0_mse: 0.92744 |  0:00:01s\n",
      "epoch 10 | loss: 0.59444 | val_0_mse: 0.95399 |  0:00:01s\n",
      "epoch 11 | loss: 0.57307 | val_0_mse: 0.84901 |  0:00:01s\n",
      "epoch 12 | loss: 0.5912  | val_0_mse: 0.87397 |  0:00:01s\n",
      "epoch 13 | loss: 0.5659  | val_0_mse: 0.86824 |  0:00:02s\n",
      "epoch 14 | loss: 0.54943 | val_0_mse: 0.93023 |  0:00:02s\n",
      "epoch 15 | loss: 0.5525  | val_0_mse: 0.74825 |  0:00:02s\n",
      "epoch 16 | loss: 0.56693 | val_0_mse: 0.77952 |  0:00:02s\n",
      "epoch 17 | loss: 0.53162 | val_0_mse: 0.74457 |  0:00:02s\n",
      "epoch 18 | loss: 0.54711 | val_0_mse: 0.70838 |  0:00:02s\n",
      "epoch 19 | loss: 0.54545 | val_0_mse: 0.85961 |  0:00:02s\n",
      "epoch 20 | loss: 0.54539 | val_0_mse: 0.80914 |  0:00:03s\n",
      "epoch 21 | loss: 0.55138 | val_0_mse: 0.83393 |  0:00:03s\n",
      "epoch 22 | loss: 0.57092 | val_0_mse: 0.71687 |  0:00:03s\n",
      "epoch 23 | loss: 0.57873 | val_0_mse: 0.80678 |  0:00:03s\n",
      "epoch 24 | loss: 0.58657 | val_0_mse: 0.70419 |  0:00:03s\n",
      "epoch 25 | loss: 0.61086 | val_0_mse: 0.83479 |  0:00:03s\n",
      "epoch 26 | loss: 0.69717 | val_0_mse: 0.79851 |  0:00:04s\n",
      "epoch 27 | loss: 0.5664  | val_0_mse: 0.68479 |  0:00:04s\n",
      "epoch 28 | loss: 0.54667 | val_0_mse: 0.70356 |  0:00:04s\n",
      "epoch 29 | loss: 0.53153 | val_0_mse: 0.71267 |  0:00:04s\n",
      "epoch 30 | loss: 0.55002 | val_0_mse: 0.6455  |  0:00:04s\n",
      "epoch 31 | loss: 0.53176 | val_0_mse: 0.66866 |  0:00:04s\n",
      "epoch 32 | loss: 0.5277  | val_0_mse: 0.67122 |  0:00:04s\n",
      "epoch 33 | loss: 0.58058 | val_0_mse: 0.65178 |  0:00:05s\n",
      "epoch 34 | loss: 0.52243 | val_0_mse: 0.73191 |  0:00:05s\n",
      "epoch 35 | loss: 0.53878 | val_0_mse: 0.62597 |  0:00:05s\n",
      "epoch 36 | loss: 0.51705 | val_0_mse: 0.65395 |  0:00:05s\n",
      "epoch 37 | loss: 0.52385 | val_0_mse: 0.68398 |  0:00:05s\n",
      "epoch 38 | loss: 0.5155  | val_0_mse: 0.67691 |  0:00:05s\n",
      "epoch 39 | loss: 0.50823 | val_0_mse: 0.68185 |  0:00:05s\n",
      "epoch 40 | loss: 0.52018 | val_0_mse: 0.63519 |  0:00:06s\n",
      "epoch 41 | loss: 0.501   | val_0_mse: 0.60479 |  0:00:06s\n",
      "epoch 42 | loss: 0.50459 | val_0_mse: 0.62325 |  0:00:06s\n",
      "epoch 43 | loss: 0.49575 | val_0_mse: 0.59192 |  0:00:06s\n",
      "epoch 44 | loss: 0.49624 | val_0_mse: 0.57567 |  0:00:06s\n",
      "epoch 45 | loss: 0.50712 | val_0_mse: 0.60403 |  0:00:06s\n",
      "epoch 46 | loss: 0.5062  | val_0_mse: 0.57892 |  0:00:07s\n",
      "epoch 47 | loss: 0.52679 | val_0_mse: 0.68728 |  0:00:07s\n",
      "epoch 48 | loss: 0.53833 | val_0_mse: 0.58222 |  0:00:07s\n",
      "epoch 49 | loss: 0.53163 | val_0_mse: 0.59191 |  0:00:07s\n",
      "epoch 50 | loss: 0.53644 | val_0_mse: 0.58186 |  0:00:07s\n",
      "epoch 51 | loss: 0.537   | val_0_mse: 0.67581 |  0:00:07s\n",
      "epoch 52 | loss: 0.59993 | val_0_mse: 0.58764 |  0:00:07s\n",
      "epoch 53 | loss: 0.52291 | val_0_mse: 0.59657 |  0:00:08s\n",
      "epoch 54 | loss: 0.51336 | val_0_mse: 0.61622 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 0.57567\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7593... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77011</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">earnest-sweep-74</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/omzq12ko\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/omzq12ko</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050515-omzq12ko/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xym1cl9r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.12296826433909044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/xym1cl9r\" target=\"_blank\">colorful-sweep-75</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 4.14636 | val_0_mse: 2.90633 |  0:00:00s\n",
      "epoch 1  | loss: 2.09054 | val_0_mse: 1.87332 |  0:00:00s\n",
      "epoch 2  | loss: 1.1945  | val_0_mse: 1.16104 |  0:00:00s\n",
      "epoch 3  | loss: 0.87746 | val_0_mse: 1.25766 |  0:00:00s\n",
      "epoch 4  | loss: 0.84535 | val_0_mse: 0.82356 |  0:00:01s\n",
      "epoch 5  | loss: 0.72174 | val_0_mse: 1.00664 |  0:00:01s\n",
      "epoch 6  | loss: 0.63632 | val_0_mse: 1.04475 |  0:00:01s\n",
      "epoch 7  | loss: 0.66541 | val_0_mse: 0.84526 |  0:00:01s\n",
      "epoch 8  | loss: 0.61518 | val_0_mse: 0.90282 |  0:00:01s\n",
      "epoch 9  | loss: 0.58969 | val_0_mse: 0.83096 |  0:00:01s\n",
      "epoch 10 | loss: 0.56717 | val_0_mse: 0.89636 |  0:00:02s\n",
      "epoch 11 | loss: 0.57366 | val_0_mse: 0.86685 |  0:00:02s\n",
      "epoch 12 | loss: 0.5761  | val_0_mse: 0.81378 |  0:00:02s\n",
      "epoch 13 | loss: 0.5654  | val_0_mse: 0.7505  |  0:00:02s\n",
      "epoch 14 | loss: 0.66526 | val_0_mse: 0.76085 |  0:00:02s\n",
      "epoch 15 | loss: 0.58252 | val_0_mse: 0.76933 |  0:00:03s\n",
      "epoch 16 | loss: 0.58851 | val_0_mse: 0.88679 |  0:00:03s\n",
      "epoch 17 | loss: 0.59997 | val_0_mse: 0.72596 |  0:00:03s\n",
      "epoch 18 | loss: 0.5585  | val_0_mse: 0.80405 |  0:00:03s\n",
      "epoch 19 | loss: 0.54653 | val_0_mse: 0.84463 |  0:00:03s\n",
      "epoch 20 | loss: 0.5523  | val_0_mse: 0.7789  |  0:00:04s\n",
      "epoch 21 | loss: 0.53928 | val_0_mse: 0.76682 |  0:00:04s\n",
      "epoch 22 | loss: 0.54546 | val_0_mse: 0.79487 |  0:00:04s\n",
      "epoch 23 | loss: 0.53719 | val_0_mse: 0.66965 |  0:00:04s\n",
      "epoch 24 | loss: 0.56265 | val_0_mse: 0.84219 |  0:00:05s\n",
      "epoch 25 | loss: 0.55893 | val_0_mse: 0.71619 |  0:00:05s\n",
      "epoch 26 | loss: 0.55108 | val_0_mse: 0.75883 |  0:00:05s\n",
      "epoch 27 | loss: 0.53191 | val_0_mse: 0.72634 |  0:00:05s\n",
      "epoch 28 | loss: 0.53565 | val_0_mse: 0.721   |  0:00:05s\n",
      "epoch 29 | loss: 0.52034 | val_0_mse: 0.71406 |  0:00:06s\n",
      "epoch 30 | loss: 0.533   | val_0_mse: 0.74454 |  0:00:06s\n",
      "epoch 31 | loss: 0.52938 | val_0_mse: 0.7372  |  0:00:06s\n",
      "epoch 32 | loss: 0.5233  | val_0_mse: 0.68856 |  0:00:06s\n",
      "epoch 33 | loss: 0.53878 | val_0_mse: 0.6604  |  0:00:06s\n",
      "epoch 34 | loss: 0.51971 | val_0_mse: 0.66024 |  0:00:07s\n",
      "epoch 35 | loss: 0.51639 | val_0_mse: 0.77954 |  0:00:07s\n",
      "epoch 36 | loss: 0.52864 | val_0_mse: 0.61911 |  0:00:07s\n",
      "epoch 37 | loss: 0.54216 | val_0_mse: 0.654   |  0:00:07s\n",
      "epoch 38 | loss: 0.56187 | val_0_mse: 0.67918 |  0:00:07s\n",
      "epoch 39 | loss: 0.50868 | val_0_mse: 0.63342 |  0:00:08s\n",
      "epoch 40 | loss: 0.50549 | val_0_mse: 0.62179 |  0:00:08s\n",
      "epoch 41 | loss: 0.51039 | val_0_mse: 0.69711 |  0:00:08s\n",
      "epoch 42 | loss: 0.54682 | val_0_mse: 0.65374 |  0:00:08s\n",
      "epoch 43 | loss: 0.51086 | val_0_mse: 0.6698  |  0:00:08s\n",
      "epoch 44 | loss: 0.51598 | val_0_mse: 0.59902 |  0:00:09s\n",
      "epoch 45 | loss: 0.50917 | val_0_mse: 0.62562 |  0:00:09s\n",
      "epoch 46 | loss: 0.49959 | val_0_mse: 0.64734 |  0:00:09s\n",
      "epoch 47 | loss: 0.50118 | val_0_mse: 0.61499 |  0:00:09s\n",
      "epoch 48 | loss: 0.49727 | val_0_mse: 0.5791  |  0:00:09s\n",
      "epoch 49 | loss: 0.49273 | val_0_mse: 0.60903 |  0:00:10s\n",
      "epoch 50 | loss: 0.49037 | val_0_mse: 0.62937 |  0:00:10s\n",
      "epoch 51 | loss: 0.5046  | val_0_mse: 0.63058 |  0:00:10s\n",
      "epoch 52 | loss: 0.50816 | val_0_mse: 0.57674 |  0:00:10s\n",
      "epoch 53 | loss: 0.50579 | val_0_mse: 0.57999 |  0:00:10s\n",
      "epoch 54 | loss: 0.50526 | val_0_mse: 0.63034 |  0:00:11s\n",
      "epoch 55 | loss: 0.50412 | val_0_mse: 0.60215 |  0:00:11s\n",
      "epoch 56 | loss: 0.49702 | val_0_mse: 0.56888 |  0:00:11s\n",
      "epoch 57 | loss: 0.50731 | val_0_mse: 0.56683 |  0:00:11s\n",
      "epoch 58 | loss: 0.50567 | val_0_mse: 0.61598 |  0:00:11s\n",
      "epoch 59 | loss: 0.51196 | val_0_mse: 0.57339 |  0:00:12s\n",
      "epoch 60 | loss: 0.50348 | val_0_mse: 0.59743 |  0:00:12s\n",
      "epoch 61 | loss: 0.50665 | val_0_mse: 0.56216 |  0:00:12s\n",
      "epoch 62 | loss: 0.50262 | val_0_mse: 0.5558  |  0:00:12s\n",
      "epoch 63 | loss: 0.50487 | val_0_mse: 0.56652 |  0:00:13s\n",
      "epoch 64 | loss: 0.50068 | val_0_mse: 0.56902 |  0:00:13s\n",
      "epoch 65 | loss: 0.50083 | val_0_mse: 0.58074 |  0:00:13s\n",
      "epoch 66 | loss: 0.51221 | val_0_mse: 0.53598 |  0:00:13s\n",
      "epoch 67 | loss: 0.50924 | val_0_mse: 0.56054 |  0:00:13s\n",
      "epoch 68 | loss: 0.51615 | val_0_mse: 0.55694 |  0:00:14s\n",
      "epoch 69 | loss: 0.51148 | val_0_mse: 0.55481 |  0:00:14s\n",
      "epoch 70 | loss: 0.53735 | val_0_mse: 0.59053 |  0:00:14s\n",
      "epoch 71 | loss: 0.52027 | val_0_mse: 0.59304 |  0:00:14s\n",
      "epoch 72 | loss: 0.55067 | val_0_mse: 0.62725 |  0:00:14s\n",
      "epoch 73 | loss: 0.53502 | val_0_mse: 0.60374 |  0:00:15s\n",
      "epoch 74 | loss: 0.54426 | val_0_mse: 0.60285 |  0:00:15s\n",
      "epoch 75 | loss: 0.53006 | val_0_mse: 0.55816 |  0:00:15s\n",
      "epoch 76 | loss: 0.51983 | val_0_mse: 0.59121 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.53598\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7666... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.77182</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">colorful-sweep-75</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/xym1cl9r\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/xym1cl9r</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050530-xym1cl9r/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4k6abqpt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.3625636491646544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/4k6abqpt\" target=\"_blank\">azure-sweep-76</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 16.77794| val_0_mse: 6.27476 |  0:00:00s\n",
      "epoch 1  | loss: 2.64032 | val_0_mse: 1.55464 |  0:00:00s\n",
      "epoch 2  | loss: 1.13558 | val_0_mse: 1.64362 |  0:00:00s\n",
      "epoch 3  | loss: 0.80803 | val_0_mse: 1.25797 |  0:00:00s\n",
      "epoch 4  | loss: 0.7213  | val_0_mse: 1.26139 |  0:00:00s\n",
      "epoch 5  | loss: 0.65806 | val_0_mse: 0.9664  |  0:00:00s\n",
      "epoch 6  | loss: 0.62658 | val_0_mse: 0.97656 |  0:00:00s\n",
      "epoch 7  | loss: 0.58558 | val_0_mse: 0.93612 |  0:00:00s\n",
      "epoch 8  | loss: 0.57401 | val_0_mse: 1.09783 |  0:00:00s\n",
      "epoch 9  | loss: 0.60205 | val_0_mse: 0.95917 |  0:00:00s\n",
      "epoch 10 | loss: 0.60434 | val_0_mse: 1.00755 |  0:00:01s\n",
      "epoch 11 | loss: 0.63517 | val_0_mse: 0.93003 |  0:00:01s\n",
      "epoch 12 | loss: 0.54892 | val_0_mse: 0.87204 |  0:00:01s\n",
      "epoch 13 | loss: 0.54816 | val_0_mse: 0.8856  |  0:00:01s\n",
      "epoch 14 | loss: 0.53769 | val_0_mse: 0.76785 |  0:00:01s\n",
      "epoch 15 | loss: 0.5397  | val_0_mse: 0.83128 |  0:00:01s\n",
      "epoch 16 | loss: 0.53019 | val_0_mse: 0.77415 |  0:00:01s\n",
      "epoch 17 | loss: 0.53348 | val_0_mse: 0.78454 |  0:00:01s\n",
      "epoch 18 | loss: 0.50438 | val_0_mse: 0.78981 |  0:00:01s\n",
      "epoch 19 | loss: 0.50681 | val_0_mse: 0.77528 |  0:00:01s\n",
      "epoch 20 | loss: 0.50484 | val_0_mse: 0.80464 |  0:00:02s\n",
      "epoch 21 | loss: 0.52832 | val_0_mse: 0.69924 |  0:00:02s\n",
      "epoch 22 | loss: 0.49965 | val_0_mse: 0.77662 |  0:00:02s\n",
      "epoch 23 | loss: 0.4933  | val_0_mse: 0.70146 |  0:00:02s\n",
      "epoch 24 | loss: 0.48712 | val_0_mse: 0.83791 |  0:00:02s\n",
      "epoch 25 | loss: 0.50128 | val_0_mse: 0.72505 |  0:00:02s\n",
      "epoch 26 | loss: 0.49161 | val_0_mse: 0.76044 |  0:00:02s\n",
      "epoch 27 | loss: 0.48048 | val_0_mse: 0.63436 |  0:00:02s\n",
      "epoch 28 | loss: 0.48601 | val_0_mse: 0.69405 |  0:00:02s\n",
      "epoch 29 | loss: 0.50005 | val_0_mse: 0.63707 |  0:00:02s\n",
      "epoch 30 | loss: 0.48862 | val_0_mse: 0.6968  |  0:00:03s\n",
      "epoch 31 | loss: 0.50466 | val_0_mse: 0.77557 |  0:00:03s\n",
      "epoch 32 | loss: 0.5158  | val_0_mse: 0.7286  |  0:00:03s\n",
      "epoch 33 | loss: 0.51206 | val_0_mse: 0.70804 |  0:00:03s\n",
      "epoch 34 | loss: 0.51497 | val_0_mse: 0.71647 |  0:00:03s\n",
      "epoch 35 | loss: 0.50212 | val_0_mse: 0.79109 |  0:00:03s\n",
      "epoch 36 | loss: 0.52657 | val_0_mse: 0.66019 |  0:00:03s\n",
      "epoch 37 | loss: 0.49986 | val_0_mse: 0.63026 |  0:00:03s\n",
      "epoch 38 | loss: 0.50643 | val_0_mse: 0.62544 |  0:00:03s\n",
      "epoch 39 | loss: 0.51612 | val_0_mse: 0.7573  |  0:00:03s\n",
      "epoch 40 | loss: 0.54703 | val_0_mse: 0.61607 |  0:00:04s\n",
      "epoch 41 | loss: 0.50868 | val_0_mse: 0.68511 |  0:00:04s\n",
      "epoch 42 | loss: 0.5342  | val_0_mse: 0.57386 |  0:00:04s\n",
      "epoch 43 | loss: 0.53651 | val_0_mse: 0.59148 |  0:00:04s\n",
      "epoch 44 | loss: 0.50437 | val_0_mse: 0.61025 |  0:00:04s\n",
      "epoch 45 | loss: 0.49414 | val_0_mse: 0.61311 |  0:00:04s\n",
      "epoch 46 | loss: 0.4864  | val_0_mse: 0.62512 |  0:00:04s\n",
      "epoch 47 | loss: 0.488   | val_0_mse: 0.58891 |  0:00:04s\n",
      "epoch 48 | loss: 0.5014  | val_0_mse: 0.5418  |  0:00:04s\n",
      "epoch 49 | loss: 0.49887 | val_0_mse: 0.57112 |  0:00:04s\n",
      "epoch 50 | loss: 0.50357 | val_0_mse: 0.57928 |  0:00:05s\n",
      "epoch 51 | loss: 0.49207 | val_0_mse: 0.5953  |  0:00:05s\n",
      "epoch 52 | loss: 0.48671 | val_0_mse: 0.57343 |  0:00:05s\n",
      "epoch 53 | loss: 0.49103 | val_0_mse: 0.54218 |  0:00:05s\n",
      "epoch 54 | loss: 0.49992 | val_0_mse: 0.59818 |  0:00:05s\n",
      "epoch 55 | loss: 0.5006  | val_0_mse: 0.59816 |  0:00:05s\n",
      "epoch 56 | loss: 0.49222 | val_0_mse: 0.5362  |  0:00:05s\n",
      "epoch 57 | loss: 0.49426 | val_0_mse: 0.53415 |  0:00:05s\n",
      "epoch 58 | loss: 0.49086 | val_0_mse: 0.57973 |  0:00:05s\n",
      "epoch 59 | loss: 0.51269 | val_0_mse: 0.54934 |  0:00:05s\n",
      "epoch 60 | loss: 0.51147 | val_0_mse: 0.5611  |  0:00:06s\n",
      "epoch 61 | loss: 0.5068  | val_0_mse: 0.55228 |  0:00:06s\n",
      "epoch 62 | loss: 0.498   | val_0_mse: 0.58552 |  0:00:06s\n",
      "epoch 63 | loss: 0.49791 | val_0_mse: 0.54175 |  0:00:06s\n",
      "epoch 64 | loss: 0.49906 | val_0_mse: 0.53863 |  0:00:06s\n",
      "epoch 65 | loss: 0.50168 | val_0_mse: 0.52684 |  0:00:06s\n",
      "epoch 66 | loss: 0.5058  | val_0_mse: 0.57887 |  0:00:06s\n",
      "epoch 67 | loss: 0.49354 | val_0_mse: 0.5845  |  0:00:06s\n",
      "epoch 68 | loss: 0.49912 | val_0_mse: 0.5559  |  0:00:06s\n",
      "epoch 69 | loss: 0.49611 | val_0_mse: 0.55759 |  0:00:06s\n",
      "epoch 70 | loss: 0.54881 | val_0_mse: 0.54619 |  0:00:07s\n",
      "epoch 71 | loss: 0.48283 | val_0_mse: 0.55113 |  0:00:07s\n",
      "epoch 72 | loss: 0.50398 | val_0_mse: 0.55503 |  0:00:07s\n",
      "epoch 73 | loss: 0.48202 | val_0_mse: 0.53796 |  0:00:07s\n",
      "epoch 74 | loss: 0.48542 | val_0_mse: 0.51458 |  0:00:07s\n",
      "epoch 75 | loss: 0.50593 | val_0_mse: 0.5503  |  0:00:07s\n",
      "epoch 76 | loss: 0.48674 | val_0_mse: 0.53213 |  0:00:07s\n",
      "epoch 77 | loss: 0.48462 | val_0_mse: 0.54897 |  0:00:07s\n",
      "epoch 78 | loss: 0.48297 | val_0_mse: 0.55167 |  0:00:07s\n",
      "epoch 79 | loss: 0.48988 | val_0_mse: 0.54    |  0:00:07s\n",
      "epoch 80 | loss: 0.50981 | val_0_mse: 0.52842 |  0:00:08s\n",
      "epoch 81 | loss: 0.48629 | val_0_mse: 0.52819 |  0:00:08s\n",
      "epoch 82 | loss: 0.48407 | val_0_mse: 0.51167 |  0:00:08s\n",
      "epoch 83 | loss: 0.47839 | val_0_mse: 0.54475 |  0:00:08s\n",
      "epoch 84 | loss: 0.48284 | val_0_mse: 0.51816 |  0:00:08s\n",
      "epoch 85 | loss: 0.48208 | val_0_mse: 0.51794 |  0:00:08s\n",
      "epoch 86 | loss: 0.49095 | val_0_mse: 0.52252 |  0:00:08s\n",
      "epoch 87 | loss: 0.47941 | val_0_mse: 0.52137 |  0:00:08s\n",
      "epoch 88 | loss: 0.4884  | val_0_mse: 0.5252  |  0:00:08s\n",
      "epoch 89 | loss: 0.49096 | val_0_mse: 0.5067  |  0:00:08s\n",
      "epoch 90 | loss: 0.48913 | val_0_mse: 0.50985 |  0:00:09s\n",
      "epoch 91 | loss: 0.51004 | val_0_mse: 0.50698 |  0:00:09s\n",
      "epoch 92 | loss: 0.49558 | val_0_mse: 0.50802 |  0:00:09s\n",
      "epoch 93 | loss: 0.48529 | val_0_mse: 0.49363 |  0:00:09s\n",
      "epoch 94 | loss: 0.48886 | val_0_mse: 0.50133 |  0:00:09s\n",
      "epoch 95 | loss: 0.47519 | val_0_mse: 0.50921 |  0:00:09s\n",
      "epoch 96 | loss: 0.48367 | val_0_mse: 0.51843 |  0:00:09s\n",
      "epoch 97 | loss: 0.49108 | val_0_mse: 0.51441 |  0:00:09s\n",
      "epoch 98 | loss: 0.48688 | val_0_mse: 0.52361 |  0:00:10s\n",
      "epoch 99 | loss: 0.50015 | val_0_mse: 0.5365  |  0:00:10s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_mse = 0.49363\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7720... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.7927</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">azure-sweep-76</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/4k6abqpt\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/4k6abqpt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050551-4k6abqpt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vbd7tbdj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.220593814267662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/vbd7tbdj\" target=\"_blank\">dark-sweep-77</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 24.7485 | val_0_mse: 2.96156 |  0:00:00s\n",
      "epoch 1  | loss: 5.42432 | val_0_mse: 2.92803 |  0:00:00s\n",
      "epoch 2  | loss: 3.04344 | val_0_mse: 1.85876 |  0:00:00s\n",
      "epoch 3  | loss: 1.47217 | val_0_mse: 1.16748 |  0:00:00s\n",
      "epoch 4  | loss: 1.07367 | val_0_mse: 1.41633 |  0:00:01s\n",
      "epoch 5  | loss: 0.87509 | val_0_mse: 1.71447 |  0:00:01s\n",
      "epoch 6  | loss: 0.82205 | val_0_mse: 1.0344  |  0:00:01s\n",
      "epoch 7  | loss: 0.7548  | val_0_mse: 1.13717 |  0:00:01s\n",
      "epoch 8  | loss: 0.67923 | val_0_mse: 1.12671 |  0:00:02s\n",
      "epoch 9  | loss: 0.64967 | val_0_mse: 0.87705 |  0:00:02s\n",
      "epoch 10 | loss: 0.59947 | val_0_mse: 0.86815 |  0:00:02s\n",
      "epoch 11 | loss: 0.62659 | val_0_mse: 1.04736 |  0:00:02s\n",
      "epoch 12 | loss: 0.65436 | val_0_mse: 0.874   |  0:00:02s\n",
      "epoch 13 | loss: 0.63978 | val_0_mse: 0.81904 |  0:00:03s\n",
      "epoch 14 | loss: 0.58974 | val_0_mse: 0.84806 |  0:00:03s\n",
      "epoch 15 | loss: 0.58948 | val_0_mse: 0.92897 |  0:00:03s\n",
      "epoch 16 | loss: 0.62855 | val_0_mse: 0.99113 |  0:00:03s\n",
      "epoch 17 | loss: 0.63558 | val_0_mse: 0.7956  |  0:00:03s\n",
      "epoch 18 | loss: 0.63671 | val_0_mse: 0.8485  |  0:00:04s\n",
      "epoch 19 | loss: 0.56599 | val_0_mse: 0.73606 |  0:00:04s\n",
      "epoch 20 | loss: 0.57744 | val_0_mse: 0.7489  |  0:00:04s\n",
      "epoch 21 | loss: 0.55145 | val_0_mse: 0.76028 |  0:00:04s\n",
      "epoch 22 | loss: 0.55929 | val_0_mse: 0.68897 |  0:00:05s\n",
      "epoch 23 | loss: 0.58429 | val_0_mse: 0.81138 |  0:00:05s\n",
      "epoch 24 | loss: 0.56961 | val_0_mse: 0.76891 |  0:00:05s\n",
      "epoch 25 | loss: 0.59153 | val_0_mse: 0.78757 |  0:00:05s\n",
      "epoch 26 | loss: 0.56463 | val_0_mse: 0.66322 |  0:00:05s\n",
      "epoch 27 | loss: 0.55971 | val_0_mse: 0.65776 |  0:00:06s\n",
      "epoch 28 | loss: 0.63769 | val_0_mse: 0.71071 |  0:00:06s\n",
      "epoch 29 | loss: 0.56135 | val_0_mse: 0.64782 |  0:00:06s\n",
      "epoch 30 | loss: 0.58453 | val_0_mse: 0.76418 |  0:00:06s\n",
      "epoch 31 | loss: 0.56354 | val_0_mse: 0.62994 |  0:00:07s\n",
      "epoch 32 | loss: 0.55245 | val_0_mse: 0.61274 |  0:00:07s\n",
      "epoch 33 | loss: 0.53517 | val_0_mse: 0.6442  |  0:00:07s\n",
      "epoch 34 | loss: 0.59154 | val_0_mse: 0.5839  |  0:00:07s\n",
      "epoch 35 | loss: 0.53921 | val_0_mse: 0.66056 |  0:00:08s\n",
      "epoch 36 | loss: 0.54952 | val_0_mse: 0.62365 |  0:00:08s\n",
      "epoch 37 | loss: 0.54777 | val_0_mse: 0.66518 |  0:00:08s\n",
      "epoch 38 | loss: 0.53362 | val_0_mse: 0.60143 |  0:00:08s\n",
      "epoch 39 | loss: 0.51251 | val_0_mse: 0.57909 |  0:00:08s\n",
      "epoch 40 | loss: 0.52736 | val_0_mse: 0.63064 |  0:00:09s\n",
      "epoch 41 | loss: 0.52525 | val_0_mse: 0.59485 |  0:00:09s\n",
      "epoch 42 | loss: 0.49958 | val_0_mse: 0.57516 |  0:00:09s\n",
      "epoch 43 | loss: 0.5137  | val_0_mse: 0.645   |  0:00:09s\n",
      "epoch 44 | loss: 0.53881 | val_0_mse: 0.57974 |  0:00:10s\n",
      "epoch 45 | loss: 0.50318 | val_0_mse: 0.60584 |  0:00:10s\n",
      "epoch 46 | loss: 0.51809 | val_0_mse: 0.62261 |  0:00:10s\n",
      "epoch 47 | loss: 0.51786 | val_0_mse: 0.56814 |  0:00:10s\n",
      "epoch 48 | loss: 0.55327 | val_0_mse: 0.65732 |  0:00:10s\n",
      "epoch 49 | loss: 0.55353 | val_0_mse: 0.56917 |  0:00:11s\n",
      "epoch 50 | loss: 0.50155 | val_0_mse: 0.67795 |  0:00:11s\n",
      "epoch 51 | loss: 0.61924 | val_0_mse: 0.59414 |  0:00:11s\n",
      "epoch 52 | loss: 0.52991 | val_0_mse: 0.65721 |  0:00:11s\n",
      "epoch 53 | loss: 0.50921 | val_0_mse: 0.54178 |  0:00:12s\n",
      "epoch 54 | loss: 0.52109 | val_0_mse: 0.58198 |  0:00:12s\n",
      "epoch 55 | loss: 0.49394 | val_0_mse: 0.6221  |  0:00:12s\n",
      "epoch 56 | loss: 0.49859 | val_0_mse: 0.58081 |  0:00:12s\n",
      "epoch 57 | loss: 0.5188  | val_0_mse: 0.53996 |  0:00:12s\n",
      "epoch 58 | loss: 0.50216 | val_0_mse: 0.60128 |  0:00:13s\n",
      "epoch 59 | loss: 0.49808 | val_0_mse: 0.53832 |  0:00:13s\n",
      "epoch 60 | loss: 0.48289 | val_0_mse: 0.55403 |  0:00:13s\n",
      "epoch 61 | loss: 0.48957 | val_0_mse: 0.55385 |  0:00:13s\n",
      "epoch 62 | loss: 0.48615 | val_0_mse: 0.55473 |  0:00:14s\n",
      "epoch 63 | loss: 0.48789 | val_0_mse: 0.58567 |  0:00:14s\n",
      "epoch 64 | loss: 0.50365 | val_0_mse: 0.55647 |  0:00:14s\n",
      "epoch 65 | loss: 0.50233 | val_0_mse: 0.56177 |  0:00:14s\n",
      "epoch 66 | loss: 0.48672 | val_0_mse: 0.52989 |  0:00:14s\n",
      "epoch 67 | loss: 0.4846  | val_0_mse: 0.53754 |  0:00:15s\n",
      "epoch 68 | loss: 0.48469 | val_0_mse: 0.53564 |  0:00:15s\n",
      "epoch 69 | loss: 0.49168 | val_0_mse: 0.5286  |  0:00:15s\n",
      "epoch 70 | loss: 0.48189 | val_0_mse: 0.52516 |  0:00:15s\n",
      "epoch 71 | loss: 0.48873 | val_0_mse: 0.5358  |  0:00:16s\n",
      "epoch 72 | loss: 0.49218 | val_0_mse: 0.54714 |  0:00:16s\n",
      "epoch 73 | loss: 0.49994 | val_0_mse: 0.56451 |  0:00:16s\n",
      "epoch 74 | loss: 0.50542 | val_0_mse: 0.55859 |  0:00:16s\n",
      "epoch 75 | loss: 0.57321 | val_0_mse: 0.53565 |  0:00:17s\n",
      "epoch 76 | loss: 0.50551 | val_0_mse: 0.54028 |  0:00:17s\n",
      "epoch 77 | loss: 0.49168 | val_0_mse: 0.52155 |  0:00:17s\n",
      "epoch 78 | loss: 0.48496 | val_0_mse: 0.5415  |  0:00:17s\n",
      "epoch 79 | loss: 0.50998 | val_0_mse: 0.51445 |  0:00:17s\n",
      "epoch 80 | loss: 0.4923  | val_0_mse: 0.52336 |  0:00:18s\n",
      "epoch 81 | loss: 0.493   | val_0_mse: 0.51837 |  0:00:18s\n",
      "epoch 82 | loss: 0.49523 | val_0_mse: 0.56201 |  0:00:18s\n",
      "epoch 83 | loss: 0.4962  | val_0_mse: 0.5746  |  0:00:19s\n",
      "epoch 84 | loss: 0.5193  | val_0_mse: 0.5491  |  0:00:19s\n",
      "epoch 85 | loss: 0.49347 | val_0_mse: 0.53992 |  0:00:19s\n",
      "epoch 86 | loss: 0.48136 | val_0_mse: 0.53791 |  0:00:19s\n",
      "epoch 87 | loss: 0.48473 | val_0_mse: 0.57657 |  0:00:19s\n",
      "epoch 88 | loss: 0.53348 | val_0_mse: 0.51824 |  0:00:20s\n",
      "epoch 89 | loss: 0.52045 | val_0_mse: 0.55113 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.51445\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7769... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.78232</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dark-sweep-77</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/vbd7tbdj\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/vbd7tbdj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050608-vbd7tbdj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l1pk4q2j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: sparsemax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.3939589776459514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/l1pk4q2j\" target=\"_blank\">lemon-sweep-78</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 3.80639 | val_0_mse: 2.11262 |  0:00:00s\n",
      "epoch 1  | loss: 1.64899 | val_0_mse: 1.76651 |  0:00:00s\n",
      "epoch 2  | loss: 1.04094 | val_0_mse: 1.06621 |  0:00:00s\n",
      "epoch 3  | loss: 0.86617 | val_0_mse: 1.12112 |  0:00:00s\n",
      "epoch 4  | loss: 0.67812 | val_0_mse: 0.92533 |  0:00:00s\n",
      "epoch 5  | loss: 0.616   | val_0_mse: 1.23796 |  0:00:00s\n",
      "epoch 6  | loss: 0.59775 | val_0_mse: 0.94329 |  0:00:00s\n",
      "epoch 7  | loss: 0.58956 | val_0_mse: 0.96335 |  0:00:00s\n",
      "epoch 8  | loss: 0.57414 | val_0_mse: 0.95858 |  0:00:01s\n",
      "epoch 9  | loss: 0.56769 | val_0_mse: 0.8854  |  0:00:01s\n",
      "epoch 10 | loss: 0.58199 | val_0_mse: 0.99218 |  0:00:01s\n",
      "epoch 11 | loss: 0.56838 | val_0_mse: 0.82031 |  0:00:01s\n",
      "epoch 12 | loss: 0.55164 | val_0_mse: 1.00049 |  0:00:01s\n",
      "epoch 13 | loss: 0.5717  | val_0_mse: 0.82253 |  0:00:01s\n",
      "epoch 14 | loss: 0.56577 | val_0_mse: 0.93018 |  0:00:01s\n",
      "epoch 15 | loss: 0.57045 | val_0_mse: 0.79328 |  0:00:01s\n",
      "epoch 16 | loss: 0.55663 | val_0_mse: 0.78912 |  0:00:02s\n",
      "epoch 17 | loss: 0.54424 | val_0_mse: 0.818   |  0:00:02s\n",
      "epoch 18 | loss: 0.55952 | val_0_mse: 0.9098  |  0:00:02s\n",
      "epoch 19 | loss: 0.55428 | val_0_mse: 0.76583 |  0:00:02s\n",
      "epoch 20 | loss: 0.52616 | val_0_mse: 0.81029 |  0:00:02s\n",
      "epoch 21 | loss: 0.53923 | val_0_mse: 0.84979 |  0:00:02s\n",
      "epoch 22 | loss: 0.5163  | val_0_mse: 0.87113 |  0:00:02s\n",
      "epoch 23 | loss: 0.5107  | val_0_mse: 0.78423 |  0:00:02s\n",
      "epoch 24 | loss: 0.51026 | val_0_mse: 0.82685 |  0:00:02s\n",
      "epoch 25 | loss: 0.53057 | val_0_mse: 0.88261 |  0:00:03s\n",
      "epoch 26 | loss: 0.53368 | val_0_mse: 0.68912 |  0:00:03s\n",
      "epoch 27 | loss: 0.56851 | val_0_mse: 0.79055 |  0:00:03s\n",
      "epoch 28 | loss: 0.55559 | val_0_mse: 0.63953 |  0:00:03s\n",
      "epoch 29 | loss: 0.68701 | val_0_mse: 0.70295 |  0:00:03s\n",
      "epoch 30 | loss: 0.55043 | val_0_mse: 0.76633 |  0:00:03s\n",
      "epoch 31 | loss: 0.51356 | val_0_mse: 0.75856 |  0:00:03s\n",
      "epoch 32 | loss: 0.51162 | val_0_mse: 0.70149 |  0:00:03s\n",
      "epoch 33 | loss: 0.50212 | val_0_mse: 0.69576 |  0:00:04s\n",
      "epoch 34 | loss: 0.51308 | val_0_mse: 0.69265 |  0:00:04s\n",
      "epoch 35 | loss: 0.51483 | val_0_mse: 0.77879 |  0:00:04s\n",
      "epoch 36 | loss: 0.51433 | val_0_mse: 0.67933 |  0:00:04s\n",
      "epoch 37 | loss: 0.5137  | val_0_mse: 0.73899 |  0:00:04s\n",
      "epoch 38 | loss: 0.50644 | val_0_mse: 0.65721 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 0.63953\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7817... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pearson</td><td>0.76187</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">lemon-sweep-78</strong>: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/l1pk4q2j\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/runs/l1pk4q2j</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220203_050634-l1pk4q2j/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lfhigajb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_type: entmax\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.08652274414839396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_d: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_independent: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_shared: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/runs/lfhigajb\" target=\"_blank\">rose-sweep-79</a></strong> to <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz\" target=\"_blank\">https://wandb.ai/notsomonk/SemEval-Task-8/sweeps/4t2h3fjz</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 8.55345 | val_0_mse: 2.19062 |  0:00:00s\n",
      "epoch 1  | loss: 1.8744  | val_0_mse: 1.41998 |  0:00:00s\n",
      "epoch 2  | loss: 1.25515 | val_0_mse: 1.28519 |  0:00:00s\n",
      "epoch 3  | loss: 0.92188 | val_0_mse: 1.00506 |  0:00:00s\n",
      "epoch 4  | loss: 0.78451 | val_0_mse: 0.90205 |  0:00:01s\n",
      "epoch 5  | loss: 0.69143 | val_0_mse: 1.07184 |  0:00:01s\n",
      "epoch 6  | loss: 0.83974 | val_0_mse: 0.85058 |  0:00:01s\n",
      "epoch 7  | loss: 0.67997 | val_0_mse: 0.97235 |  0:00:01s\n",
      "epoch 8  | loss: 0.6493  | val_0_mse: 0.8924  |  0:00:01s\n",
      "epoch 9  | loss: 0.59879 | val_0_mse: 0.84196 |  0:00:01s\n",
      "epoch 10 | loss: 0.61257 | val_0_mse: 0.98607 |  0:00:02s\n",
      "epoch 11 | loss: 0.57475 | val_0_mse: 0.97152 |  0:00:02s\n",
      "epoch 12 | loss: 0.57701 | val_0_mse: 0.85261 |  0:00:02s\n",
      "epoch 13 | loss: 0.55984 | val_0_mse: 0.80188 |  0:00:02s\n",
      "epoch 14 | loss: 0.53838 | val_0_mse: 0.85077 |  0:00:02s\n",
      "epoch 15 | loss: 0.54793 | val_0_mse: 0.79177 |  0:00:03s\n",
      "epoch 16 | loss: 0.56157 | val_0_mse: 0.98684 |  0:00:03s\n",
      "epoch 17 | loss: 0.62364 | val_0_mse: 0.74157 |  0:00:03s\n",
      "epoch 18 | loss: 0.57668 | val_0_mse: 0.93094 |  0:00:03s\n",
      "epoch 19 | loss: 0.59793 | val_0_mse: 0.68633 |  0:00:04s\n",
      "epoch 20 | loss: 0.54069 | val_0_mse: 0.88843 |  0:00:04s\n",
      "epoch 21 | loss: 0.53697 | val_0_mse: 0.74491 |  0:00:04s\n",
      "epoch 22 | loss: 0.5221  | val_0_mse: 0.78715 |  0:00:04s\n",
      "epoch 23 | loss: 0.5302  | val_0_mse: 0.82229 |  0:00:04s\n",
      "epoch 24 | loss: 0.51546 | val_0_mse: 0.72221 |  0:00:05s\n",
      "epoch 25 | loss: 0.51463 | val_0_mse: 0.82932 |  0:00:05s\n",
      "epoch 26 | loss: 0.5226  | val_0_mse: 0.76258 |  0:00:05s\n",
      "epoch 27 | loss: 0.50712 | val_0_mse: 0.79729 |  0:00:05s\n",
      "epoch 28 | loss: 0.51815 | val_0_mse: 0.65174 |  0:00:05s\n",
      "epoch 29 | loss: 0.57215 | val_0_mse: 0.72199 |  0:00:06s\n",
      "epoch 30 | loss: 0.52236 | val_0_mse: 0.64609 |  0:00:06s\n",
      "epoch 31 | loss: 0.50291 | val_0_mse: 0.63769 |  0:00:06s\n",
      "epoch 32 | loss: 0.50392 | val_0_mse: 0.64963 |  0:00:06s\n",
      "epoch 33 | loss: 0.51454 | val_0_mse: 0.69299 |  0:00:06s\n",
      "epoch 34 | loss: 0.49966 | val_0_mse: 0.64874 |  0:00:07s\n",
      "epoch 35 | loss: 0.51236 | val_0_mse: 0.62434 |  0:00:07s\n",
      "epoch 36 | loss: 0.51182 | val_0_mse: 0.66006 |  0:00:07s\n",
      "epoch 37 | loss: 0.50696 | val_0_mse: 0.63764 |  0:00:07s\n",
      "epoch 38 | loss: 0.50161 | val_0_mse: 0.66003 |  0:00:07s\n",
      "epoch 39 | loss: 0.51232 | val_0_mse: 0.56679 |  0:00:08s\n",
      "epoch 40 | loss: 0.50085 | val_0_mse: 0.60346 |  0:00:08s\n",
      "epoch 41 | loss: 0.49505 | val_0_mse: 0.61969 |  0:00:08s\n",
      "epoch 42 | loss: 0.50536 | val_0_mse: 0.6201  |  0:00:08s\n",
      "epoch 43 | loss: 0.49837 | val_0_mse: 0.56024 |  0:00:08s\n",
      "epoch 44 | loss: 0.49656 | val_0_mse: 0.60917 |  0:00:09s\n",
      "epoch 45 | loss: 0.49014 | val_0_mse: 0.58039 |  0:00:09s\n",
      "epoch 46 | loss: 0.49012 | val_0_mse: 0.59633 |  0:00:09s\n",
      "epoch 47 | loss: 0.49662 | val_0_mse: 0.56133 |  0:00:09s\n",
      "epoch 48 | loss: 0.50452 | val_0_mse: 0.54971 |  0:00:09s\n",
      "epoch 49 | loss: 0.49695 | val_0_mse: 0.6118  |  0:00:10s\n",
      "epoch 50 | loss: 0.49598 | val_0_mse: 0.52557 |  0:00:10s\n",
      "epoch 51 | loss: 0.49496 | val_0_mse: 0.55852 |  0:00:10s\n",
      "epoch 52 | loss: 0.48503 | val_0_mse: 0.64931 |  0:00:10s\n",
      "epoch 53 | loss: 0.52293 | val_0_mse: 0.54853 |  0:00:10s\n",
      "epoch 54 | loss: 0.60041 | val_0_mse: 0.56369 |  0:00:11s\n",
      "epoch 55 | loss: 0.50378 | val_0_mse: 0.56815 |  0:00:11s\n",
      "epoch 56 | loss: 0.50425 | val_0_mse: 0.55916 |  0:00:11s\n",
      "epoch 57 | loss: 0.481   | val_0_mse: 0.54831 |  0:00:11s\n",
      "epoch 58 | loss: 0.48337 | val_0_mse: 0.57452 |  0:00:12s\n",
      "epoch 59 | loss: 0.49179 | val_0_mse: 0.54475 |  0:00:12s\n",
      "epoch 60 | loss: 0.48106 | val_0_mse: 0.58337 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.52557\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7868... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3356051a0deb4d7fb7e403a73e4f09f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    with wandb.init() as run:\n",
    "        import numpy as np\n",
    "        import random\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        from pandas import read_csv, concat, DataFrame\n",
    "        from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "        from src.config import CLEANED_PATH, DataType, UNCLEANED_PATH, RAW_FILE, INFERENCE_FILE\n",
    "\n",
    "\n",
    "        train_path = CLEANED_PATH.format(data_type=DataType.train.name) + INFERENCE_FILE\n",
    "        test_path = CLEANED_PATH.format(data_type=DataType.test.name) + INFERENCE_FILE\n",
    "\n",
    "        train_df = read_csv(train_path, sep=',', usecols=['sentences_mean', 'sentences_min', 'sentences_max',\n",
    "                                                          'sentences_med', 'title', 'n1_title_n2_text',\n",
    "                                                          'n2_title_n1_text', 'n1_title_n1_text',\n",
    "                                                          'n2_title_n2_text', 'start_para', 'end_para',\n",
    "                                                          'ner', 'tf_idf', 'wmd_dist', 'overall'])\n",
    "\n",
    "\n",
    "        train_df = train_df.drop_duplicates()\n",
    "        test_df = read_csv(test_path, sep=',', usecols=['sentences_mean', 'sentences_min', 'sentences_max',\n",
    "                                                        'sentences_med', 'title', 'n1_title_n2_text',\n",
    "                                                        'n2_title_n1_text', 'n1_title_n1_text',\n",
    "                                                        'n2_title_n2_text', 'start_para', 'end_para',\n",
    "                                                        'ner', 'tf_idf', 'wmd_dist'])\n",
    "\n",
    "        y = train_df.pop('overall')\n",
    "        y = y.values\n",
    "        x = train_df.values\n",
    "        train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.15, random_state=5)\n",
    "        \n",
    "        config = wandb.config\n",
    "        clf = TabNetRegressor(**config)  #TabNetRegressor()\n",
    "        clf.fit(train_x, np.array(train_y).reshape(-1, 1), eval_set=[(val_x, np.array(val_y).reshape(-1, 1))])\n",
    "        \n",
    "        \n",
    "        pred_val = clf.predict(val_x)\n",
    "        \n",
    "        pred_val = np.squeeze(np.asarray(pred_val))\n",
    "        val_y = np.squeeze(np.asarray(val_y))\n",
    "        \n",
    "        p_s = pearsonr(pred_val, val_y)\n",
    "        wandb.log({\"pearson\": p_s[0]})\n",
    "\n",
    "count = 100 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d4303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testp = model.predict(test_df.values)\n",
    "testp = np.clip(testp, 1.0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24bed0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4902,)\n",
      "(4878,)\n"
     ]
    }
   ],
   "source": [
    "test_df_full = read_csv(test_path, sep=',', usecols=['pair_id'])\n",
    "test_df_full['Overall'] = testp\n",
    "out_path = 'results/try/tabnet_95.csv'\n",
    "\n",
    "\n",
    "test_df_full.to_csv(out_path, mode='w', columns=[\"pair_id\", \"Overall\"], index=False)\n",
    "UNCLEANED_PATH = UNCLEANED_PATH.format(data_type=DataType.test.name)\n",
    "RAW_FILE = RAW_FILE.format(data_type=DataType.test.name)\n",
    "add_missing_entries(UNCLEANED_PATH + RAW_FILE, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
